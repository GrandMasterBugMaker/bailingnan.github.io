<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://bailingnan.github.io/</id>
    <title>ç™½å‡Œå—</title>
    <updated>2020-01-31T16:43:17.726Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://bailingnan.github.io/"/>
    <link rel="self" href="https://bailingnan.github.io/atom.xml"/>
    <subtitle>DL/RecSys/Python/Java/INTJ</subtitle>
    <logo>https://bailingnan.github.io/images/avatar.png</logo>
    <icon>https://bailingnan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, ç™½å‡Œå—</rights>
    <entry>
        <title type="html"><![CDATA[Pycharmå¸¸ç”¨å¿«æ·é”®åŠæŠ€å·§(macOS)]]></title>
        <id>https://bailingnan.github.io/post/pycharm-chang-yong-kuai-jie-jian-ji-ji-qiao-macos</id>
        <link href="https://bailingnan.github.io/post/pycharm-chang-yong-kuai-jie-jian-ji-ji-qiao-macos">
        </link>
        <updated>2020-01-31T16:42:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="macé”®ç›˜ç¬¦å·å’Œä¿®é¥°é”®è¯´æ˜">Macé”®ç›˜ç¬¦å·å’Œä¿®é¥°é”®è¯´æ˜</h1>
<ul>
<li><code>âŒ˜</code>:Command</li>
<li><code>â‡§</code>:Shift</li>
<li><code>âŒ¥</code>:Option</li>
<li><code>âŒƒ</code>:Control</li>
<li><code>â†©ï¸</code>:Return/Enter</li>
<li><code>âŒ«</code>:Delete</li>
<li><code>âŒ¦</code>:å‘å‰åˆ é™¤é”®ï¼ˆFn+Deleteï¼‰</li>
<li><code>â†‘</code>:ä¸Šç®­å¤´</li>
<li><code>â†“</code>:ä¸‹ç®­å¤´</li>
<li><code>â†</code>:å·¦ç®­å¤´</li>
<li><code>â†’</code>:å³ç®­å¤´</li>
<li><code>â‡</code>:Page Upï¼ˆFn+â†‘ï¼‰</li>
<li><code>â‡Ÿ</code>:Page Downï¼ˆFn+â†“ï¼‰</li>
<li><code>Home</code>:Fn + â†</li>
<li><code>End</code>:Fn + â†’</li>
<li><code>â‡¥</code>:å³åˆ¶è¡¨ç¬¦ï¼ˆTabé”®ï¼‰</li>
<li><code>â‡¤</code>:å·¦åˆ¶è¡¨ç¬¦ï¼ˆShift+Tabï¼‰</li>
<li><code>â‹</code>:Escape (Esc)</li>
<li>ä¸€ç›´æŒ‰ä½<code>fn</code>å¯è°ƒå‡ºF1~F10</li>
</ul>
<h1 id="editingç¼–è¾‘">Editingï¼ˆç¼–è¾‘ï¼‰</h1>
<ul>
<li><code>âŒ˜Z</code>:æ’¤é”€æ“ä½œ</li>
<li><code>âŒ˜Y</code>:åˆ é™¤æ•´è¡Œ</li>
<li><code>â‡§F6</code>:é‡å‘½åæ–‡ä»¶</li>
<li><code>âŒ˜S</code>:ä¿å­˜æ‰€æœ‰</li>
<li><code>âŒ¦</code>:åˆ é™¤æ–‡ä»¶ï¼ˆFn+Deleteï¼‰</li>
<li><code>âŒ˜âŒ¥L</code>:æ ¼å¼åŒ–ä»£ç </li>
<li><code>Home</code>:Fn + â†ï¼Œè·³è½¬åˆ°è¡Œé¦–</li>
<li><code>End</code>:Fn + â†’ï¼Œè·³è½¬åˆ°è¡Œæœ«</li>
<li><code>â‡§â†‘/â‡§â†“</code>:å‘ä¸Š/å‘ä¸‹é€‰ä¸­è¡Œ</li>
<li><code>âŒ˜D</code>: å¤åˆ¶å½“å‰è¡Œæˆ–é€‰å®šçš„å—</li>
<li><code>âŒ˜/</code>:æ³¨é‡Š/å–æ¶ˆæ³¨é‡Šä¸è¡Œæ³¨é‡Š</li>
<li><code>âŒ˜âŒ¥/</code>:æ³¨é‡Š/å–æ¶ˆæ³¨é‡Šä¸å—æ³¨é‡Š</li>
<li><code>âŒ˜J</code>:æ’å…¥è‡ªå®šä¹‰åŠ¨æ€ä»£ç æ¨¡æ¿</li>
<li><code>âŒƒSpace</code>:åŸºæœ¬çš„ä»£ç è¡¥å…¨ï¼ˆè¡¥å…¨ä»»ä½•ç±»ã€æ–¹æ³•ã€å˜é‡ï¼‰</li>
<li><code>âŒƒâ‡§Space</code>:æ™ºèƒ½ä»£ç è¡¥å…¨ï¼ˆè¿‡æ»¤å™¨æ–¹æ³•åˆ—è¡¨å’Œå˜é‡çš„é¢„æœŸç±»å‹ï¼‰</li>
<li><code>â‡§â†©</code>:å¼€å§‹æ–°çš„ä¸€è¡Œ</li>
<li><code>âŒ˜â‡§U</code>:å¤§å°å†™åˆ‡æ¢,å…‰æ ‡åœ¨è¡Œå†…ä»»æ„ä½ç½®éƒ½èƒ½å¦èµ·ä¸€è¡Œï¼Œä¸”ä¸ç ´åå½“è¡Œç»“æ„</li>
<li><code>âŒ˜â‡§â†©</code>:è‡ªåŠ¨ç»“æŸä»£ç ï¼Œè¡Œæœ«è‡ªåŠ¨æ·»åŠ åˆ†å·</li>
<li><code>âŒ˜P</code>:æ˜¾ç¤ºæ–¹æ³•çš„å‚æ•°ä¿¡æ¯</li>
<li><code>âŒƒJ</code>:å¿«é€ŸæŸ¥çœ‹æ–‡æ¡£</li>
<li><code>â‡§F1</code>:æŸ¥çœ‹å¤–éƒ¨æ–‡æ¡£ï¼ˆåœ¨æŸäº›ä»£ç ä¸Šä¼šè§¦å‘æ‰“å¼€æµè§ˆå™¨æ˜¾ç¤ºç›¸å…³æ–‡æ¡£ï¼‰</li>
<li><code>âŒ˜F1</code>:åœ¨é”™è¯¯æˆ–è­¦å‘Šå¤„æ˜¾ç¤ºå…·ä½“æè¿°ä¿¡æ¯</li>
<li><code>âŒ˜N, âŒƒâ†©, âŒƒN</code>:ç”Ÿæˆä»£ç ï¼ˆgetterã€setterã€æ„é€ å‡½æ•°ã€hashCode/equals,toStringï¼‰</li>
<li><code>âŒ¥â†‘</code>:è¿ç»­é€‰ä¸­ä»£ç å—</li>
<li><code>âŒ¥â†“</code>:å‡å°‘å½“å‰é€‰ä¸­çš„ä»£ç å—</li>
<li><code>âŒ¥â†©</code>:æ˜¾ç¤ºæ„å‘åŠ¨ä½œå’Œå¿«é€Ÿä¿®å¤ä»£ç </li>
<li><code>âŒ˜â‡§] / âŒ˜â‡§[</code>:é€‰æ‹©ç›´åˆ°ä»£ç å—ç»“æŸ/å¼€å§‹</li>
<li><code>âŒ˜+ / âŒ˜-</code>:å±•å¼€ / æŠ˜å ä»£ç å—</li>
<li><code>âŒ˜â‡§+</code>:å±•å¼€æ‰€æœ‰ä»£ç å—</li>
<li><code>âŒ˜â‡§-</code>:æŠ˜å æ‰€æœ‰ä»£ç å—</li>
</ul>
<h1 id="searchreplaceæŸ¥è¯¢æ›¿æ¢">Search/Replaceï¼ˆæŸ¥è¯¢/æ›¿æ¢ï¼‰</h1>
<ul>
<li><code>Double â‡§</code>:æŸ¥è¯¢ä»»ä½•ä¸œè¥¿</li>
<li><code>âŒ˜F</code>:æ–‡ä»¶å†…æŸ¥æ‰¾</li>
</ul>
<h1 id="compile-and-runç¼–è¯‘å’Œè¿è¡Œ">Compile and Runï¼ˆç¼–è¯‘å’Œè¿è¡Œï¼‰</h1>
<ul>
<li><code>âŒƒâ‡§F10</code>:Run</li>
<li><code>âŒƒâ‡§F9</code>:Debug</li>
</ul>
<h1 id="navigationå¯¼èˆª">Navigationï¼ˆå¯¼èˆªï¼‰</h1>
<ul>
<li><code>âŒ˜B</code>:è¿›å…¥å…‰æ ‡æ‰€åœ¨çš„æ–¹æ³•/å˜é‡çš„æ¥å£æˆ–æ˜¯å®šä¹‰å¤„</li>
<li><code>âŒ˜âŒ¥B</code>:è·³è½¬åˆ°å®ç°å¤„ï¼Œåœ¨æŸä¸ªè°ƒç”¨çš„æ–¹æ³•åä¸Šä½¿ç”¨ä¼šè·³åˆ°å…·ä½“çš„å®ç°å¤„ï¼Œå¯ä»¥è·³è¿‡æ¥å£</li>
<li><code>âŒ¥ Space, âŒ˜Y</code>:å¿«é€Ÿæ‰“å¼€å…‰æ ‡æ‰€åœ¨æ–¹æ³•ã€ç±»çš„å®šä¹‰</li>
<li><code>âŒƒâ‡§B</code>:è·³è½¬åˆ°ç±»å‹å£°æ˜å¤„</li>
<li><code>âŒ˜U</code>:å‰å¾€å½“å‰å…‰æ ‡æ‰€åœ¨æ–¹æ³•çš„çˆ¶ç±»çš„æ–¹æ³• / æ¥å£å®šä¹‰</li>
<li><code>âŒƒH</code>:æ˜¾ç¤ºå½“å‰ç±»çš„å±‚æ¬¡ç»“æ„</li>
<li><code>âŒ˜â‡§H</code>:æ˜¾ç¤ºæ–¹æ³•å±‚æ¬¡ç»“æ„</li>
<li><code>âŒƒâŒ¥H</code>:æ˜¾ç¤ºè°ƒç”¨å±‚æ¬¡ç»“æ„</li>
</ul>
<h1 id="è°ƒè¯•">è°ƒè¯•</h1>
<ul>
<li><code>step over</code>:åœ¨å•æ­¥æ‰§è¡Œæ—¶ï¼Œåœ¨å‡½æ•°å†…é‡åˆ°å­å‡½æ•°æ—¶ä¸ä¼šè¿›å…¥å­å‡½æ•°å†…å•æ­¥æ‰§è¡Œï¼Œè€Œæ˜¯å°†å­å‡½æ•°æ•´ä¸ªæ‰§è¡Œå®Œå†åœæ­¢ï¼Œä¹Ÿå°±æ˜¯æŠŠå­å‡½æ•°æ•´ä¸ªä½œä¸ºä¸€æ­¥ã€‚åœ¨ä¸å­˜åœ¨å­å‡½æ•°çš„æƒ…å†µä¸‹æ˜¯å’Œstep intoæ•ˆæœä¸€æ ·çš„ã€‚ç®€å•çš„è¯´å°±æ˜¯ï¼Œ<strong>ç¨‹åºä»£ç è¶Šè¿‡å­å‡½æ•°ï¼Œä½†å­å‡½æ•°ä¼šæ‰§è¡Œï¼Œä¸”ä¸è¿›å…¥</strong>ã€‚</li>
<li><code>step into</code>:åœ¨å•æ­¥æ‰§è¡Œæ—¶ï¼Œé‡åˆ°å­å‡½æ•°å°±è¿›å…¥å¹¶ä¸”ç»§ç»­å•æ­¥æ‰§è¡Œï¼Œ<strong>æœ‰çš„ä¼šè·³åˆ°æºä»£ç é‡Œé¢å»æ‰§è¡Œ</strong>ã€‚</li>
<li><code>step into my code</code>:åœ¨å•æ­¥æ‰§è¡Œæ—¶ï¼Œé‡åˆ°å­å‡½æ•°å°±è¿›å…¥å¹¶ä¸”ç»§ç»­å•æ­¥æ‰§è¡Œï¼Œ<strong>ä¸ä¼šè¿›å…¥åˆ°æºç ä¸­</strong>ã€‚</li>
<li><code>step out</code>:å‡å¦‚è¿›å…¥äº†ä¸€ä¸ªå‡½æ•°ä½“ä¸­ï¼Œä½ çœ‹äº†ä¸¤è¡Œä»£ç ï¼Œä¸æƒ³çœ‹äº†ï¼Œè·³å‡ºå½“å‰å‡½æ•°ä½“å†…ï¼Œè¿”å›åˆ°è°ƒç”¨æ­¤å‡½æ•°çš„åœ°æ–¹ï¼Œå³ä½¿ç”¨æ­¤åŠŸèƒ½å³å¯ã€‚</li>
<li><code>Resume program</code>:ç»§ç»­æ¢å¤ç¨‹åºï¼Œç›´æ¥è¿è¡Œåˆ°ä¸‹ä¸€æ–­ç‚¹å¤„ã€‚è·³è¿‡ä¸æƒ³çœ‹çš„åœ°æ–¹ï¼Œç›´æ¥è®¾ç½®ä¸‹ä¸€ä¸ªæ–­ç‚¹ï¼Œç„¶å<code>Resume program</code>ã€‚</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorchå¸¸ç”¨ä»£ç æ®µ]]></title>
        <id>https://bailingnan.github.io/post/pytorch-chang-yong-dai-ma-duan</id>
        <link href="https://bailingnan.github.io/post/pytorch-chang-yong-dai-ma-duan">
        </link>
        <updated>2020-01-30T19:09:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1åŸºæœ¬é…ç½®">1.åŸºæœ¬é…ç½®</h1>
<h2 id="å¯¼å…¥åŒ…å’Œç‰ˆæœ¬æŸ¥è¯¢">å¯¼å…¥åŒ…å’Œç‰ˆæœ¬æŸ¥è¯¢</h2>
<pre><code class="language-Python">import torch
import torch.nn as nn
import torchvision
print(torch.__version__)# PyTorch version
print(torch.version.cuda)#Corresponding CUDA version
print(torch.backends.cudnn.version())#Corresponding cuDNN version
print(torch.cuda.get_device_name(0))#GPU type
</code></pre>
<h2 id="å¯å¤ç°æ€§">å¯å¤ç°æ€§</h2>
<p>åœ¨ç¡¬ä»¶è®¾å¤‡ï¼ˆCPUã€GPUï¼‰ä¸åŒæ—¶ï¼Œå®Œå…¨çš„å¯å¤ç°æ€§æ— æ³•ä¿è¯ï¼Œå³ä½¿éšæœºç§å­ç›¸åŒã€‚ä½†æ˜¯ï¼Œåœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œåº”è¯¥ä¿è¯å¯å¤ç°æ€§ã€‚å…·ä½“åšæ³•æ˜¯ï¼Œåœ¨ç¨‹åºå¼€å§‹çš„æ—¶å€™å›ºå®štorchçš„éšæœºç§å­ï¼ŒåŒæ—¶ä¹ŸæŠŠnumpyçš„éšæœºç§å­å›ºå®šã€‚</p>
<pre><code class="language-Python">np.random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
</code></pre>
<h2 id="æ˜¾å¡è®¾ç½®">æ˜¾å¡è®¾ç½®</h2>
<p>å¦‚æœåªéœ€è¦ä¸€å¼ æ˜¾å¡</p>
<pre><code class="language-Python"># Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
</code></pre>
<p>å¦‚æœéœ€è¦æŒ‡å®šå¤šå¼ æ˜¾å¡ï¼Œæ¯”å¦‚0ï¼Œ1å·æ˜¾å¡ã€‚</p>
<pre><code class="language-Python">import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
</code></pre>
<p>ä¹Ÿå¯ä»¥åœ¨å‘½ä»¤è¡Œè¿è¡Œä»£ç æ—¶è®¾ç½®æ˜¾å¡ï¼š</p>
<pre><code>CUDA_VISIBLE_DEVICES=0,1 python train.py
</code></pre>
<p>æ¸…é™¤æ˜¾å­˜:</p>
<pre><code class="language-Python">torch.cuda.empty_cache()
</code></pre>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨åœ¨å‘½ä»¤è¡Œé‡ç½®GPUçš„æŒ‡ä»¤ï¼š</p>
<pre><code>nvidia-smi --gpu-reset -i [gpu_id]
</code></pre>
<p>æˆ–åœ¨å‘½ä»¤è¡Œå¯ä»¥å…ˆä½¿ç”¨psæ‰¾åˆ°ç¨‹åºçš„PIDï¼Œå†ä½¿ç”¨killç»“æŸè¯¥è¿›ç¨‹</p>
<pre><code class="language-python">ps aux | grep python
kill -9 [pid]
</code></pre>
<h2 id="è®¾ç½®ä¸ºcudnn-benchmarkæ¨¡å¼">è®¾ç½®ä¸ºcuDNN benchmarkæ¨¡å¼</h2>
<p>Benchmarkæ¨¡å¼ä¼šæå‡è®¡ç®—é€Ÿåº¦ï¼Œä½†æ˜¯ç”±äºè®¡ç®—ä¸­æœ‰éšæœºæ€§ï¼Œæ¯æ¬¡ç½‘ç»œå‰é¦ˆç»“æœç•¥æœ‰å·®å¼‚ã€‚</p>
<pre><code class="language-python">torch.backends.cudnn.benchmark = True
</code></pre>
<p>å¦‚æœæƒ³è¦é¿å…è¿™ç§ç»“æœæ³¢åŠ¨ï¼Œè®¾ç½®</p>
<pre><code class="language-python">torch.backends.cudnn.deterministic = True
</code></pre>
<h1 id="å¼ é‡tensorå¤„ç†">å¼ é‡(Tensor)å¤„ç†</h1>
<h2 id="å¼ é‡åŸºæœ¬ä¿¡æ¯">å¼ é‡åŸºæœ¬ä¿¡æ¯</h2>
<pre><code class="language-Python">tensor = torch.randn(3,4,5)
print(tensor.type())  # æ•°æ®ç±»å‹
print(tensor.size())  # å¼ é‡çš„shapeï¼Œæ˜¯ä¸ªå…ƒç»„
print(tensor.dim())   # ç»´åº¦çš„æ•°é‡
</code></pre>
<h2 id="å‘½åå˜é‡">å‘½åå˜é‡</h2>
<pre><code class="language-Python"># åœ¨PyTorch 1.3ä¹‹å‰ï¼Œéœ€è¦ä½¿ç”¨æ³¨é‡Š
# Tensor[N, C, H, W]
images = torch.randn(32, 3, 56, 56)
images.sum(dim=1)
images.select(dim=1, index=0)

# PyTorch 1.3ä¹‹å
NCHW = [â€˜Nâ€™, â€˜Câ€™, â€˜Hâ€™, â€˜Wâ€™]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)
# ä¹Ÿå¯ä»¥è¿™ä¹ˆè®¾ç½®
tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))
# ä½¿ç”¨align_toå¯ä»¥å¯¹ç»´åº¦æ–¹ä¾¿åœ°æ’åº
tensor = tensor.align_to('N', 'C', 'H', 'W')
</code></pre>
<h2 id="æ•°æ®ç±»å‹è½¬æ¢">æ•°æ®ç±»å‹è½¬æ¢</h2>
<pre><code class="language-Python"># è®¾ç½®é»˜è®¤ç±»å‹ï¼Œpytorchä¸­çš„FloatTensorè¿œè¿œå¿«äºDoubleTensor
torch.set_default_tensor_type(torch.FloatTensor)

# ç±»å‹è½¬æ¢
tensor = tensor.cuda()
tensor = tensor.cpu()
tensor = tensor.float()
tensor = tensor.long()
</code></pre>
<h2 id="torchtensorä¸npndarrayè½¬æ¢">torch.Tensorä¸np.ndarrayè½¬æ¢</h2>
<p>é™¤äº†CharTensorï¼Œå…¶ä»–æ‰€æœ‰CPUä¸Šçš„å¼ é‡éƒ½æ”¯æŒè½¬æ¢ä¸ºnumpyæ ¼å¼ç„¶åå†è½¬æ¢å›æ¥ã€‚</p>
<pre><code class="language-Python">ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()
tensor = torch.from_numpy(ndarray.copy()).float() # If ndarray has negative stride.
</code></pre>
<h2 id="ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼">ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼</h2>
<p><code>value = torch.rand(1).item()</code></p>
<h2 id="å¼ é‡å½¢å˜">å¼ é‡å½¢å˜</h2>
<pre><code class="language-Python"># åœ¨å°†å·ç§¯å±‚è¾“å…¥å…¨è¿æ¥å±‚çš„æƒ…å†µä¸‹é€šå¸¸éœ€è¦å¯¹å¼ é‡åšå½¢å˜å¤„ç†ï¼Œ
# ç›¸æ¯”torch.viewï¼Œtorch.reshapeå¯ä»¥è‡ªåŠ¨å¤„ç†è¾“å…¥å¼ é‡ä¸è¿ç»­çš„æƒ…å†µã€‚
tensor = torch.rand(2,3,4)
shape = (6, 4)
tensor = torch.reshape(tensor, shape)
</code></pre>
<h2 id="å¼ é‡å¤åˆ¶">å¼ é‡å¤åˆ¶</h2>
<pre><code class="language-Python"># Operation                 |  New/Shared memory | Still in computation graph |
tensor.clone()            # |        New         |          Yes               |
tensor.detach()           # |      Shared        |          No                |
tensor.detach.clone()()   # |        New         |          No                |
</code></pre>
<h2 id="å¼ é‡æ‹¼æ¥">å¼ é‡æ‹¼æ¥</h2>
<pre><code class="language-Python">'''
æ³¨æ„torch.catå’Œtorch.stackçš„åŒºåˆ«åœ¨äºtorch.catæ²¿ç€ç»™å®šçš„ç»´åº¦æ‹¼æ¥ï¼Œ
è€Œtorch.stackä¼šæ–°å¢ä¸€ç»´ã€‚ä¾‹å¦‚å½“å‚æ•°æ˜¯3ä¸ª10x5çš„å¼ é‡ï¼Œtorch.catçš„ç»“æœæ˜¯30x5çš„å¼ é‡ï¼Œ
è€Œtorch.stackçš„ç»“æœæ˜¯3x10x5çš„å¼ é‡ã€‚
'''
tensor = torch.cat(list_of_tensors, dim=0)
tensor = torch.stack(list_of_tensors, dim=0)
</code></pre>
<h2 id="å°†æ•´æ•°æ ‡ç­¾è½¬ä¸ºone-hotç¼–ç ">å°†æ•´æ•°æ ‡ç­¾è½¬ä¸ºone-hotç¼–ç </h2>
<pre><code class="language-python"># pytorchçš„æ ‡è®°é»˜è®¤ä»0å¼€å§‹
tensor = torch.tensor([0, 2, 1, 3])
N = tensor.size(0)
num_classes = 4
one_hot = torch.zeros(N, num_classes).long()
one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())
</code></pre>
<h2 id="å¾—åˆ°éé›¶å…ƒç´ ">å¾—åˆ°éé›¶å…ƒç´ </h2>
<pre><code class="language-python">torch.nonzero(tensor)               # index of non-zero elements,åŒ…å«ç‚¹åæ ‡çš„åˆ—è¡¨å‘é‡
torch.nonzero(tensor==0)            # index of zero elements
torch.nonzero(tensor).size(0)       # number of non-zero elements
torch.nonzero(tensor == 0).size(0)  # number of zero elements
</code></pre>
<h2 id="åˆ¤æ–­ä¸¤ä¸ªå¼ é‡ç›¸ç­‰">åˆ¤æ–­ä¸¤ä¸ªå¼ é‡ç›¸ç­‰</h2>
<pre><code class="language-Python">torch.allclose(tensor1, tensor2)  # float tensor
torch.equal(tensor1, tensor2)     # int tensor
</code></pre>
<h2 id="å¼ é‡æ‰©å±•">å¼ é‡æ‰©å±•</h2>
<pre><code class="language-python"># Expand tensor of shape 64*512 to shape 64*512*7*7.
tensor = torch.rand(64,512)
torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)
</code></pre>
<h2 id="çŸ©é˜µä¹˜æ³•">çŸ©é˜µä¹˜æ³•</h2>
<pre><code class="language-python"># Matrix multiplcation: (m*n) * (n*p) * -&gt; (m*p).
result = torch.mm(tensor1, tensor2)

# Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)
result = torch.bmm(tensor1, tensor2)

# Element-wise multiplication.
result = tensor1 * tensor2
</code></pre>
<h2 id="è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»">è®¡ç®—ä¸¤ç»„æ•°æ®ä¹‹é—´çš„ä¸¤ä¸¤æ¬§å¼è·ç¦»</h2>
<p>åˆ©ç”¨broadcastæœºåˆ¶</p>
<pre><code class="language-python">dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))
</code></pre>
<h1 id="æ¨¡å‹å®šä¹‰å’Œæ“ä½œ">æ¨¡å‹å®šä¹‰å’Œæ“ä½œ</h1>
<h2 id="è®¡ç®—æ¨¡å‹æ•´ä½“å‚æ•°é‡">è®¡ç®—æ¨¡å‹æ•´ä½“å‚æ•°é‡</h2>
<pre><code class="language-python">num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())
</code></pre>
<h2 id="æŸ¥çœ‹ç½‘ç»œä¸­çš„å‚æ•°">æŸ¥çœ‹ç½‘ç»œä¸­çš„å‚æ•°</h2>
<p>å¯ä»¥é€šè¿‡model.state_dict()æˆ–è€…model.named_parameters()å‡½æ•°æŸ¥çœ‹ç°åœ¨çš„å…¨éƒ¨å¯è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬é€šè¿‡ç»§æ‰¿å¾—åˆ°çš„çˆ¶ç±»ä¸­çš„å‚æ•°ï¼‰</p>
<pre><code class="language-python">params = list(model.named_parameters())
(name, param) = params[28]
print(name)
print(param.grad)
print('-------------------------------------------------')
(name2, param2) = params[29]
print(name2)
print(param2.grad)
print('----------------------------------------------------')
(name1, param1) = params[30]
print(name1)
print(param1.grad)
</code></pre>
<h2 id="ç±»ä¼¼-keras-çš„-modelsummary-è¾“å‡ºæ¨¡å‹ä¿¡æ¯ä½¿ç”¨pytorch-summary">ç±»ä¼¼ Keras çš„ model.summary() è¾“å‡ºæ¨¡å‹ä¿¡æ¯ï¼ˆä½¿ç”¨pytorch-summary ï¼‰</h2>
<h2 id="æ¨¡å‹æƒé‡åˆå§‹åŒ–">æ¨¡å‹æƒé‡åˆå§‹åŒ–</h2>
<p>æ³¨æ„ model.modules() å’Œ model.children() çš„åŒºåˆ«ï¼šmodel.modules() ä¼šè¿­ä»£åœ°éå†æ¨¡å‹çš„æ‰€æœ‰å­å±‚ï¼Œè€Œ model.children() åªä¼šéå†æ¨¡å‹ä¸‹çš„ä¸€å±‚ã€‚</p>
<pre><code class="language-python"># Common practise for initialization.
for layer in model.modules():
    if isinstance(layer, torch.nn.Conv2d):
        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',
                                      nonlinearity='relu')
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.BatchNorm2d):
        torch.nn.init.constant_(layer.weight, val=1.0)
        torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.Linear):
        torch.nn.init.xavier_normal_(layer.weight)
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)

# Initialization with given tensor.
layer.weight = torch.nn.Parameter(tensor)
</code></pre>
<h2 id="æå–æ¨¡å‹ä¸­çš„æŸä¸€å±‚">æå–æ¨¡å‹ä¸­çš„æŸä¸€å±‚</h2>
<p>modules()ä¼šè¿”å›æ¨¡å‹ä¸­æ‰€æœ‰æ¨¡å—çš„è¿­ä»£å™¨ï¼Œå®ƒèƒ½å¤Ÿè®¿é—®åˆ°æœ€å†…å±‚ï¼Œæ¯”å¦‚self.layer1.conv1è¿™ä¸ªæ¨¡å—ï¼Œè¿˜æœ‰ä¸€ä¸ªä¸å®ƒä»¬ç›¸å¯¹åº”çš„æ˜¯name_children()å±æ€§ä»¥åŠnamed_modules(),è¿™ä¸¤ä¸ªä¸ä»…ä¼šè¿”å›æ¨¡å—çš„è¿­ä»£å™¨ï¼Œè¿˜ä¼šè¿”å›ç½‘ç»œå±‚çš„åå­—ã€‚</p>
<pre><code class="language-python"># å–æ¨¡å‹ä¸­çš„å‰ä¸¤å±‚
new_model = nn.Sequential(*list(model.children())[:2] 
# å¦‚æœå¸Œæœ›æå–å‡ºæ¨¡å‹ä¸­çš„æ‰€æœ‰å·ç§¯å±‚ï¼Œå¯ä»¥åƒä¸‹é¢è¿™æ ·æ“ä½œï¼š
for layer in model.named_modules():
    if isinstance(layer[1],nn.Conv2d):
         conv_model.add_module(layer[0],layer[1])
</code></pre>
<h2 id="éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹">éƒ¨åˆ†å±‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹</h2>
<p>æ³¨æ„å¦‚æœä¿å­˜çš„æ¨¡å‹æ˜¯ torch.nn.DataParallelï¼Œåˆ™å½“å‰çš„æ¨¡å‹ä¹Ÿéœ€è¦æ˜¯</p>
<pre><code class="language-python">model.load_state_dict(torch.load('model.pth'), strict=False)
</code></pre>
<h1 id="æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•">æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•</h1>
<h2 id="è‡ªå®šä¹‰loss">è‡ªå®šä¹‰loss</h2>
<p>ç»§æ‰¿torch.nn.Moduleç±»å†™è‡ªå·±çš„lossã€‚</p>
<pre><code class="language-python">class MyLoss(torch.nn.Moudle):
    def __init__(self):
        super(MyLoss, self).__init__()
        
    def forward(self, x, y):
        loss = torch.mean((x - y) ** 2)
        return loss
</code></pre>
<h2 id="æ ‡ç­¾å¹³æ»‘label-smoothing">æ ‡ç­¾å¹³æ»‘ï¼ˆlabel smoothingï¼‰</h2>
<p>å†™ä¸€ä¸ªlabel_smoothing.pyçš„æ–‡ä»¶ï¼Œç„¶ååœ¨è®­ç»ƒä»£ç é‡Œå¼•ç”¨ï¼Œç”¨LSRä»£æ›¿äº¤å‰ç†µæŸå¤±å³å¯ã€‚label_smoothing.pyå†…å®¹å¦‚ä¸‹ï¼š</p>
<pre><code class="language-python">import torch
import torch.nn as nn


class LSR(nn.Module):

    def __init__(self, e=0.1, reduction='mean'):
        super().__init__()

        self.log_softmax = nn.LogSoftmax(dim=1)
        self.e = e
        self.reduction = reduction
    
    def _one_hot(self, labels, classes, value=1):
        &quot;&quot;&quot;
            Convert labels to one hot vectors
        
        Args:
            labels: torch tensor in format [label1, label2, label3, ...]
            classes: int, number of classes
            value: label value in one hot vector, default to 1
        
        Returns:
            return one hot format labels in shape [batchsize, classes]
        &quot;&quot;&quot;

        one_hot = torch.zeros(labels.size(0), classes)

        #labels and value_added  size must match
        labels = labels.view(labels.size(0), -1)
        value_added = torch.Tensor(labels.size(0), 1).fill_(value)

        value_added = value_added.to(labels.device)
        one_hot = one_hot.to(labels.device)

        one_hot.scatter_add_(1, labels, value_added)

        return one_hot

    def _smooth_label(self, target, length, smooth_factor):
        &quot;&quot;&quot;convert targets to one-hot format, and smooth
        them.
        Args:
            target: target in form with [label1, label2, label_batchsize]
            length: length of one-hot format(number of classes)
            smooth_factor: smooth factor for label smooth
        
        Returns:
            smoothed labels in one hot format
        &quot;&quot;&quot;
        one_hot = self._one_hot(target, length, value=1 - smooth_factor)
        one_hot += smooth_factor / (length - 1)

        return one_hot.to(target.device)

    def forward(self, x, target):

        if x.size(0) != target.size(0):
            raise ValueError('Expected input batchsize ({}) to match target batch_size({})'
                    .format(x.size(0), target.size(0)))

        if x.dim() &lt; 2:
            raise ValueError('Expected input tensor to have least 2 dimensions(got {})'
                    .format(x.size(0)))

        if x.dim() != 2:
            raise ValueError('Only 2 dimension tensor are implemented, (got {})'
                    .format(x.size()))


        smoothed_target = self._smooth_label(target, x.size(1), self.e)
        x = self.log_softmax(x)
        loss = torch.sum(- x * smoothed_target, dim=1)

        if self.reduction == 'none':
            return loss
        
        elif self.reduction == 'sum':
            return torch.sum(loss)
        
        elif self.reduction == 'mean':
            return torch.mean(loss)
        
        else:
            raise ValueError('unrecognized option, expect reduction to be one of none, mean, sum')
</code></pre>
<p>æˆ–è€…ç›´æ¥åœ¨è®­ç»ƒæ–‡ä»¶é‡Œåšlabel smoothing</p>
<pre><code class="language-python">for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()
    N = labels.size(0)
    # C is the number of classes.
    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()
    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)

    score = model(images)
    log_prob = torch.nn.functional.log_softmax(score, dim=1)
    loss = -torch.sum(log_prob * smoothed_labels) / N
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()    
</code></pre>
<h2 id="l1-æ­£åˆ™åŒ–">L1 æ­£åˆ™åŒ–</h2>
<pre><code class="language-python">l1_regularization = torch.nn.L1Loss(reduction='sum')
loss = ...  # Standard cross-entropy loss
for param in model.parameters():
    loss += torch.sum(torch.abs(param))
loss.backward()
</code></pre>
<h2 id="ä¸å¯¹åç½®é¡¹è¿›è¡Œæƒé‡è¡°å‡weight-decay">ä¸å¯¹åç½®é¡¹è¿›è¡Œæƒé‡è¡°å‡ï¼ˆweight decayï¼‰</h2>
<p>pytorché‡Œçš„weight decayç›¸å½“äºl2æ­£åˆ™</p>
<pre><code class="language-python">bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')
others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')
parameters = [{'parameters': bias_list, 'weight_decay': 0},                
              {'parameters': others_list}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
</code></pre>
<h2 id="æ¢¯åº¦è£å‰ªgradient-clipping">æ¢¯åº¦è£å‰ªï¼ˆgradient clippingï¼‰</h2>
<pre><code class="language-python">torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)
</code></pre>
<h2 id="å¾—åˆ°å½“å‰å­¦ä¹ ç‡">å¾—åˆ°å½“å‰å­¦ä¹ ç‡</h2>
<pre><code class="language-python"># If there is one global learning rate (which is the common case).
lr = next(iter(optimizer.param_groups))['lr']

# If there are multiple learning rates for different layers.
all_lr = []
for param_group in optimizer.param_groups:
    all_lr.append(param_group['lr'])
</code></pre>
<p>å¦ä¸€ç§æ–¹æ³•ï¼Œåœ¨ä¸€ä¸ªbatchè®­ç»ƒä»£ç é‡Œï¼Œå½“å‰çš„lræ˜¯</p>
<pre><code class="language-python">optimizer.param_groups[0]['lr']
</code></pre>
<h2 id="å­¦ä¹ ç‡è¡°å‡">å­¦ä¹ ç‡è¡°å‡</h2>
<pre><code class="language-python"># Reduce learning rate when validation accuarcy plateau.
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)
for t in range(0, 80):
    train(...)
    val(...)
    scheduler.step(val_acc)

# Cosine annealing learning rate.
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)
# Reduce learning rate by 10 at given epochs.
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)
for t in range(0, 80):
    scheduler.step()    
    train(...)
    val(...)

# Learning rate warmup by 10 epochs.
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)
for t in range(0, 10):
    scheduler.step()
    train(...)
    val(...)
</code></pre>
<h2 id="ä¼˜åŒ–å™¨é“¾å¼æ›´æ–°">ä¼˜åŒ–å™¨é“¾å¼æ›´æ–°</h2>
<p>ä»1.4ç‰ˆæœ¬å¼€å§‹ï¼Œ<code>torch.optim.lr_scheduler</code> æ”¯æŒé“¾å¼æ›´æ–°ï¼ˆchainingï¼‰ï¼Œå³ç”¨æˆ·å¯ä»¥å®šä¹‰ä¸¤ä¸ª schedulersï¼Œå¹¶äº¤æ›¿åœ¨è®­ç»ƒä¸­ä½¿ç”¨ã€‚</p>
<pre><code class="language-python">import torch
from torch.optim import SGD
from torch.optim.lr_scheduler import ExponentialLR, StepLR
model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]
optimizer = SGD(model, 0.1)
scheduler1 = ExponentialLR(optimizer, gamma=0.9)
scheduler2 = StepLR(optimizer, step_size=3, gamma=0.1)
for epoch in range(4):
    print(epoch, scheduler2.get_last_lr()[0])
    optimizer.step()
    scheduler1.step()
    scheduler2.step()
</code></pre>
<h2 id="æ¨¡å‹è®­ç»ƒå¯è§†åŒ–">æ¨¡å‹è®­ç»ƒå¯è§†åŒ–</h2>
<p>PyTorchå¯ä»¥ä½¿ç”¨tensorboardæ¥å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚<br>
å®‰è£…å’Œè¿è¡ŒTensorBoardã€‚</p>
<pre><code class="language-python">pip install tensorboard
tensorboard --logdir=runs
</code></pre>
<p>ä½¿ç”¨SummaryWriterç±»æ¥æ”¶é›†å’Œå¯è§†åŒ–ç›¸åº”çš„æ•°æ®ï¼Œæ”¾äº†æ–¹ä¾¿æŸ¥çœ‹ï¼Œå¯ä»¥ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å¤¹ï¼Œæ¯”å¦‚'Loss/train'å’Œ'Loss/test'ã€‚</p>
<pre><code class="language-python">from torch.utils.tensorboard import SummaryWriter
import numpy as np

writer = SummaryWriter()

for n_iter in range(100):
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
</code></pre>
<h2 id="ä¿å­˜ä¸åŠ è½½æ–­ç‚¹">ä¿å­˜ä¸åŠ è½½æ–­ç‚¹</h2>
<p>æ³¨æ„ä¸ºäº†èƒ½å¤Ÿæ¢å¤è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦åŒæ—¶ä¿å­˜æ¨¡å‹å’Œä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼Œä»¥åŠå½“å‰çš„è®­ç»ƒè½®æ•°ã€‚</p>
<pre><code class="language-python">start_epoch = 0
# Load checkpoint.
if resume: # resumeä¸ºå‚æ•°ï¼Œç¬¬ä¸€æ¬¡è®­ç»ƒæ—¶è®¾ä¸º0ï¼Œä¸­æ–­å†è®­ç»ƒæ—¶è®¾ä¸º1
    model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    assert os.path.isfile(model_path)
    checkpoint = torch.load(model_path)
    best_acc = checkpoint['best_acc']
    start_epoch = checkpoint['epoch']
    model.load_state_dict(checkpoint['model'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    print('Load checkpoint at epoch {}.'.format(start_epoch))
    print('Best accuracy so far {}.'.format(best_acc))

# Train the model
for epoch in range(start_epoch, num_epochs): 
    ... 

    # Test the model
    ...
        
    # save checkpoint
    is_best = current_acc &gt; best_acc
    best_acc = max(current_acc, best_acc)
    checkpoint = {
        'best_acc': best_acc,
        'epoch': epoch + 1,
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict(),
    }
    model_path = os.path.join('model', 'checkpoint.pth.tar')
    best_model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    torch.save(checkpoint, model_path)
    if is_best:
        shutil.copy(model_path, best_model_path)
</code></pre>
<h1 id="å…¶ä»–æ³¨æ„äº‹é¡¹">å…¶ä»–æ³¨æ„äº‹é¡¹</h1>
<ol>
<li>å»ºè®®æœ‰å‚æ•°çš„å±‚å’Œæ±‡åˆï¼ˆpoolingï¼‰å±‚ä½¿ç”¨<code>torch.nn</code>æ¨¡å—å®šä¹‰ï¼Œæ¿€æ´»å‡½æ•°ç›´æ¥ä½¿ç”¨<code>torch.nn.functionalã€‚torch.nn</code>æ¨¡å—å’Œ<code>torch.nn.functional</code>çš„åŒºåˆ«åœ¨äºï¼Œ<code>torch.nn</code>æ¨¡å—åœ¨è®¡ç®—æ—¶åº•å±‚è°ƒç”¨äº†<code>torch.nn.functional</code>ï¼Œä½†<code>torch.nn</code>æ¨¡å—åŒ…æ‹¬è¯¥å±‚å‚æ•°ï¼Œè¿˜å¯ä»¥åº”å¯¹è®­ç»ƒå’Œæµ‹è¯•ä¸¤ç§ç½‘ç»œçŠ¶æ€ã€‚ä½¿ç”¨<code>torch.nn.functional</code>æ—¶è¦æ³¨æ„ç½‘ç»œçŠ¶æ€ï¼Œå¦‚</li>
</ol>
<pre><code class="language-python">def forward(self, x):
  ...
  x = torch.nn.functional.dropout(x, p=0.5, training=self.training)
</code></pre>
<ol start="2">
<li>ä¸è¦ä½¿ç”¨å¤ªå¤§çš„çº¿æ€§å±‚ã€‚å› ä¸ºnn.Linear(m,n)ä½¿ç”¨çš„æ˜¯O(mn)çš„å†…å­˜ï¼Œçº¿æ€§å±‚å¤ªå¤§å¾ˆå®¹æ˜“è¶…å‡ºç°æœ‰æ˜¾å­˜ã€‚</li>
<li>ä¸è¦åœ¨å¤ªé•¿çš„åºåˆ—ä¸Šä½¿ç”¨RNNã€‚å› ä¸ºRNNåå‘ä¼ æ’­ä½¿ç”¨çš„æ˜¯BPTTç®—æ³•ï¼Œå…¶éœ€è¦çš„å†…å­˜å’Œè¾“å…¥åºåˆ—çš„é•¿åº¦å‘ˆçº¿æ€§å…³ç³»ã€‚</li>
<li>model(x) å‰ç”¨ <code>model.train()</code> å’Œ <code>model.eval()</code> åˆ‡æ¢ç½‘ç»œçŠ¶æ€ã€‚</li>
<li>ä¸éœ€è¦è®¡ç®—æ¢¯åº¦çš„ä»£ç å—ç”¨ with torch.no_grad() åŒ…å«èµ·æ¥ã€‚</li>
<li><code>model.eval()</code> å’Œ <code>torch.no_grad()</code> çš„åŒºåˆ«åœ¨äºï¼Œ<code>model.eval()</code> æ˜¯å°†ç½‘ç»œåˆ‡æ¢ä¸ºæµ‹è¯•çŠ¶æ€ï¼Œä¾‹å¦‚ BN å’Œdropoutåœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µä½¿ç”¨ä¸åŒçš„è®¡ç®—æ–¹æ³•ã€‚<code>torch.no_grad()</code>æ˜¯å…³é—­ PyTorch å¼ é‡çš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ï¼Œä»¥å‡å°‘å­˜å‚¨ä½¿ç”¨å’ŒåŠ é€Ÿè®¡ç®—ï¼Œå¾—åˆ°çš„ç»“æœæ— æ³•è¿›è¡Œ <code>loss.backward()</code>ã€‚</li>
<li><code>model.zero_grad()</code>ä¼šæŠŠæ•´ä¸ªæ¨¡å‹çš„å‚æ•°çš„æ¢¯åº¦éƒ½å½’é›¶, è€Œ<code>optimizer.zero_grad()</code>åªä¼šæŠŠä¼ å…¥å…¶ä¸­çš„å‚æ•°çš„æ¢¯åº¦å½’é›¶ã€‚</li>
<li>torch.nn.CrossEntropyLoss çš„è¾“å…¥ä¸éœ€è¦ç»è¿‡ Softmaxã€‚torch.nn.CrossEntropyLoss ç­‰ä»·äº torch.nn.functional.log_softmax + torch.nn.NLLLossã€‚</li>
<li><code>loss.backward()</code>å‰ç”¨ <code>optimizer.zero_grad()</code> æ¸…é™¤ç´¯ç§¯æ¢¯åº¦ã€‚</li>
<li><code>torch.utils.data.DataLoader</code> ä¸­å°½é‡è®¾ç½® <code>pin_memory=True</code>ï¼Œå¯¹ç‰¹åˆ«å°çš„æ•°æ®é›†å¦‚ MNIST è®¾ç½® <code>pin_memory=False</code> åè€Œæ›´å¿«ä¸€äº›ã€‚<code>num_workers</code> çš„è®¾ç½®éœ€è¦åœ¨å®éªŒä¸­æ‰¾åˆ°æœ€å¿«çš„å–å€¼ã€‚</li>
<li>ç”¨ <code>del</code>åŠæ—¶åˆ é™¤ä¸ç”¨çš„ä¸­é—´å˜é‡ï¼ŒèŠ‚çº¦ GPU å­˜å‚¨ã€‚</li>
<li>ä½¿ç”¨ <code>inplace</code> æ“ä½œå¯èŠ‚çº¦ GPU å­˜å‚¨ï¼Œå¦‚</li>
</ol>
<pre><code class="language-python">x = torch.nn.functional.relu(x, inplace=True)
</code></pre>
<ol start="13">
<li>å‡å°‘ CPU å’Œ GPU ä¹‹é—´çš„æ•°æ®ä¼ è¾“ã€‚ä¾‹å¦‚å¦‚æœä½ æƒ³çŸ¥é“ä¸€ä¸ª epoch ä¸­æ¯ä¸ª mini-batch çš„ loss å’Œå‡†ç¡®ç‡ï¼Œå…ˆå°†å®ƒä»¬ç´¯ç§¯åœ¨ GPU ä¸­ç­‰ä¸€ä¸ª epoch ç»“æŸä¹‹åä¸€èµ·ä¼ è¾“å› CPU ä¼šæ¯”æ¯ä¸ª mini-batch éƒ½è¿›è¡Œä¸€æ¬¡ GPU åˆ° CPU çš„ä¼ è¾“æ›´å¿«ã€‚</li>
<li>ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•° <code>half()</code>ä¼šæœ‰ä¸€å®šçš„é€Ÿåº¦æå‡ï¼Œå…·ä½“æ•ˆç‡ä¾èµ–äº GPU å‹å·ã€‚éœ€è¦å°å¿ƒæ•°å€¼ç²¾åº¦è¿‡ä½å¸¦æ¥çš„ç¨³å®šæ€§é—®é¢˜ã€‚</li>
<li>æ—¶å¸¸ä½¿ç”¨ <code>assert tensor.size() == (N, D, H, W)</code> ä½œä¸ºè°ƒè¯•æ‰‹æ®µï¼Œç¡®ä¿å¼ é‡ç»´åº¦å’Œä½ è®¾æƒ³ä¸­ä¸€è‡´ã€‚</li>
<li>é™¤äº†æ ‡è®° y å¤–ï¼Œå°½é‡å°‘ä½¿ç”¨ä¸€ç»´å¼ é‡ï¼Œä½¿ç”¨ n*1 çš„äºŒç»´å¼ é‡ä»£æ›¿ï¼Œå¯ä»¥é¿å…ä¸€äº›æ„æƒ³ä¸åˆ°çš„ä¸€ç»´å¼ é‡è®¡ç®—ç»“æœã€‚</li>
<li>ç»Ÿè®¡ä»£ç å„éƒ¨åˆ†è€—æ—¶</li>
</ol>
<pre><code class="language-python">with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:
    ...
print(profile)

# æˆ–è€…åœ¨å‘½ä»¤è¡Œè¿è¡Œ
python -m torch.utils.bottleneck main.py
</code></pre>
<ol start="18">
<li>ä½¿ç”¨TorchSnooperæ¥è°ƒè¯•PyTorchä»£ç ï¼Œç¨‹åºåœ¨æ‰§è¡Œçš„æ—¶å€™ï¼Œå°±ä¼šè‡ªåŠ¨ print å‡ºæ¥æ¯ä¸€è¡Œçš„æ‰§è¡Œç»“æœçš„ tensor çš„å½¢çŠ¶ã€æ•°æ®ç±»å‹ã€è®¾å¤‡ã€æ˜¯å¦éœ€è¦æ¢¯åº¦çš„ä¿¡æ¯ã€‚</li>
</ol>
<pre><code class="language-python"># pip install torchsnooper
import torchsnooper

# å¯¹äºå‡½æ•°ï¼Œä½¿ç”¨ä¿®é¥°å™¨
@torchsnooper.snoop()

# å¦‚æœä¸æ˜¯å‡½æ•°ï¼Œä½¿ç”¨ with è¯­å¥æ¥æ¿€æ´» TorchSnooperï¼ŒæŠŠè®­ç»ƒçš„é‚£ä¸ªå¾ªç¯è£…è¿› with è¯­å¥ä¸­å»ã€‚
with torchsnooper.snoop():
    åŸæœ¬çš„ä»£ç 
</code></pre>
<ol start="19">
<li>æ¨¡å‹å¯è§£é‡Šæ€§ï¼Œä½¿ç”¨captumåº“</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linuxå¸¸ç”¨å‘½ä»¤]]></title>
        <id>https://bailingnan.github.io/post/linux-chang-yong-ming-ling</id>
        <link href="https://bailingnan.github.io/post/linux-chang-yong-ming-ling">
        </link>
        <updated>2020-01-22T08:16:23.000Z</updated>
        <content type="html"><![CDATA[<h1 id="ä¸€-linuxæ–‡ä»¶ä¸ç›®å½•">ä¸€ã€Linuxæ–‡ä»¶ä¸ç›®å½•</h1>
<ul>
<li>
<h2 id="11-linuxæ–‡ä»¶æƒé™æ¦‚å¿µ">1.1 Linuxæ–‡ä»¶æƒé™æ¦‚å¿µ</h2>
<ul>
<li>åˆ‡æ¢è‡³rootèº«ä»½:<code>su -</code></li>
<li>ç¦»å¼€rootèº«ä»½:<code>exit</code></li>
<li>æ–‡ä»¶åç¬¬ä¸€ä¸ªå­—ç¬¦ä¸º.çš„æ–‡ä»¶ä¸ºéšè—æ–‡ä»¶</li>
</ul>
</li>
<li>
<h2 id="12-linuxç›®å½•é…ç½®">1.2 Linuxç›®å½•é…ç½®</h2>
</li>
<li>
<p>FHSé’ˆå¯¹ç›®å½•æ ‘æ¶æ„ä»…å®šä¹‰å‡ºä¸‰å±‚ç›®å½•ä¸‹é¢åº”è¯¥æ”¾ç½®ä»€ä¹ˆæ•°æ®è€Œå·²ï¼Œåˆ†åˆ«æ˜¯ä¸‹é¢è¿™ä¸‰ä¸ªç›®å½•çš„å®šä¹‰ï¼š</p>
<ul>
<li><code>/</code>ï¼ˆroot, æ ¹ç›®å½•ï¼‰:ä¸å¼€æœºç³»ç»Ÿæœ‰å…³ï¼›</li>
<li><code>/usr</code> ï¼ˆunix software resourceï¼‰:ä¸è½¯ä»¶å®‰è£…/æ‰§è¡Œæœ‰å…³ï¼›</li>
<li><code>/var</code>ï¼ˆvariableï¼‰:ä¸ç³»ç»Ÿè¿è¡Œè¿‡ç¨‹æœ‰å…³ã€‚</li>
</ul>
</li>
<li>
<p>FHSè¦æ±‚æ ¹ç›®å½•ä¸­å¿…é¡»å­˜åœ¨çš„ç›®å½•:</p>
<ul>
<li>
<p><code>/bin</code>:ç³»ç»Ÿæœ‰å¾ˆå¤šæ”¾ç½®å¯æ‰§è¡Œæ–‡ä»¶çš„ç›®å½•ï¼Œä½†<code>/bin</code>æ¯”è¾ƒç‰¹æ®Šã€‚å› ä¸º<code>/bin</code>æ”¾ç½®çš„æ˜¯åœ¨ å•äººç»´æŠ¤æ¨¡å¼ä¸‹è¿˜èƒ½å¤Ÿè¢«æ“ä½œçš„æŒ‡ä»¤ã€‚ åœ¨<code>/bin</code>ä¸‹é¢çš„æŒ‡ä»¤å¯ä»¥è¢«rootä¸ä¸€èˆ¬å¸å·æ‰€ä½¿ç”¨ï¼Œä¸»è¦æœ‰ï¼šcat, chmod, chown, date, mv, mkdir, cp, bashç­‰ç­‰å¸¸ç”¨çš„æŒ‡ä»¤ã€‚</p>
</li>
<li>
<p><code>/boot</code>:ä¸»è¦åœ¨æ”¾ç½®å¼€æœºä¼šä½¿ç”¨åˆ°çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬ Linux æ ¸å¿ƒæ–‡ä»¶ä»¥åŠå¼€æœºèœå•ä¸å¼€æœºæ‰€éœ€é…ç½®æ–‡ä»¶ç­‰ç­‰Linux kernel å¸¸ç”¨çš„æ–‡ä»¶åä¸ºï¼švmlinuzï¼Œå¦‚æœä½¿ç”¨çš„æ˜¯ grub2 è¿™ä¸ªå¼€æœºç®¡ç†ç¨‹åºï¼Œ åˆ™è¿˜ä¼šå­˜åœ¨<code>/boot/grub2/</code>è¿™ä¸ªç›®å½•ã€‚</p>
</li>
<li>
<p><code>/dev</code>:å­˜æ”¾ç¡¬ä»¶ç›¸å…³çš„æ–‡ä»¶ã€‚åœ¨ Linux ç³»ç»Ÿä¸Šï¼Œä»»ä½•è®¾å¤‡ä¸å‘¨è¾¹è®¾å¤‡éƒ½æ˜¯ä»¥æ–‡ä»¶çš„å‹æ€å­˜åœ¨äºè¿™ä¸ªç›®å½•å½“ä¸­çš„ã€‚ä½ åªè¦é€šè¿‡å­˜å–è¿™ä¸ªç›®å½•ä¸‹é¢çš„æŸä¸ªæ–‡ä»¶ï¼Œå°±ç­‰äºå­˜å–æŸä¸ªè®¾å¤‡ã€‚æ¯”è¦é‡è¦çš„æ–‡ä»¶æœ‰<code>/dev/null</code>, <code>/dev/zero</code>, <code>/dev/tty</code>, <code>/dev/loop</code>, <code>/dev/sd</code>ç­‰ç­‰ã€‚</p>
</li>
<li>
<p><code>/etc</code>:å­˜æ”¾é…ç½®æ–‡ä»¶çš„ç›®å½•ã€‚ç³»ç»Ÿä¸»è¦çš„é…ç½®æ–‡ä»¶å‡ ä¹éƒ½æ”¾ç½®åœ¨è¿™ä¸ªç›®å½•å†…ï¼Œä¾‹å¦‚äººå‘˜çš„å¸å·å¯†ç æ¡£ã€å„ç§æœåŠ¡çš„å¯å§‹æ¡£ç­‰ç­‰ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè¿™ä¸ªç›®å½•ä¸‹çš„å„æ–‡ä»¶å±æ€§æ˜¯å¯ä»¥è®©ä¸€èˆ¬ä½¿ç”¨è€…æŸ¥é˜…çš„ï¼Œä½†æ˜¯åªæœ‰ root æœ‰æƒåŠ›ä¿®æ”¹ã€‚FHSå»ºè®®ä¸è¦æ”¾ç½®å¯æ‰§è¡Œæ–‡ä»¶ ï¼ˆbinaryï¼‰åœ¨è¿™ä¸ªç›®å½•ä¸­å–”ã€‚æ¯”è¾ƒé‡è¦çš„æ–‡ä»¶æœ‰ï¼š <code>/etc/modprobe.d/</code>, <code>/etc/passwd</code>, <code>/etc/fstab</code>, <code>/etc/issue</code>ç­‰ç­‰ã€‚å¦å¤– FHS è¿˜è§„èŒƒå‡ ä¸ªé‡è¦çš„ç›®å½•æœ€å¥½è¦å­˜åœ¨ <code>/etc/</code>ç›®å½•ä¸‹ï¼š</p>
<ul>
<li><code>/etc/opt</code>ï¼ˆå¿…è¦ï¼‰ï¼šè¿™ä¸ªç›®å½•åœ¨æ”¾ç½®ç¬¬ä¸‰æ–¹ååŠ›è½¯ä»¶ <code>/opt</code> çš„ç›¸å…³é…ç½®æ–‡ä»¶ã€‚</li>
<li><code>/etc/X11/</code>ï¼ˆå»ºè®®ï¼‰ï¼šä¸ X Window æœ‰å…³çš„å„ç§é…ç½®æ–‡ä»¶éƒ½åœ¨è¿™é‡Œï¼Œå°¤å…¶æ˜¯ xorg.conf è¿™ä¸ª X Server çš„é…ç½®æ–‡ä»¶ã€‚</li>
<li><code>/etc/sgml/</code>ï¼ˆå»ºè®®ï¼‰ï¼šä¸ SGML æ ¼å¼æœ‰å…³çš„å„é¡¹é…ç½®æ–‡ä»¶ã€‚</li>
<li><code>/etc/xml/</code>ï¼ˆå»ºè®®ï¼‰ï¼šä¸ XML æ ¼å¼æœ‰å…³çš„å„é¡¹é…ç½®æ–‡ä»¶ã€‚</li>
</ul>
</li>
<li>
<p><code>/lib</code>:ç³»ç»Ÿçš„å‡½æ•°åº“éå¸¸çš„å¤šï¼Œè€Œ<code>/lib</code>æ”¾ç½®çš„åˆ™æ˜¯åœ¨å¼€æœºæ—¶ä¼šç”¨åˆ°çš„å‡½æ•°åº“ï¼Œ ä»¥åŠ åœ¨<code>/bin</code>æˆ–<code>/sbin</code>ä¸‹é¢çš„æŒ‡ä»¤ä¼šè°ƒç”¨çš„å‡½æ•°åº“è€Œå·²ã€‚ ä»€ä¹ˆæ˜¯å‡½æ•°åº“å‘¢ï¼Ÿä½ å¯ä»¥å°† ä»–æƒ³æˆæ˜¯â€œå¤–æŒ‚â€ï¼ŒæŸäº›æŒ‡ä»¤å¿…é¡»è¦æœ‰è¿™äº›â€œå¤–æŒ‚â€æ‰èƒ½å¤Ÿé¡ºåˆ©å®Œæˆç¨‹åºçš„æ‰§è¡Œ ä¹‹æ„ã€‚ å¦å¤– FSH è¿˜è¦æ±‚ä¸‹é¢çš„ç›®å½•å¿…é¡»è¦å­˜åœ¨ï¼š<code>/lib/modules/</code>ï¼šè¿™ä¸ªç›®å½• ä¸»è¦æ”¾ç½®å¯æŠ½æ¢å¼çš„æ ¸å¿ƒç›¸å…³æ¨¡å—ï¼ˆé©±åŠ¨ç¨‹åºï¼‰</p>
</li>
<li>
<p><code>/media</code>:mediaæ˜¯â€œåª’ä½“â€çš„è‹±æ–‡ï¼Œé¡¾åæ€ä¹‰ï¼Œè¿™ä¸ª<code>/media</code>ä¸‹é¢æ”¾ç½®çš„å°±æ˜¯å¯ç§»é™¤çš„è®¾å¤‡ï¼ åŒ…æ‹¬è½¯ç›˜ã€å…‰ç›˜ã€DVDç­‰ç­‰è®¾å¤‡éƒ½æš‚æ—¶æŒ‚è½½äºæ­¤ã€‚å¸¸è§çš„æ–‡ä»¶å æœ‰ï¼š<code>/media/floppy</code>, <code>/media/cdrom</code>ç­‰ç­‰ã€‚</p>
</li>
<li>
<p><code>/mnt</code>:å¦‚æœä½ æƒ³è¦æš‚æ—¶æŒ‚è½½æŸäº›é¢å¤–çš„è®¾å¤‡ï¼Œä¸€èˆ¬å»ºè®®ä½ å¯ä»¥æ”¾ç½®åˆ°è¿™ä¸ªç›®å½•ä¸­ã€‚ åœ¨å¤æ—©æ—¶å€™ï¼Œè¿™ä¸ªç›®å½•çš„ç”¨é€”ä¸<code>/media</code>ç›¸åŒå•¦ï¼åªæ˜¯æœ‰äº†<code>/media</code>ä¹‹åï¼Œè¿™ä¸ª ç›®å½•å°±ç”¨æ¥æš‚æ—¶æŒ‚è½½ç”¨äº†ã€‚</p>
</li>
<li>
<p><code>/opt</code>:è¿™ä¸ªæ˜¯ç»™ç¬¬ä¸‰æ–¹ååŠ›è½¯ä»¶æ”¾ç½®çš„ç›®å½•ã€‚ä»€ä¹ˆæ˜¯ç¬¬ä¸‰æ–¹ååŠ›è½¯ä»¶å•Šï¼Ÿ ä¸¾ä¾‹æ¥è¯´ï¼ŒKDE è¿™ä¸ªæ¡Œé¢ç®¡ç†ç³»ç»Ÿæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„è®¡åˆ’ï¼Œä¸è¿‡ä»–å¯ä»¥å®‰è£…åˆ° Linux ç³»ç»Ÿä¸­ï¼Œå› æ­¤KDEçš„è½¯ä»¶å°±å»ºè®®æ”¾ç½®åˆ°æ­¤ç›®å½•ä¸‹äº†ã€‚ å¦å¤–ï¼Œå¦‚æœä½ æƒ³è¦è‡ªè¡Œå®‰è£…é¢å¤–çš„è½¯ä»¶ï¼ˆéåŸæœ¬çš„ distribution æä¾›çš„ï¼‰ï¼Œé‚£ä¹ˆä¹Ÿèƒ½å¤Ÿå°†ä½ çš„è½¯ä»¶å®‰è£…åˆ°è¿™é‡Œæ¥ã€‚ ä¸è¿‡ï¼Œä»¥å‰çš„ Linux ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬è¿˜æ˜¯ä¹ æƒ¯æ”¾ç½®åœ¨<code>/usr/local</code>ç›®å½•ä¸‹å‘¢ï¼</p>
</li>
<li>
<p><code>/run</code>:æ—©æœŸçš„ FHS è§„å®šç³»ç»Ÿå¼€æœºåæ‰€äº§ç”Ÿçš„å„é¡¹ä¿¡æ¯åº”è¯¥è¦æ”¾ç½®åˆ° <code>/var/run</code> ç›®å½•ä¸‹ï¼Œæ–°ç‰ˆçš„ FHS åˆ™è§„èŒƒåˆ° <code>/run</code> ä¸‹é¢ã€‚ ç”±äº <code>/run</code> å¯ä»¥ä½¿ç”¨å†…å­˜æ¥ä»¿çœŸï¼Œå› æ­¤æ€§èƒ½ä¸Šä¼šå¥½å¾ˆå¤šï¼</p>
</li>
<li>
<p><code>/sbin</code>:å­˜æ”¾ç®¡ç†å‘˜rootå¯ä»¥æ‰§è¡Œçš„å‘½ä»¤ã€‚Linux æœ‰éå¸¸å¤šæŒ‡ä»¤æ˜¯ç”¨æ¥è®¾ç½®ç³»ç»Ÿç¯å¢ƒçš„ï¼Œè¿™äº›æŒ‡ä»¤åªæœ‰ root æ‰èƒ½å¤Ÿåˆ©ç”¨ æ¥â€œè®¾ç½®â€ç³»ç»Ÿï¼Œå…¶ä»–ä½¿ç”¨è€…æœ€å¤šåªèƒ½ç”¨æ¥â€œæŸ¥è¯¢â€è€Œå·²ã€‚æ”¾åœ¨<code>/sbin</code>ä¸‹é¢çš„ä¸ºå¼€æœºè¿‡ç¨‹ä¸­æ‰€éœ€è¦çš„ï¼Œé‡Œé¢åŒ…æ‹¬äº†å¼€æœºã€ä¿®å¤ã€è¿˜åŸç³»ç»Ÿæ‰€éœ€è¦çš„æŒ‡ä»¤ã€‚è‡³äºæŸäº›æœåŠ¡å™¨è½¯ä»¶ç¨‹åºï¼Œä¸€èˆ¬åˆ™æ”¾ç½®åˆ°<code>/usr/sbin/</code>å½“ä¸­ã€‚è‡³äºæœ¬æœºè‡ªè¡Œå®‰è£…çš„è½¯ä»¶æ‰€äº§ç”Ÿçš„ç³»ç»Ÿå¯æ‰§è¡Œæ–‡ä»¶ï¼ˆsystem binaryï¼‰ï¼Œ åˆ™æ”¾ç½®åˆ°<code>/usr/local/sbin/</code> å½“ä¸­äº†ã€‚å¸¸è§çš„æŒ‡ä»¤åŒ…æ‹¬ï¼šfdisk, fsck, ifconfig, mkfsç­‰ç­‰ã€‚</p>
</li>
<li>
<p><code>/srv</code>:srv å¯ä»¥è§†ä¸ºâ€œserviceâ€çš„ç¼©å†™ï¼Œæ˜¯ä¸€äº›ç½‘ç»œæœåŠ¡å¯åŠ¨ä¹‹åï¼Œè¿™äº›æœåŠ¡æ‰€éœ€è¦å–ç”¨çš„æ•°æ®ç›®å½•ã€‚ å¸¸è§çš„æœåŠ¡ä¾‹å¦‚ WWW, FTP ç­‰ç­‰ã€‚ä¸¾ä¾‹æ¥è¯´ï¼ŒWWW æœåŠ¡å™¨éœ€è¦çš„ç½‘é¡µæ•°æ®å°±å¯ä»¥æ”¾ç½®åœ¨<code>/srv/www/</code>é‡Œé¢ã€‚ ä¸è¿‡ï¼Œç³»ç»Ÿçš„æœåŠ¡æ•°æ® å¦‚æœå°šæœªè¦æä¾›ç»™ç½‘é™…ç½‘ç»œä»»ä½•äººæµè§ˆçš„è¯ï¼Œé»˜è®¤è¿˜æ˜¯å»ºè®®æ”¾ç½®åˆ° <code>/var/lib</code>ä¸‹é¢å³å¯ã€‚</p>
</li>
<li>
<p><code>tem</code>:è¿™æ˜¯è®©ä¸€èˆ¬ä½¿ç”¨è€…æˆ–è€…æ˜¯æ­£åœ¨æ‰§è¡Œçš„ç¨‹åºæš‚æ—¶æ”¾ç½®æ–‡ä»¶çš„åœ°æ–¹ã€‚ è¿™ä¸ªç›®å½•æ˜¯ä»»ä½•äººéƒ½èƒ½å¤Ÿå­˜å–çš„ï¼Œæ‰€ä»¥ä½ éœ€è¦å®šæœŸçš„æ¸…ç†ä¸€ä¸‹ã€‚å½“ç„¶ï¼Œé‡è¦æ•°æ®ä¸å¯æ”¾ç½®åœ¨æ­¤ç›®å½•å•Šï¼ å› ä¸ºFHSç”šè‡³å»ºè®®åœ¨å¼€æœºæ—¶ï¼Œåº”è¯¥è¦å°†<code>/tmp</code>ä¸‹çš„æ•°æ®éƒ½åˆ é™¤å”·!</p>
</li>
<li>
<p><code>/var</code>:ç¬¬äºŒå±‚ FHS è®¾ç½®ï¼Œä¸»è¦ä¸ºæ”¾ç½®å˜åŠ¨æ€§çš„æ•°æ®ï¼Œåç»­ä»‹ç»ã€‚</p>
</li>
<li>
<p><code>/usr</code>:ç¬¬äºŒå±‚ FHS è®¾ç½®ï¼Œåç»­ä»‹ç»ã€‚</p>
</li>
</ul>
</li>
<li>
<p>FHS å»ºè®®æ ¹ç›®å½•ä¸­å¯ä»¥å­˜åœ¨çš„ç›®å½•ï¼š</p>
<ul>
<li><code>/home</code>ï¼šè¿™æ˜¯ç³»ç»Ÿé»˜è®¤çš„ä½¿ç”¨è€…ä¸»æ–‡ä»¶å¤¹ï¼ˆhome directoryï¼‰ã€‚åœ¨ä½ æ–°å¢ä¸€ä¸ªä¸€èˆ¬ä½¿ ç”¨è€…å¸å·æ—¶ï¼Œé»˜è®¤çš„ä½¿ç”¨è€…ä¸»æ–‡ä»¶å¤¹éƒ½ä¼šè§„èŒƒåˆ°è¿™é‡Œæ¥ã€‚</li>
<li><code>/lib&lt;equal&gt;</code>:ç”¨æ¥å­˜æ”¾ä¸ <code>/lib</code> ä¸åŒçš„æ ¼å¼çš„äºŒè¿›åˆ¶å‡½æ•°åº“ï¼Œä¾‹å¦‚æ”¯æŒ 64 ä½çš„ <code>/lib64</code> å‡½æ•°åº“ç­‰ã€‚</li>
<li><code>/root</code>:ç³»ç»Ÿç®¡ç†å‘˜ï¼ˆrootï¼‰çš„ä¸»æ–‡ä»¶å¤¹ã€‚ä¹‹æ‰€ä»¥æ”¾åœ¨è¿™é‡Œï¼Œæ˜¯å› ä¸ºå¦‚æœè¿›å…¥å•äººç»´æŠ¤æ¨¡å¼è€Œä»…æŒ‚è½½æ ¹ç›®å½•æ—¶ï¼Œ è¯¥ç›®å½•å°±èƒ½å¤Ÿæ‹¥æœ‰ root çš„ä¸»æ–‡ä»¶å¤¹ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼š å¸Œæœ› root çš„ä¸»æ–‡ä»¶å¤¹ä¸æ ¹ç›®å½•æ”¾ç½®åœ¨åŒä¸€ä¸ªåˆ†åŒºä¸­ã€‚</li>
<li><code>/lost+found</code>:è¿™ä¸ªç›®å½•æ˜¯ä½¿ç”¨æ ‡å‡†çš„ ext2/ext3/ext4 æ–‡ä»¶ç³»ç»Ÿæ ¼å¼æ‰ä¼šäº§ç”Ÿçš„ä¸€ä¸ªç›®å½•ï¼Œ ç›®çš„åœ¨äºå½“æ–‡ä»¶ç³»ç»Ÿå‘ç”Ÿé”™è¯¯æ—¶ï¼Œ å°†ä¸€äº›é—å¤±çš„ç‰‡æ®µæ”¾ç½®åˆ°è¿™ä¸ªç›®å½•ä¸‹ã€‚ ä¸è¿‡å¦‚æœä½¿ç”¨çš„æ˜¯ xfs æ–‡ä»¶ç³»ç»Ÿçš„è¯ï¼Œå°±ä¸ä¼šå­˜åœ¨è¿™ä¸ªç›®å½•äº†ï¼</li>
<li><code>/proc</code>:è¿™ä¸ªç›®å½•æœ¬èº«æ˜¯ä¸€ä¸ªâ€œè™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿï¼ˆvirtual filesystemï¼‰â€å–”ï¼ä»–æ”¾ç½®çš„æ•°æ®éƒ½æ˜¯åœ¨å†…å­˜å½“ä¸­ï¼Œ ä¾‹å¦‚ç³»ç»Ÿæ ¸å¿ƒã€è¡Œç¨‹ä¿¡æ¯ï¼ˆprocessï¼‰ã€å‘¨è¾¹è®¾å¤‡çš„çŠ¶æ€åŠç½‘ç»œçŠ¶æ€ç­‰ç­‰ã€‚å› ä¸ºè¿™ä¸ªç›®å½•ä¸‹çš„æ•°æ®éƒ½æ˜¯åœ¨å†…å­˜å½“ä¸­ï¼Œ æ‰€ä»¥æœ¬èº«ä¸å ä»»ä½•ç¡¬ç›˜ç©ºé—´å•Šï¼æ¯”è¾ƒé‡è¦çš„æ–‡ä»¶ä¾‹å¦‚ï¼š<code>/proc/cpuinfo</code>, <code>/proc/dma</code>, <code>/proc/interrupts</code>, <code>/proc/ioports</code>, <code>/proc/net/*</code> ç­‰ç­‰ã€‚</li>
<li><code>/sys</code>:è¿™ä¸ªç›®å½•å…¶å®è·Ÿ/procéå¸¸ç±»ä¼¼ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„æ–‡ä»¶ç³»ç»Ÿï¼Œä¸»è¦ä¹Ÿæ˜¯è®°å½• æ ¸å¿ƒä¸ç³»ç»Ÿç¡¬ä»¶ä¿¡æ¯è¾ƒç›¸å…³çš„ä¿¡æ¯ã€‚ åŒ…æ‹¬ç›®å‰å·²è½½å…¥çš„æ ¸å¿ƒæ¨¡å—ä¸æ ¸å¿ƒä¾¦æµ‹åˆ°çš„ç¡¬ä»¶è®¾å¤‡ä¿¡æ¯ç­‰ç­‰ã€‚è¿™ä¸ªç›®å½•åŒæ ·ä¸å ç¡¬ç›˜å®¹é‡å–”ï¼</li>
</ul>
</li>
<li>
<p>å› ä¸ºæ˜¯æ‰€æœ‰ç³»ç»Ÿé»˜è®¤çš„è½¯ä»¶ï¼ˆdistributionå‘å¸ƒè€…æä¾›çš„è½¯ä»¶ï¼‰éƒ½ä¼šæ”¾ç½®åˆ°<code>/usr</code>ä¸‹é¢ï¼Œå› æ­¤è¿™ä¸ªç›®å½•æœ‰ç‚¹ç±»ä¼¼ Windows ç³»ç»Ÿçš„â€œC:\Windows\ ï¼ˆå½“ä¸­çš„ä¸€éƒ¨ä»½ï¼‰ + C:\Program files\â€è¿™ä¸¤ä¸ªç›® å½•çš„ç»¼åˆä½“ï¼Œç³»ç»Ÿåˆšå®‰è£…å®Œæ¯•æ—¶ï¼Œè¿™ä¸ªç›®å½•ä¼šå ç”¨æœ€å¤šçš„ç¡¬ç›˜å®¹é‡ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œ<code>/usr</code>çš„æ¬¡ç›®å½• å»ºè®®æœ‰ä¸‹é¢è¿™äº›ï¼š</p>
</li>
<li>
<p>FHS è¦æ±‚å¿…é¡»è¦å­˜åœ¨çš„ç›®å½•:</p>
<ul>
<li><code>/usr/bin/</code>:æ‰€æœ‰ä¸€èˆ¬ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨çš„æŒ‡ä»¤éƒ½æ”¾åœ¨è¿™é‡Œï¼<code>/usr/bin</code> ä¸ <code>/bin</code> æ˜¯ä¸€æ¨¡ä¸€æ ·äº†ï¼å¦å¤–ï¼ŒFHS è¦æ±‚åœ¨æ­¤ç›®å½•ä¸‹ä¸åº”è¯¥æœ‰å­ç›®å½•ï¼</li>
<li><code>/usr/lib/</code>:åŸºæœ¬ä¸Šï¼Œä¸ <code>/lib</code> åŠŸèƒ½ç›¸åŒï¼Œæ‰€ä»¥ <code>/lib</code> å°±æ˜¯é“¾æ¥åˆ°æ­¤ç›®å½•ä¸­çš„ï¼</li>
<li><code>/usr/local/</code>:ç³»ç»Ÿç®¡ç†å‘˜åœ¨æœ¬æœºè‡ªè¡Œå®‰è£…è‡ªå·±ä¸‹è½½çš„è½¯ä»¶ï¼ˆé distribution é»˜è®¤æä¾›è€…ï¼‰ï¼Œå»ºè®®å®‰è£…åˆ°æ­¤ç›®å½•ï¼Œ è¿™æ ·ä¼šæ¯”è¾ƒä¾¿äºç®¡ç†ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œä½ çš„ distribution æä¾›çš„è½¯ä»¶è¾ƒæ—§ï¼Œä½ æƒ³å®‰è£…è¾ƒæ–°çš„è½¯ä»¶ä½†åˆä¸æƒ³ç§»é™¤æ—§ç‰ˆï¼Œæ­¤æ—¶ä½ å¯ä»¥å°†æ–°ç‰ˆè½¯ä»¶å®‰è£…äº<code>/usr/local/</code>ç›®å½•ä¸‹ï¼Œå¯ä¸åŸå…ˆçš„æ—§ç‰ˆè½¯ä»¶æœ‰åˆ†åˆ«å•¦ï¼ ä½ å¯ä»¥è‡ªè¡Œåˆ°<code>/usr/local</code>å»çœ‹çœ‹ï¼Œè¯¥ç›®å½•ä¸‹ä¹Ÿæ˜¯å…·æœ‰bin, etc, include, lib...çš„æ¬¡ç›®å½•å–”ï¼</li>
<li><code>/usr/sbin/</code>:éç³»ç»Ÿæ­£å¸¸è¿è¡Œæ‰€éœ€è¦çš„ç³»ç»ŸæŒ‡ä»¤ã€‚æœ€å¸¸è§çš„å°±æ˜¯æŸäº›ç½‘ç»œæœåŠ¡å™¨è½¯ä»¶ çš„æœåŠ¡æŒ‡ä»¤ï¼ˆdaemonï¼‰å•°ï¼ä¸è¿‡åŸºæœ¬åŠŸèƒ½ä¸ <code>/sbin</code> ä¹Ÿå·®ä¸å¤šï¼Œ å› æ­¤ç›®å‰ <code>/sbin</code> å°±æ˜¯é“¾æ¥åˆ°æ­¤ç›®å½•ä¸­çš„ã€‚</li>
<li><code>/usr/share/</code>:ä¸»è¦æ”¾ç½®åªè¯»æ¶æ„çš„æ•°æ®æ–‡ä»¶ï¼Œå½“ç„¶ä¹ŸåŒ…æ‹¬å…±äº«æ–‡ä»¶ã€‚åœ¨è¿™ä¸ªç›®å½•ä¸‹æ”¾ç½®çš„æ•°æ®å‡ ä¹æ˜¯ä¸åˆ†ç¡¬ä»¶æ¶æ„å‡å¯è¯»å–çš„æ•°æ®ï¼Œå› ä¸ºå‡ ä¹éƒ½æ˜¯æ–‡å­—æ–‡ä»¶å˜›ï¼åœ¨æ­¤ç›®å½•ä¸‹å¸¸è§çš„è¿˜æœ‰è¿™äº›æ¬¡ç›®å½•ï¼š
<ul>
<li><code>/usr/share/man</code>ï¼šçº¿ä¸Šè¯´æ˜æ–‡æ¡£ã€‚</li>
<li><code>/usr/share/doc</code>ï¼šè½¯ä»¶æ‚é¡¹çš„æ–‡ä»¶è¯´æ˜ã€‚</li>
<li><code>/usr/share/zoneinfo</code>ï¼šä¸æ—¶åŒºæœ‰å…³çš„æ—¶åŒºæ–‡ä»¶ã€‚</li>
</ul>
</li>
</ul>
</li>
<li>
<p>FHS å»ºè®®å¯ä»¥å­˜åœ¨çš„ç›®å½•ï¼š</p>
<ul>
<li><code>/usr/games/</code>:ä¸æ¸¸æˆæ¯”è¾ƒç›¸å…³çš„æ•°æ®æ”¾ç½®å¤„ã€‚</li>
<li><code>/usr/include/</code>:c/c++ç­‰ç¨‹åºè¯­è¨€çš„æ–‡ä»¶å¼€å§‹ï¼ˆheaderï¼‰ä¸åŒ…å«æ¡£ï¼ˆincludeï¼‰æ”¾ç½®å¤„ï¼Œ å½“æˆ‘ä»¬ä»¥tarballæ–¹å¼ ï¼ˆ*.tar.gz çš„æ–¹å¼å®‰è£…è½¯ä»¶ï¼‰å®‰è£…æŸäº›æ•°æ®æ—¶ï¼Œä¼šä½¿ç”¨åˆ°é‡Œå¤´çš„è®¸å¤šåŒ…å«æ¡£å–”ï¼</li>
<li><code>/usr/libexec/</code>:æŸäº›ä¸è¢«ä¸€èˆ¬ä½¿ç”¨è€…æƒ¯ç”¨çš„å¯æ‰§è¡Œæ–‡ä»¶æˆ–è„šæœ¬ï¼ˆscriptï¼‰ç­‰ç­‰ï¼Œéƒ½ä¼šæ”¾ ç½®åœ¨æ­¤ç›®å½•ä¸­ã€‚ä¾‹å¦‚å¤§éƒ¨åˆ†çš„ X çª—å£ä¸‹é¢çš„æ“ä½œæŒ‡ä»¤ï¼Œ å¾ˆå¤šéƒ½æ˜¯æ”¾åœ¨æ­¤ç›®å½•ä¸‹çš„ã€‚</li>
<li><code>/usr/lib&lt;qual&gt;/</code>:ä¸ <code>/lib&lt;qual&gt;/</code>åŠŸèƒ½ç›¸åŒï¼Œå› æ­¤ç›®å‰ <code>/lib&lt;qual&gt;</code> å°±æ˜¯é“¾æ¥åˆ°æ­¤ç›®å½•ä¸­ã€‚</li>
<li><code>/usr/src/</code>:ä¸€èˆ¬æºä»£ç å»ºè®®æ”¾ç½®åˆ°è¿™é‡Œï¼Œsrcæœ‰sourceçš„æ„æ€ã€‚è‡³äºæ ¸å¿ƒæºä»£ç åˆ™å»ºè®®æ”¾ç½®åˆ°<code>/usr/src/linux/</code>ç›®å½•ä¸‹ã€‚</li>
</ul>
</li>
<li>
<p>å¦‚æœ<code>/usr</code>æ˜¯å®‰è£…æ—¶ä¼šå ç”¨è¾ƒå¤§ç¡¬ç›˜å®¹é‡çš„ç›®å½•ï¼Œé‚£ä¹ˆ<code>/var</code>å°±æ˜¯åœ¨ç³»ç»Ÿè¿è¡Œåæ‰ä¼šæ¸æ¸å ç”¨ç¡¬ç›˜å®¹é‡çš„ç›®å½•ã€‚ å› ä¸º<code>/var</code>ç›®å½•ä¸»è¦é’ˆå¯¹å¸¸æ€æ€§å˜åŠ¨çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬é«˜é€Ÿç¼“å­˜ï¼ˆcacheï¼‰ã€ç™»å½•æ–‡ä»¶ ï¼ˆlog fileï¼‰ä»¥åŠæŸäº›è½¯ä»¶è¿è¡Œæ‰€äº§ç”Ÿçš„æ–‡ä»¶ï¼Œ åŒ…æ‹¬ç¨‹åºæ–‡ä»¶ï¼ˆlock file, run fileï¼‰ï¼Œæˆ–è€…ä¾‹å¦‚ MySQLæ•°æ®åº“çš„æ–‡ä»¶ç­‰ç­‰ã€‚å¸¸è§çš„æ¬¡ç›®å½•æœ‰ï¼š</p>
</li>
<li>
<p>FHS è¦æ±‚å¿…é¡»è¦å­˜åœ¨çš„ç›®å½•:</p>
<ul>
<li><code>/var/cache/</code>:åº”ç”¨ç¨‹åºæœ¬èº«è¿è¡Œè¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿçš„ä¸€äº›æš‚å­˜ç›˜ï¼›</li>
<li><code>/var/lib/</code>:ç¨‹åºæœ¬èº«æ‰§è¡Œçš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦ä½¿ç”¨åˆ°çš„æ•°æ®æ–‡ä»¶æ”¾ç½®çš„ç›®å½•ã€‚åœ¨æ­¤ç›®å½•ä¸‹å„è‡ªçš„è½¯ä»¶åº”è¯¥è¦æœ‰å„è‡ªçš„ç›®å½•ã€‚ä¸¾ä¾‹æ¥è¯´ï¼ŒMySQLçš„æ•°æ®åº“æ”¾ç½® åˆ°<code>/var/lib/mysql/</code>è€Œrpmçš„æ•°æ®åº“åˆ™æ”¾åˆ°<code>/var/lib/rpm</code>å»ï¼</li>
<li><code>/var/lock/</code>:æŸäº›è®¾å¤‡æˆ–è€…æ˜¯æ–‡ä»¶èµ„æºä¸€æ¬¡åªèƒ½è¢«ä¸€ä¸ªåº”ç”¨ç¨‹åºæ‰€ä½¿ç”¨ï¼Œå¦‚æœåŒæ—¶æœ‰ä¸¤ä¸ªç¨‹åºä½¿ç”¨è¯¥è®¾å¤‡æ—¶ï¼Œå°±å¯èƒ½äº§ç”Ÿä¸€äº›é”™è¯¯çš„çŠ¶å†µï¼Œå› æ­¤å°±å¾—è¦å°†è¯¥è®¾å¤‡ä¸Šé”ï¼ˆlockï¼‰ï¼Œä»¥ç¡®ä¿è¯¥è®¾å¤‡åªä¼šç»™å•ä¸€è½¯ä»¶æ‰€ä½¿ç”¨ã€‚ç›®å‰æ­¤ç›®å½•ä¹Ÿå·²ç»æŒªåˆ° <code>/run/lock</code>ä¸­ï¼</li>
<li><code>/var/log/</code>:é‡è¦åˆ°ä¸è¡Œï¼è¿™æ˜¯ç™»å½•æ–‡ä»¶æ”¾ç½®çš„ç›®å½•ï¼é‡Œé¢æ¯”è¾ƒé‡è¦çš„æ–‡ä»¶ å¦‚<code>/var/log/messages</code>, <code>/var/log/wtmp</code>ï¼ˆè®°å½•ç™»é™†è€…çš„ä¿¡æ¯ï¼‰ç­‰ã€‚</li>
<li><code>/var/mail/</code>:æ”¾ç½®ä¸ªäººç”µå­é‚®ä»¶ä¿¡ç®±çš„ç›®å½•ï¼Œä¸è¿‡è¿™ä¸ªç›®å½•ä¹Ÿè¢«æ”¾ç½®åˆ°<code>/var/spool/mail/</code> ç›®å½•ä¸­ï¼ é€šå¸¸è¿™ä¸¤ä¸ªç›®å½•æ˜¯äº’ä¸ºé“¾æ¥æ–‡ä»¶å•¦ï¼</li>
<li><code>/var/run/</code>:æŸäº›ç¨‹åºæˆ–è€…æ˜¯æœåŠ¡å¯åŠ¨åï¼Œä¼šå°†ä»–ä»¬çš„PIDæ”¾ç½®åœ¨è¿™ä¸ªç›®å½•ä¸‹å–”ï¼è‡³äº PIDçš„æ„ä¹‰æˆ‘ä»¬ä¼šåœ¨åç»­ç« èŠ‚æåˆ°çš„ã€‚ä¸ <code>/run</code> ç›¸åŒï¼Œè¿™ä¸ªç›®å½•é“¾æ¥åˆ° <code>/run</code> å»äº†ï¼</li>
<li><code>/var/spool/</code>:è¿™ä¸ªç›®å½•é€šå¸¸æ”¾ç½®ä¸€äº›ä¼«åˆ—æ•°æ®ï¼Œæ‰€è°“çš„â€œä¼«åˆ—â€å°±æ˜¯æ’é˜Ÿç­‰å¾…å…¶ä»–ç¨‹åºä½¿ç”¨çš„æ•°æ®å•¦ï¼ è¿™äº›æ•°æ®è¢«ä½¿ç”¨åé€šå¸¸éƒ½ä¼šè¢«åˆ é™¤ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œç³»ç»Ÿæ”¶åˆ°æ–°ä¿¡ä¼šæ”¾ç½®åˆ°<code>/var/spool/mail/</code>ä¸­ï¼Œ ä½†ä½¿ç”¨è€…æ”¶ä¸‹è¯¥ä¿¡ä»¶åè¯¥å°ä¿¡åŸåˆ™ä¸Šå°±ä¼š è¢«åˆ é™¤ã€‚ä¿¡ä»¶å¦‚æœæš‚æ—¶å¯„ä¸å‡ºå»ä¼šè¢«æ”¾åˆ°<code>/var/spool/mqueue/</code>ä¸­ï¼Œ ç­‰åˆ°è¢«é€å‡ºåå°±è¢«åˆ é™¤ã€‚å¦‚æœæ˜¯å·¥ä½œè°ƒåº¦æ•°æ®ï¼ˆcrontabï¼‰ï¼Œå°±ä¼šè¢«æ”¾ç½®åˆ°<code>/var/spool/cron/</code>ç›®å½•ä¸­ï¼</li>
</ul>
</li>
<li>
<h2 id="13-æ–‡ä»¶ä¸ç›®å½•ç®¡ç†">1.3 æ–‡ä»¶ä¸ç›®å½•ç®¡ç†</h2>
<ul>
<li>
<p>ç½‘ç»œæ–‡ä»¶å¸¸å¸¸æåˆ°ç±»ä¼¼â€œ./run.shâ€ä¹‹ç±»çš„æ•°æ®ï¼Œè¿™ä¸ªæŒ‡ä»¤çš„æ„ä¹‰ä¸ºä½•ï¼Ÿç­”ï¼šç”±äºæŒ‡ä»¤çš„æ‰§è¡Œéœ€è¦å˜é‡ï¼ˆbashç« èŠ‚æ‰ä¼šæåˆ°ï¼‰çš„æ”¯æŒï¼Œè‹¥ä½ çš„å¯æ‰§è¡Œæ–‡ä»¶æ”¾ç½®åœ¨æœ¬ç›®å½•ï¼Œå¹¶ä¸”æœ¬ç›®å½•å¹¶éæ­£è§„çš„å¯æ‰§è¡Œæ–‡ä»¶ç›®å½•ï¼ˆ/bin, /usr/binç­‰ä¸ºæ­£è§„ï¼‰ï¼Œæ­¤æ—¶è¦æ‰§è¡ŒæŒ‡ä»¤å°±å¾—è¦ä¸¥æ ¼æŒ‡å®šè¯¥å¯æ‰§è¡Œæ–‡ä»¶ã€‚â€œ./â€ä»£è¡¨â€œæœ¬ç›®å½•â€çš„æ„æ€ï¼Œæ‰€ä»¥â€œ./run.shâ€ä»£è¡¨â€œæ‰§è¡Œæœ¬ç›®å½•ä¸‹ï¼Œåä¸ºrun.shçš„æ–‡ä»¶â€ã€‚</p>
</li>
<li>
<p>cd ï¼ˆchange directory, å˜æ¢ç›®å½•ï¼‰</p>
<ul>
<li><code>cd ~dmtsai</code>: ä»£è¡¨å»åˆ° dmtsai è¿™ä¸ªä½¿ç”¨è€…çš„ä¸»æ–‡ä»¶å¤¹ï¼Œäº¦å³ <code>/home/dmtsai</code></li>
<li><code>cd ~</code>:è¡¨ç¤ºå›åˆ°è‡ªå·±çš„ä¸»æ–‡ä»¶å¤¹ï¼Œäº¦å³æ˜¯ <code>/root</code> è¿™ä¸ªç›®å½•</li>
<li><code>cd</code>:æ²¡æœ‰åŠ ä¸Šä»»ä½•è·¯å¾„ï¼Œä¹Ÿè¿˜æ˜¯ä»£è¡¨å›åˆ°è‡ªå·±ä¸»æ–‡ä»¶å¤¹çš„æ„æ€</li>
<li><code>cd ..</code>:è¡¨ç¤ºå»åˆ°ç›®å‰çš„ä¸Šå±‚ç›®å½•</li>
<li><code>cd -</code>:è¡¨ç¤ºå›åˆ°åˆšåˆšçš„é‚£ä¸ªç›®å½•</li>
<li><code>cd ../postfix</code>:ç”±<code>/var/spool/mail</code> å»åˆ°<code>/var/spool/postfix</code></li>
</ul>
</li>
<li>
<p>ä¸€ç™»é™†Linuxç³»ç»Ÿåï¼Œæ¯ä¸ªå¸å·éƒ½ä¼šåœ¨è‡ªå·±å¸å·çš„ä¸»æ–‡ä»¶å¤¹ä¸­(<code>/home</code>)ã€‚</p>
</li>
<li>
<p>pwd ï¼ˆæ˜¾ç¤ºç›®å‰æ‰€åœ¨çš„ç›®å½•ï¼‰</p>
<ul>
<li><code>pwd [-P]</code>ğŸ˜› ï¼šæ˜¾ç¤ºå‡ºç¡®å®çš„è·¯å¾„ï¼Œè€Œéä½¿ç”¨é“¾æ¥ ï¼ˆlinkï¼‰ è·¯å¾„ã€‚åŠ ä¸Š <code>pwd -P</code> çš„é€‰é¡¹åï¼Œä¼šä¸ä»¥é“¾æ¥æ–‡ä»¶çš„æ•°æ®æ˜¾ç¤ºï¼Œè€Œæ˜¯æ˜¾ç¤ºæ­£ç¡®çš„å®Œæ•´è·¯å¾„ã€‚</li>
<li><code>pwd</code>:å•çº¯æ˜¾ç¤ºå‡ºç›®å‰çš„å·¥ä½œç›®å½•ã€‚</li>
</ul>
</li>
<li>
<p>mkdir ï¼ˆåˆ›å»ºæ–°ç›®å½•ï¼‰</p>
<ul>
<li><code>mkdir [-mp] ç›®å½•åç§°</code>:
<ul>
<li><code>-m</code> ï¼šè®¾ç½®æ–‡ä»¶çš„æƒé™å–”ï¼ç›´æ¥è®¾ç½®ï¼Œä¸éœ€è¦çœ‹é»˜è®¤æƒé™ ï¼ˆumaskï¼‰ çš„è„¸è‰²ï½</li>
<li><code>-p</code> ï¼šå¸®åŠ©ä½ ç›´æ¥å°†æ‰€éœ€è¦çš„ç›®å½•ï¼ˆåŒ…å«ä¸Šå±‚ç›®å½•ï¼‰é€’å›åˆ›å»ºèµ·æ¥ï¼</li>
<li>ç¤ºä¾‹:
<ul>
<li><code>mkdir test1/test2/test3/test4</code>:é”™è¯¯ã€‚mkdir: cannot create directory â€˜test1/test2/test3/test4â€™: No such file or directory</li>
<li><code>mkdir -p test1/test2/test3/test4</code>:æ­£ç¡®ã€‚</li>
</ul>
</li>
</ul>
</li>
<li>rmdir ï¼ˆåˆ é™¤â€œç©ºâ€çš„ç›®å½•ï¼‰
<ul>
<li><code>rmdir [-p] ç›®å½•åç§°</code>:
<ul>
<li><code>-p</code> ï¼šè¿åŒâ€œä¸Šå±‚â€â€œç©ºçš„â€ç›®å½•ä¹Ÿä¸€èµ·åˆ é™¤ã€‚</li>
</ul>
</li>
<li>ç¤ºä¾‹:
<ul>
<li><code>rmdir test1</code>:rmdir: failed to remove â€˜test1â€™: Directory not empty</li>
<li><code>rmdir -p test1/test2/test3/test4</code>:åˆ©ç”¨ <code>-p</code> è¿™ä¸ªé€‰é¡¹ï¼Œç«‹åˆ»å°±å¯ä»¥å°† <code>test1/test2/test3/test4</code> ä¸€æ¬¡åˆ é™¤,åŒ…æ‹¬test1</li>
<li>å¦‚æœè¦å°†éç©ºç›®å½•ä¸‹çš„ä¸œè¥¿éƒ½æ€æ‰å‘¢ï¼Ÿï¼ è¿™ä¸ªæ—¶å€™å°±å¿…é¡»ä½¿ç”¨<code>rm -r ç›®å½•åç§°</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>æ–‡ä»¶ä¸ç›®å½•çš„æ£€è§†ï¼š ls</p>
<ul>
<li><code>ls [-aAdfFhilnrRSt] æ–‡ä»¶åæˆ–ç›®å½•åç§°</code>
<ul>
<li><code>-a</code> ï¼šå…¨éƒ¨çš„æ–‡ä»¶ï¼Œè¿åŒéšè—æ–‡ä»¶ï¼ˆ å¼€å¤´ä¸º . çš„æ–‡ä»¶ï¼‰ ä¸€èµ·åˆ—å‡ºæ¥ï¼ˆå¸¸ç”¨ï¼‰</li>
<li><code>-d</code> ï¼šä»…åˆ—å‡ºç›®å½•æœ¬èº«ï¼Œè€Œä¸æ˜¯åˆ—å‡ºç›®å½•å†…çš„æ–‡ä»¶æ•°æ®ï¼ˆå¸¸ç”¨ï¼‰</li>
<li><code>-l</code> ï¼šé•¿æ•°æ®ä¸²è¡Œå‡ºï¼ŒåŒ…å«æ–‡ä»¶çš„å±æ€§ä¸æƒé™ç­‰ç­‰æ•°æ®ï¼ˆå¸¸ç”¨ï¼‰</li>
<li>ç¤ºä¾‹ï¼š
<ul>
<li><code>ls -al ~</code>: å°†ä¸»æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åˆ—å‡ºæ¥ï¼ˆå«å±æ€§ä¸éšè—æ–‡ä»¶ï¼‰</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>cp ï¼ˆå¤åˆ¶æ–‡ä»¶æˆ–ç›®å½•ï¼‰</p>
<ul>
<li><code>cp [-adfilprsu] æ¥æºæ–‡ä»¶ï¼ˆsourceï¼‰ ç›®æ ‡æ–‡ä»¶ï¼ˆdestinationï¼‰</code></li>
<li><code>cp [options] source1 source2 source3 .... directory</code>
<ul>
<li><code>-a</code> ï¼šç›¸å½“äº -dr --preserve=all çš„æ„æ€ï¼Œè‡³äº dr è¯·å‚è€ƒä¸‹åˆ—è¯´æ˜ï¼›ï¼ˆå¸¸ç”¨ï¼‰</li>
<li><code>-i</code> ï¼šè‹¥ç›®æ ‡æ–‡ä»¶ï¼ˆdestinationï¼‰å·²ç»å­˜åœ¨æ—¶ï¼Œåœ¨è¦†ç›–æ—¶ä¼šå…ˆè¯¢é—®åŠ¨ä½œçš„è¿›è¡Œï¼ˆå¸¸ç”¨ï¼‰</li>
<li><code>-r</code> ï¼šé€’å›æŒç»­å¤åˆ¶ï¼Œç”¨äºç›®å½•çš„å¤åˆ¶è¡Œä¸ºï¼›ï¼ˆå¸¸ç”¨ï¼‰</li>
<li><code>-p</code> ï¼šè¿åŒæ–‡ä»¶çš„å±æ€§ï¼ˆæƒé™ã€ç”¨æˆ·ã€æ—¶é—´ï¼‰ä¸€èµ·å¤åˆ¶è¿‡å»ï¼Œè€Œéä½¿ç”¨é»˜è®¤å±æ€§ï¼ˆå¤‡ä»½å¸¸ç”¨ï¼‰ï¼›</li>
<li><code>--preserve=all</code> ï¼šé™¤äº† -p çš„æƒé™ç›¸å…³å‚æ•°å¤–ï¼Œè¿˜åŠ å…¥ SELinux çš„å±æ€§, links, xattr ç­‰ä¹Ÿå¤åˆ¶äº†ã€‚</li>
<li>å¦‚æœæ¥æºæ–‡ä»¶æœ‰ä¸¤ä¸ªä»¥ä¸Šï¼Œåˆ™æœ€åä¸€ä¸ªç›®çš„æ–‡ä»¶ä¸€å®šè¦æ˜¯â€œç›®å½•â€æ‰è¡Œï¼</li>
<li>å¦‚æœç›®æ ‡ç›®å½•æˆ–è€…ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ç›¸å½“äºé‡å‘½åã€‚</li>
<li>ç¤ºä¾‹
<ul>
<li><code>cp ~/.bashrc /tmp/bashrc</code>:å°†ä¸»æ–‡ä»¶å¤¹ä¸‹çš„ .bashrc å¤åˆ¶åˆ° <code>/tmp</code> ä¸‹ï¼Œå¹¶æ›´åä¸º bashrc</li>
<li><code>cp -i ~/.bashrc /tmp/bashrc</code>:cp: overwrite <code>/tmp/bashrc'? nä¸è¦†ç›–ï¼Œyä¸ºè¦†ç›–ï¼Œé‡å¤ä½œä¸¤æ¬¡åŠ¨ä½œï¼Œç”±äº</code>/tmp<code>ä¸‹é¢å·²ç»å­˜åœ¨ bashrc äº†ï¼ŒåŠ ä¸Š</code>-i` é€‰é¡¹åï¼Œåˆ™åœ¨è¦†ç›–å‰ä¼šè¯¢é—®ä½¿ç”¨è€…æ˜¯å¦ç¡®å®šï¼å¯ä»¥æŒ‰ä¸‹ n æˆ–è€… y æ¥äºŒæ¬¡ç¡®è®¤</li>
<li><code>cp /var/log/wtmp .</code>:å¤åˆ¶åˆ°å½“å‰ç›®å½•</li>
<li><code>cp /etc/ /tmp</code>:å¤åˆ¶ <code>/etc/</code> è¿™ä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹åˆ° <code>/tmp</code> ä¸‹é¢ï¼Œcp: omitting directory <code>/etc</code>ï¼Œå¦‚æœæ˜¯ç›®å½•åˆ™ä¸èƒ½ç›´æ¥å¤åˆ¶ï¼Œè¦åŠ ä¸Š <code>-r</code> çš„é€‰é¡¹</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>rm ï¼ˆç§»é™¤æ–‡ä»¶æˆ–ç›®å½•ï¼‰</p>
<ul>
<li><code>rm [-fir] æ–‡ä»¶æˆ–ç›®å½•</code>ï¼š
<ul>
<li><code>-f</code> ï¼šå°±æ˜¯ force çš„æ„æ€ï¼Œå¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼Œä¸ä¼šå‡ºç°è­¦å‘Šè®¯æ¯ï¼›</li>
<li><code>-r</code> ï¼šé€’å›åˆ é™¤å•Šï¼æœ€å¸¸ç”¨åœ¨ç›®å½•çš„åˆ é™¤äº†ï¼è¿™æ˜¯éå¸¸å±é™©çš„é€‰é¡¹ï¼ï¼ï¼</li>
<li><code>-rf</code>: å¦‚å­ç›®å½•é‡Œé¢è¿˜æœ‰å­ç›®å½•æ—¶ï¼Œé‚£å°±è¦ä½¿ç”¨ -r è¿™ä¸ªé€‰é¡¹</li>
<li><code>-rf/</code>: ä¼šå°†ç³»ç»Ÿæ–‡ä»¶å…¨éƒ¨åˆ é™¤ï¼Œéå¸¸å±é™©  <s>åˆ åº“è·‘è·¯</s></li>
<li>ç¤ºä¾‹ï¼š
<ul>
<li><code>rm bashrc*</code>:é€šè¿‡ä¸‡ç”¨å­—ç¬¦*çš„å¸®å¿™ï¼Œå°†<code>/tmp</code>ä¸‹é¢å¼€å¤´ä¸ºbashrcçš„æ–‡ä»¶åé€šé€šåˆ é™¤</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>mv ï¼ˆç§»åŠ¨æ–‡ä»¶ä¸ç›®å½•ï¼Œæˆ–æ›´åï¼‰</p>
<ul>
<li><code>mv [-fiu] source destination</code></li>
<li><code>mv [options] source1 source2 source3 .... directory</code>
<ul>
<li><code>-f</code> ï¼šforce å¼ºåˆ¶çš„æ„æ€ï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œä¸ä¼šè¯¢é—®è€Œç›´æ¥è¦†ç›–ï¼›</li>
<li><code>-i</code> ï¼šè‹¥ç›®æ ‡æ–‡ä»¶ ï¼ˆdestinationï¼‰ å·²ç»å­˜åœ¨æ—¶ï¼Œå°±ä¼šè¯¢é—®æ˜¯å¦è¦†ç›–ï¼</li>
<li><code>-u</code> ï¼šè‹¥ç›®æ ‡æ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œä¸” source æ¯”è¾ƒæ–°ï¼Œæ‰ä¼šæ›´æ–° ï¼ˆupdateï¼‰</li>
<li>ç¤ºä¾‹:
<ul>
<li>å¤åˆ¶ä¸€æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ç›®å½•ï¼Œå°†æ–‡ä»¶ç§»åŠ¨åˆ°ç›®å½•ä¸­ï¼š
<ul>
<li><code>cd /tmp</code></li>
<li><code>cp ~/.bashrc bashrc</code></li>
<li><code>mkdir mvtest</code></li>
<li><code>mv bashrc mvtest</code></li>
</ul>
</li>
<li>æ–‡ä»¶æ”¹åï¼š
<ul>
<li><code>mv mvtest mvtest2</code></li>
</ul>
</li>
<li>å†åˆ›å»ºä¸¤ä¸ªæ–‡ä»¶ï¼Œå†å…¨éƒ¨ç§»åŠ¨åˆ° <code>/tmp/mvtest2</code> å½“ä¸­:
<ul>
<li><code>cp ~/.bashrc bashrc1</code></li>
<li><code>cp ~/.bashrc bashrc2</code></li>
<li><code>mv bashrc1 bashrc2 mvtest2</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="äºŒ-pip">äºŒã€pip</h1>
<ul>
<li><code>pip install --upgrade pip</code>æˆ–<code>pip install -U pip</code>:å‡çº§pipè‡ªèº«</li>
<li><code>pip list</code>ï¼šæŸ¥çœ‹å·²ç»é€šè¿‡pipå®‰è£…çš„åŒ…</li>
<li><code>pip install &lt;åŒ…å&gt; --upgrade</code>æˆ–<code>pip install -U &lt;åŒ…å&gt;</code>:å‡çº§åŒ…</li>
<li><code>pip install &lt;åŒ…å&gt; -i https://mirrors.aliyun.com/pypi/simple</code>:æŒ‡å®šå•æ¬¡å®‰è£…æº</li>
<li><code>pip install SomePackage==1.0.4</code>:æŒ‡å®šç‰ˆæœ¬</li>
<li><code>pip-review --auto/pip-review --local --interactive</code>:è‡ªåŠ¨æ›´æ–°æ‰€æœ‰åŒ…</li>
</ul>
<h1 id="ä¸‰-conda">ä¸‰ã€conda</h1>
<ul>
<li><code>conda --version</code>:æŸ¥çœ‹condaç‰ˆæœ¬ï¼ŒéªŒè¯æ˜¯å¦å®‰è£…</li>
<li><code>conda update conda</code>:æ›´æ–°è‡³æœ€æ–°ç‰ˆæœ¬ï¼Œä¹Ÿä¼šæ›´æ–°å…¶å®ƒç›¸å…³åŒ…</li>
<li><code>conda update --all</code>:æ›´æ–°æ‰€æœ‰åŒ…</li>
<li><code>conda update package_name</code>:æ›´æ–°æŒ‡å®šçš„åŒ…</li>
<li><code>conda create -n env_name package_name</code>:åˆ›å»ºåä¸º env_name çš„æ–°ç¯å¢ƒï¼Œå¹¶åœ¨è¯¥ç¯å¢ƒä¸‹å®‰è£…åä¸º package_name çš„åŒ…ï¼Œå¯ä»¥æŒ‡å®šæ–°ç¯å¢ƒçš„ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ï¼š<code>conda create -n python2 python=python2.7 numpy pandas</code>ï¼Œåˆ›å»ºäº†python2ç¯å¢ƒï¼Œpythonç‰ˆæœ¬ä¸º2.7ï¼ŒåŒæ—¶è¿˜å®‰è£…äº†numpy pandasåŒ…</li>
<li><code>conda activate env_name</code>:åˆ‡æ¢è‡³env_nameç¯å¢ƒ</li>
<li><code>conda deactivate</code>:é€€å‡ºç¯å¢ƒ</li>
<li><code>conda info -e</code>:æ˜¾ç¤ºæ‰€æœ‰å·²ç»åˆ›å»ºçš„ç¯</li>
<li><code>conda create -n new_env_name --clone old_env_name</code>:å¤åˆ¶old_env_nameä¸ºnew_env_name</li>
<li><code>conda remove -n env_name â€“-all</code>:åˆ é™¤ç¯å¢ƒ</li>
<li><code>conda list</code>:æŸ¥çœ‹æ‰€æœ‰å·²ç»å®‰è£…çš„åŒ…</li>
<li><code>conda install -n env_name package_name</code>:åœ¨æŒ‡å®šç¯å¢ƒä¸­å®‰è£…åŒ…</li>
<li><code>conda remove -n env_name package</code>:åˆ é™¤æŒ‡å®šç¯å¢ƒä¸­çš„åŒ…</li>
<li><code>rm -rf è™šæ‹Ÿç¯å¢ƒæ‰€åœ¨è·¯å¾„</code>:åˆ é™¤ç©ºç¯å¢ƒ</li>
</ul>
<h1 id="å››-vim">å››ã€Vim</h1>
<ul>
<li><code>shift+g</code>:ç§»è‡³æ–‡ä»¶æœ«å°¾</li>
</ul>
<h1 id="äº”-å…¶ä»–">äº”ã€å…¶ä»–</h1>
<ul>
<li><code>sudo nautilus /home</code>:æ‰“å¼€å›¾å½¢åŒ–æ–‡ä»¶å¤¹</li>
<li><code>top</code>æˆ–<code>htop</code>ï¼šæŸ¥çœ‹å½“å‰è¿›ç¨‹</li>
<li><code>ifconfig</code>ï¼šæŸ¥çœ‹IPåœ°å€</li>
<li><code>kill è¿›ç¨‹å·</code>:ç»ˆæ­¢è¿›ç¨‹</li>
<li><code>kill -9 è¿›ç¨‹å·</code>:å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹</li>
<li><code>tar -zxvf xxx.tar.gz</code>:è§£å‹ç¼©</li>
<li><code>chmod u+x file</code>:å¯¹æ–‡ä»¶ file å¢åŠ æ–‡ä»¶ä¸»å¯æ‰§è¡Œæƒé™ï¼ˆuè¡¨ç¤ºæ–‡ä»¶ä¸»ï¼‰</li>
<li><code>sudo apt-get install package</code>:å®‰è£…åŒ…</li>
<li><code>sudo apt-get install package --reinstall</code>:é‡æ–°å®‰è£…åŒ…</li>
<li><code>sudo apt-get -f install</code>:ä¿®å¤å®‰è£…</li>
<li><code>sudo apt-get remove package</code>:åˆ é™¤åŒ…</li>
<li><code>sudo apt-get remove package --purge</code>:åˆ é™¤åŒ…ï¼ŒåŒ…æ‹¬åˆ é™¤é…ç½®æ–‡ä»¶ç­‰</li>
<li><code>sudo apt-get update</code>:æ›´æ–°æº</li>
<li><code>sudo apt-get upgrade</code>:æ›´æ–°å·²å®‰è£…çš„åŒ…</li>
<li><code>sudo apt-get dist-upgrade</code>:`å‡çº§ç³»ç»Ÿ</li>
<li><code>sudo apt-get autoclean</code>:æ¸…ç†æ—§ç‰ˆæœ¬è½¯ä»¶ç¼“å­˜</li>
<li><code>sudo dpkg -i package.deb</code>:æ‰€æœ‰debæ–‡ä»¶çš„å®‰è£…</li>
<li><code>sudo dpkg -r package</code>ï¼šæ‰€æœ‰debæ–‡ä»¶çš„å¸è½½</li>
<li><code>sudo dpkg -P package</code>:å½»åº•çš„å¸è½½ï¼ŒåŒ…æ‹¬è½¯ä»¶çš„é…ç½®æ–‡ä»¶</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello World!]]></title>
        <id>https://bailingnan.github.io/post/hello-world</id>
        <link href="https://bailingnan.github.io/post/hello-world">
        </link>
        <updated>2019-12-22T17:10:09.000Z</updated>
        <content type="html"><![CDATA[<p>New begin!</p>
]]></content>
    </entry>
</feed>