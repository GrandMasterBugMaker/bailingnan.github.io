<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://bailingnan.github.io/</id>
    <title>白凌南</title>
    <updated>2020-03-06T17:24:46.365Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://bailingnan.github.io/"/>
    <link rel="self" href="https://bailingnan.github.io/atom.xml"/>
    <subtitle>DL/RecSys/Python/Java/INTJ</subtitle>
    <logo>https://bailingnan.github.io/images/avatar.png</logo>
    <icon>https://bailingnan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 白凌南</rights>
    <entry>
        <title type="html"><![CDATA[LeetCode26. 删除排序数组中的重复项]]></title>
        <id>https://bailingnan.github.io/post/leetcode26-shan-chu-pai-xu-shu-zu-zhong-de-chong-fu-xiang/</id>
        <link href="https://bailingnan.github.io/post/leetcode26-shan-chu-pai-xu-shu-zu-zhong-de-chong-fu-xiang/">
        </link>
        <updated>2020-02-22T08:23:59.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-python3">class Solution:
    def removeDuplicates(self, nums: List[int]) -&gt; int:
        cnt=len(set(nums))
        j=0
        for i in range(len(nums)):
            if i!=0:
                if(nums[i]==nums[i-1]):
                    continue
            nums[j]=nums[i]
            j+=1
        if(j&lt;len(nums)):
            del(nums[j:len(nums)])
        return j
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Numpy笔记]]></title>
        <id>https://bailingnan.github.io/post/numpy-bi-ji/</id>
        <link href="https://bailingnan.github.io/post/numpy-bi-ji/">
        </link>
        <updated>2020-02-15T14:58:47.000Z</updated>
        <content type="html"><![CDATA[<p>NumPy（Numerical Python的简称）是Python数值计算最重要的基础包。大多数提供科学计算的包都是用NumPy的数组作为构建基础。</p>
<p>NumPy的部分功能如下：</p>
<ul>
<li>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。</li>
<li>用于对整组数据进行快速运算的标准数学函数（无需编写循环）。</li>
<li>用于读写磁盘数据的工具以及用于操作内存映射文件的工具。</li>
<li>线性代数、随机数生成以及傅里叶变换功能。</li>
<li>用于集成由C、C++、Fortran等语言编写的代码的A C API。</li>
</ul>
<p>由于NumPy提供了一个简单易用的C API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以NumPy数组的形式将数据返回给Python。这个功能使Python成为一种包装C/C++/Fortran历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。</p>
<p>NumPy本身并没有提供多么高级的数据分析功能，理解NumPy数组以及面向数组的计算将有助于你更加高效地使用诸如pandas之类的工具。因为NumPy是一个很大的题目，我会在附录A中介绍更多NumPy高级功能，比如广播。</p>
<p>对于大部分数据分析应用而言，我最关注的功能主要集中在：</p>
<ul>
<li>用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。</li>
<li>常用的数组算法，如排序、唯一化、集合运算等。</li>
<li>高效的描述统计和数据聚合/摘要运算。</li>
<li>用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。</li>
<li>将条件逻辑表述为数组表达式（而不是带有if-elif-else分支的循环）。</li>
<li>数据的分组运算（聚合、转换、函数应用等）。。</li>
</ul>
<p>虽然NumPy提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将pandas作为统计和分析工作的基础，尤其是处理表格数据时。pandas还提供了一些NumPy所没有的领域特定的功能，如时间序列处理等。</p>
<blockquote>
<p>笔记：Python的面向数组计算可以追溯到1995年，Jim Hugunin创建了Numeric库。接下来的10年，许多科学编程社区纷纷开始使用Python的数组编程，但是进入21世纪，库的生态系统变得碎片化了。2005年，Travis Oliphant从Numeric和Numarray项目整合出了NumPy项目，进而所有社区都集合到了这个框架下。</p>
</blockquote>
<p>NumPy之于数值计算特别重要的原因之一，是因为它可以高效处理大数组的数据。这是因为：</p>
<ul>
<li>NumPy是在一个连续的内存块中存储数据，独立于其他Python内置对象。NumPy的C语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起Python的内置序列，NumPy数组使用的内存更少。</li>
<li>NumPy可以在整个数组上执行复杂的计算，而不需要Python的for循环。</li>
</ul>
<p>要搞明白具体的性能差距，考察一个包含一百万整数的数组，和一个等价的Python列表：</p>
<pre><code class="language-python">In [7]: import numpy as np

In [8]: my_arr = np.arange(1000000)

In [9]: my_list = list(range(1000000))
</code></pre>
<p>各个序列分别乘以2：</p>
<pre><code class="language-python">In [10]: %time for _ in range(10): my_arr2 = my_arr * 2
CPU times: user 20 ms, sys: 50 ms, total: 70 ms
Wall time: 72.4 ms

In [11]: %time for _ in range(10): my_list2 = [x * 2 for x in my_list]
CPU times: user 760 ms, sys: 290 ms, total: 1.05 s
Wall time: 1.05 s
</code></pre>
<p>基于NumPy的算法要比纯Python快10到100倍（甚至更快），并且使用的内存更少。</p>
<h1 id="41-numpy的ndarray一种多维数组对象">4.1 NumPy的ndarray：一种多维数组对象</h1>
<p>NumPy最重要的一个特点就是其N维数组对象（即ndarray），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。</p>
<p>要明白Python是如何利用与标量值类似的语法进行批次计算，我先引入NumPy，然后生成一个包含随机数据的小数组：</p>
<pre><code class="language-python">In [12]: import numpy as np

# Generate some random data
In [13]: data = np.random.randn(2, 3)

In [14]: data
Out[14]: 
array([[-0.2047,  0.4789, -0.5194],
       [-0.5557,  1.9658,  1.3934]])
</code></pre>
<p>然后进行数学运算：</p>
<pre><code class="language-python">In [15]: data * 10
Out[15]: 
array([[ -2.0471,   4.7894,  -5.1944],
       [ -5.5573,  19.6578,  13.9341]])

In [16]: data + data
Out[16]: 
array([[-0.4094,  0.9579, -1.0389],
       [-1.1115,  3.9316,  2.7868]])
</code></pre>
<p>第一个例子中，所有的元素都乘以10。第二个例子中，每个元素都与自身相加。</p>
<blockquote>
<p>笔记：在本章及全书中，我会使用标准的NumPy惯用法<code>import numpy as np</code>。你当然也可以在代码中使用<code>from numpy import *</code>，但不建议这么做。<code>numpy</code>的命名空间很大，包含许多函数，其中一些的名字与Python的内置函数重名（比如min和max）。</p>
</blockquote>
<p>ndarray是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个shape（一个表示各维度大小的元组）和一个dtype（一个用于说明数组数据类型的对象）：</p>
<pre><code class="language-python">In [17]: data.shape
Out[17]: (2, 3)

In [18]: data.dtype
Out[18]: dtype('float64')
</code></pre>
<p>本章将会介绍NumPy数组的基本用法，这对于本书后面各章的理解基本够用。虽然大多数数据分析工作不需要深入理解NumPy，但是精通面向数组的编程和思维方式是成为Python科学计算牛人的一大关键步骤。</p>
<blockquote>
<p>笔记：当你在本书中看到“数组”、“NumPy数组”、&quot;ndarray&quot;时，基本上都指的是同一样东西，即ndarray对象。</p>
</blockquote>
<h2 id="创建ndarray">创建ndarray</h2>
<p>创建数组最简单的办法就是使用array函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的NumPy数组。以一个列表的转换为例：</p>
<pre><code class="language-python">In [19]: data1 = [6, 7.5, 8, 0, 1]

In [20]: arr1 = np.array(data1)

In [21]: arr1
Out[21]: array([ 6. ,  7.5,  8. ,  0. ,  1. ])
</code></pre>
<p>嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：</p>
<pre><code class="language-python">In [22]: data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]

In [23]: arr2 = np.array(data2)

In [24]: arr2
Out[24]: 
array([[1, 2, 3, 4],
       [5, 6, 7, 8]])
</code></pre>
<p>因为data2是列表的列表，NumPy数组arr2的两个维度的shape是从data2引入的。可以用属性ndim和shape验证：</p>
<pre><code class="language-python">In [25]: arr2.ndim
Out[25]: 2

In [26]: arr2.shape
Out[26]: (2, 4)
</code></pre>
<p>除非特别说明（稍后将会详细介绍），np.array会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的dtype对象中。比如说，在上面的两个例子中，我们有：</p>
<pre><code class="language-python">In [27]: arr1.dtype
Out[27]: dtype('float64')

In [28]: arr2.dtype
Out[28]: dtype('int64')
</code></pre>
<p>除np.array之外，还有一些函数也可以新建数组。比如，zeros和ones分别可以创建指定长度或形状的全0或全1数组。empty可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可：</p>
<pre><code class="language-python">In [29]: np.zeros(10)
Out[29]: array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])

In [30]: np.zeros((3, 6))
Out[30]: 
array([[ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.]])

In [31]: np.empty((2, 3, 2))
Out[31]: 
array([[[ 0.,  0.],
        [ 0.,  0.],
        [ 0.,  0.]],
       [[ 0.,  0.],
        [ 0.,  0.],
        [ 0.,  0.]]])
</code></pre>
<blockquote>
<p>注意：认为np.empty会返回全0数组的想法是不安全的。很多情况下（如前所示），它返回的都是一些未初始化的垃圾值。</p>
</blockquote>
<p>arange是Python内置函数range的数组版：</p>
<pre><code class="language-python">In [32]: np.arange(15)
Out[32]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])
</code></pre>
<p>表4-1列出了一些数组创建函数。由于NumPy关注的是数值计算，因此，如果没有特别指定，数据类型基本都是float64（浮点数）。</p>
<figure data-type="image" tabindex="1"><img src="http://upload-images.jianshu.io/upload_images/7178691-78ab11f67e7077a6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表4-1 数组创建函数" loading="lazy"></figure>
<h2 id="ndarray的数据类型">ndarray的数据类型</h2>
<p>dtype（数据类型）是一个特殊的对象，它含有ndarray将一块内存解释为特定数据类型所需的信息：</p>
<pre><code class="language-python">In [33]: arr1 = np.array([1, 2, 3], dtype=np.float64)

In [34]: arr2 = np.array([1, 2, 3], dtype=np.int32)

In [35]: arr1.dtype
Out[35]: dtype('float64')

In [36]: arr2.dtype
Out[36]: dtype('int32')
</code></pre>
<p>dtype是NumPy灵活交互其它系统的源泉之一。多数情况下，它们直接映射到相应的机器表示，这使得“读写磁盘上的二进制数据流”以及“集成低级语言代码（如C、Fortran）”等工作变得更加简单。数值型dtype的命名方式相同：一个类型名（如float或int），后面跟一个用于表示各元素位长的数字。标准的双精度浮点值（即Python中的float对象）需要占用8字节（即64位）。因此，该类型在NumPy中就记作float64。表4-2列出了NumPy所支持的全部数据类型。</p>
<blockquote>
<p>笔记：记不住这些NumPy的dtype也没关系，新手更是如此。通常只需要知道你所处理的数据的大致类型是浮点数、复数、整数、布尔值、字符串，还是普通的Python对象即可。当你需要控制数据在内存和磁盘中的存储方式时（尤其是对大数据集），那就得了解如何控制存储类型。</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="http://upload-images.jianshu.io/upload_images/7178691-2f2d7406a8bc076c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="http://upload-images.jianshu.io/upload_images/7178691-5cc31115615737b7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<p>你可以通过ndarray的astype方法明确地将一个数组从一个dtype转换成另一个dtype：</p>
<pre><code class="language-python">In [37]: arr = np.array([1, 2, 3, 4, 5])

In [38]: arr.dtype
Out[38]: dtype('int64')

In [39]: float_arr = arr.astype(np.float64)

In [40]: float_arr.dtype
Out[40]: dtype('float64')
</code></pre>
<p>在本例中，整数被转换成了浮点数。如果将浮点数转换成整数，则小数部分将会被截取删除：</p>
<pre><code class="language-python">In [41]: arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])

In [42]: arr
Out[42]: array([  3.7,  -1.2,  -2.6,   0.5,  12.9,  10.1])

In [43]: arr.astype(np.int32)
Out[43]: array([ 3, -1, -2,  0, 12, 10], dtype=int32)
</code></pre>
<p>如果某字符串数组表示的全是数字，也可以用astype将其转换为数值形式：</p>
<pre><code class="language-python">In [44]: numeric_strings = np.array(['1.25', '-9.6', '42'], dtype=np.string_)

In [45]: numeric_strings.astype(float)
Out[45]: array([  1.25,  -9.6 ,  42.  ])
</code></pre>
<blockquote>
<p>注意：使用numpy.string_类型时，一定要小心，因为NumPy的字符串数据是大小固定的，发生截取时，不会发出警告。pandas提供了更多非数值数据的便利的处理方法。</p>
</blockquote>
<p>如果转换过程因为某种原因而失败了（比如某个不能被转换为float64的字符串），就会引发一个ValueError。这里，我比较懒，写的是float而不是np.float64；NumPy很聪明，它会将Python类型映射到等价的dtype上。</p>
<p>数组的dtype还有另一个属性：</p>
<pre><code class="language-python">In [46]: int_array = np.arange(10)

In [47]: calibers = np.array([.22, .270, .357, .380, .44, .50], dtype=np.float64)

In [48]: int_array.astype(calibers.dtype)
Out[48]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])
</code></pre>
<p>你还可以用简洁的类型代码来表示dtype：</p>
<pre><code class="language-python">In [49]: empty_uint32 = np.empty(8, dtype='u4')

In [50]: empty_uint32
Out[50]: 
array([         0, 1075314688,          0, 1075707904,          0,
       1075838976,          0, 1072693248], dtype=uint32)
</code></pre>
<blockquote>
<p>笔记：调用astype总会创建一个新的数组（一个数据的备份），即使新的dtype与旧的dtype相同。</p>
</blockquote>
<h2 id="numpy数组的运算">NumPy数组的运算</h2>
<p>数组很重要，因为它使你不用编写循环即可对数据执行批量运算。NumPy用户称其为矢量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级：</p>
<pre><code class="language-python">In [51]: arr = np.array([[1., 2., 3.], [4., 5., 6.]])

In [52]: arr
Out[52]: 
array([[ 1.,  2.,  3.],
       [ 4.,  5.,  6.]])

In [53]: arr * arr
Out[53]: 
array([[  1.,   4.,   9.],
       [ 16.,  25.,  36.]])

In [54]: arr - arr
Out[54]: 
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])
</code></pre>
<p>数组与标量的算术运算会将标量值传播到各个元素：</p>
<pre><code class="language-python">In [55]: 1 / arr
Out[55]: 
array([[ 1.    ,  0.5   ,  0.3333],
       [ 0.25  ,  0.2   ,  0.1667]])

In [56]: arr ** 0.5
Out[56]: 
array([[ 1.    ,  1.4142,  1.7321],
       [ 2.    ,  2.2361,  2.4495]])
</code></pre>
<p>大小相同的数组之间的比较会生成布尔值数组：</p>
<pre><code class="language-python">In [57]: arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])

In [58]: arr2
Out[58]: 
array([[  0.,   4.,   1.],
       [  7.,   2.,  12.]])

In [59]: arr2 &gt; arr
Out[59]:
array([[False,  True, False],
       [ True, False,  True]], dtype=bool)
</code></pre>
<p>不同大小的数组之间的运算叫做广播（broadcasting），将在附录A中对其进行详细讨论。本书的内容不需要对广播机制有多深的理解。</p>
<h2 id="基本的索引和切片">基本的索引和切片</h2>
<p>NumPy数组的索引是一个内容丰富的主题，因为选取数据子集或单个元素的方式有很多。一维数组很简单。从表面上看，它们跟Python列表的功能差不多：</p>
<pre><code class="language-python">In [60]: arr = np.arange(10)

In [61]: arr
Out[61]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

In [62]: arr[5]
Out[62]: 5

In [63]: arr[5:8]
Out[63]: array([5, 6, 7])

In [64]: arr[5:8] = 12

In [65]: arr
Out[65]: array([ 0,  1,  2,  3,  4, 12, 12, 12,  8,  9])
</code></pre>
<p>如上所示，当你将一个标量值赋值给一个切片时（如arr[5:8]=12），该值会自动传播（也就说后面将会讲到的“广播”）到整个选区。跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上。</p>
<p>作为例子，先创建一个arr的切片：</p>
<pre><code class="language-python">In [66]: arr_slice = arr[5:8]

In [67]: arr_slice
Out[67]: array([12, 12, 12])
</code></pre>
<p>现在，当我修稿arr_slice中的值，变动也会体现在原始数组arr中：</p>
<pre><code class="language-python">In [68]: arr_slice[1] = 12345

In [69]: arr
Out[69]: array([    0,     1,     2,     3,     4,    12, 12345,    12,     8,   
  9])
</code></pre>
<p>切片[ : ]会给数组中的所有值赋值：</p>
<pre><code class="language-python">In [70]: arr_slice[:] = 64

In [71]: arr
Out[71]: array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])
</code></pre>
<p>如果你刚开始接触NumPy，可能会对此感到惊讶（尤其是当你曾经用过其他热衷于复制数组数据的编程语言）。由于NumPy的设计目的是处理大数据，所以你可以想象一下，假如NumPy坚持要将数据复制来复制去的话会产生何等的性能和内存问题。</p>
<blockquote>
<p>注意：如果你想要得到的是ndarray切片的一份副本而非视图，就需要明确地进行复制操作，例如<code>arr[5:8].copy()</code>。</p>
</blockquote>
<p>对于高维度数组，能做的事情更多。在一个二维数组中，各索引位置上的元素不再是标量而是一维数组：</p>
<pre><code class="language-python">In [72]: arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

In [73]: arr2d[2]
Out[73]: array([7, 8, 9])
</code></pre>
<p>因此，可以对各个元素进行递归访问，但这样需要做的事情有点多。你可以传入一个以逗号隔开的索引列表来选取单个元素。也就是说，下面两种方式是等价的：</p>
<pre><code class="language-python">In [74]: arr2d[0][2]
Out[74]: 3

In [75]: arr2d[0, 2]
Out[75]: 3
</code></pre>
<p>图4-1说明了二维数组的索引方式。轴0作为行，轴1作为列。</p>
<figure data-type="image" tabindex="4"><img src="http://upload-images.jianshu.io/upload_images/7178691-0a641536f73f560e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-1 NumPy数组中的元素索引" loading="lazy"></figure>
<p>在多维数组中，如果省略了后面的索引，则返回对象会是一个维度低一点的ndarray（它含有高一级维度上的所有数据）。因此，在2×2×3数组arr3d中：</p>
<pre><code class="language-python">In [76]: arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])

In [77]: arr3d
Out[77]: 
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]])
</code></pre>
<p>arr3d[0]是一个2×3数组：</p>
<pre><code class="language-python">In [78]: arr3d[0]
Out[78]: 
array([[1, 2, 3],
       [4, 5, 6]])
</code></pre>
<p>标量值和数组都可以被赋值给arr3d[0]：</p>
<pre><code class="language-python">In [79]: old_values = arr3d[0].copy()

In [80]: arr3d[0] = 42

In [81]: arr3d
Out[81]: 
array([[[42, 42, 42],
        [42, 42, 42]],
       [[ 7,  8,  9],
        [10, 11, 12]]])

In [82]: arr3d[0] = old_values

In [83]: arr3d
Out[83]: 
array([[[ 1,  2,  3],
        [ 4,  5,  6]],
       [[ 7,  8,  9],
        [10, 11, 12]]])
</code></pre>
<p>相似的，arr3d[1,0]可以访问索引以(1,0)开头的那些值（以一维数组的形式返回）：</p>
<pre><code class="language-python">In [84]: arr3d[1, 0]
Out[84]: array([7, 8, 9])
</code></pre>
<p>虽然是用两步进行索引的，表达式是相同的：</p>
<pre><code class="language-python">In [85]: x = arr3d[1]

In [86]: x
Out[86]: 
array([[ 7,  8,  9],
       [10, 11, 12]])

In [87]: x[0]
Out[87]: array([7, 8, 9])
</code></pre>
<p>注意，在上面所有这些选取数组子集的例子中，返回的数组都是视图。</p>
<h2 id="切片索引">切片索引</h2>
<p>ndarray的切片语法跟Python列表这样的一维对象差不多：</p>
<pre><code class="language-python">In [88]: arr
Out[88]: array([ 0,  1,  2,  3,  4, 64, 64, 64,  8,  9])

In [89]: arr[1:6]
Out[89]: array([ 1,  2,  3,  4, 64])
</code></pre>
<p>对于之前的二维数组arr2d，其切片方式稍显不同：</p>
<pre><code class="language-python">In [90]: arr2d
Out[90]: 
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])

In [91]: arr2d[:2]
Out[91]: 
array([[1, 2, 3],
       [4, 5, 6]])
</code></pre>
<p>可以看出，它是沿着第0轴（即第一个轴）切片的。也就是说，切片是沿着一个轴向选取元素的。表达式arr2d[:2]可以被认为是“选取arr2d的前两行”。</p>
<p>你可以一次传入多个切片，就像传入多个索引那样：</p>
<pre><code class="language-python">In [92]: arr2d[:2, 1:]
Out[92]: 
array([[2, 3],
       [5, 6]])
</code></pre>
<p>像这样进行切片时，只能得到相同维数的数组视图。通过将整数索引和切片混合，可以得到低维度的切片。</p>
<p>例如，我可以选取第二行的前两列：</p>
<pre><code class="language-python">In [93]: arr2d[1, :2]
Out[93]: array([4, 5])
</code></pre>
<p>相似的，还可以选择第三列的前两行：</p>
<pre><code class="language-python">In [94]: arr2d[:2, 2]
Out[94]: array([3, 6])
</code></pre>
<p>图4-2对此进行了说明。注意，“只有冒号”表示选取整个轴，因此你可以像下面这样只对高维轴进行切片：</p>
<pre><code class="language-python">In [95]: arr2d[:, :1]
Out[95]: 
array([[1],
       [4],
       [7]])
</code></pre>
<figure data-type="image" tabindex="5"><img src="http://upload-images.jianshu.io/upload_images/7178691-9da32d2f4629c304.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-2 二维数组切片" loading="lazy"></figure>
<p>自然，对切片表达式的赋值操作也会被扩散到整个选区：</p>
<pre><code class="language-python">In [96]: arr2d[:2, 1:] = 0

In [97]: arr2d
Out[97]: 
array([[1, 0, 0],
       [4, 0, 0],
       [7, 8, 9]])
</code></pre>
<h2 id="布尔型索引">布尔型索引</h2>
<p>来看这样一个例子，假设我们有一个用于存储数据的数组以及一个存储姓名的数组（含有重复项）。在这里，我将使用numpy.random中的randn函数生成一些正态分布的随机数据：</p>
<pre><code class="language-python">In [98]: names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])

In [99]: data = np.random.randn(7, 4)

In [100]: names
Out[100]: 
array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'],
      dtype='&lt;U4')

In [101]: data
Out[101]: 
array([[ 0.0929,  0.2817,  0.769 ,  1.2464],
       [ 1.0072, -1.2962,  0.275 ,  0.2289],
       [ 1.3529,  0.8864, -2.0016, -0.3718],
       [ 1.669 , -0.4386, -0.5397,  0.477 ],
       [ 3.2489, -1.0212, -0.5771,  0.1241],
       [ 0.3026,  0.5238,  0.0009,  1.3438],
       [-0.7135, -0.8312, -2.3702, -1.8608]])
</code></pre>
<p>假设每个名字都对应data数组中的一行，而我们想要选出对应于名字&quot;Bob&quot;的所有行。跟算术运算一样，数组的比较运算（如==）也是矢量化的。因此，对names和字符串&quot;Bob&quot;的比较运算将会产生一个布尔型数组：</p>
<pre><code class="language-python">In [102]: names == 'Bob'
Out[102]: array([ True, False, False,  True, False, False, False], dtype=bool)
</code></pre>
<p>这个布尔型数组可用于数组索引：</p>
<pre><code class="language-python">In [103]: data[names == 'Bob']
Out[103]: 
array([[ 0.0929,  0.2817,  0.769 ,  1.2464],
       [ 1.669 , -0.4386, -0.5397,  0.477 ]])
</code></pre>
<p>布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组跟切片、整数（或整数序列，稍后将对此进行详细讲解）混合使用：</p>
<pre><code class="language-python">In [103]: data[names == 'Bob']
Out[103]: 
array([[ 0.0929,  0.2817,  0.769 ,  1.2464],
       [ 1.669 , -0.4386, -0.5397,  0.477 ]])
</code></pre>
<blockquote>
<p>注意：如果布尔型数组的长度不对，布尔型选择就会出错，因此一定要小心。</p>
</blockquote>
<p>下面的例子，我选取了<code>names == 'Bob'</code>的行，并索引了列：</p>
<pre><code class="language-python">In [104]: data[names == 'Bob', 2:]
Out[104]: 
array([[ 0.769 ,  1.2464],
       [-0.5397,  0.477 ]])

In [105]: data[names == 'Bob', 3]
Out[105]: array([ 1.2464,  0.477 ])
</code></pre>
<p>要选择除&quot;Bob&quot;以外的其他值，既可以使用不等于符号（!=），也可以通过~对条件进行否定：</p>
<pre><code class="language-python">In [106]: names != 'Bob'
Out[106]: array([False,  True,  True, False,  True,  True,  True], dtype=bool)

In [107]: data[~(names == 'Bob')]
Out[107]:
array([[ 1.0072, -1.2962,  0.275 ,  0.2289],
       [ 1.3529,  0.8864, -2.0016, -0.3718],
       [ 3.2489, -1.0212, -0.5771,  0.1241],
       [ 0.3026,  0.5238,  0.0009,  1.3438],
       [-0.7135, -0.8312, -2.3702, -1.8608]])
</code></pre>
<p>~操作符用来反转条件很好用：</p>
<pre><code class="language-python">In [108]: cond = names == 'Bob'

In [109]: data[~cond]
Out[109]: 
array([[ 1.0072, -1.2962,  0.275 ,  0.2289],
       [ 1.3529,  0.8864, -2.0016, -0.3718],
       [ 3.2489, -1.0212, -0.5771,  0.1241],
       [ 0.3026,  0.5238,  0.0009,  1.3438],
       [-0.7135, -0.8312, -2.3702, -1.8608]])
</code></pre>
<p>选取这三个名字中的两个需要组合应用多个布尔条件，使用&amp;（和）、|（或）之类的布尔算术运算符即可：</p>
<pre><code class="language-python">In [110]: mask = (names == 'Bob') | (names == 'Will')

In [111]: mask
Out[111]: array([ True, False,  True,  True,  True, False, False], dtype=bool)

In [112]: data[mask]
Out[112]: 
array([[ 0.0929,  0.2817,  0.769 ,  1.2464],
       [ 1.3529,  0.8864, -2.0016, -0.3718],
       [ 1.669 , -0.4386, -0.5397,  0.477 ],
       [ 3.2489, -1.0212, -0.5771,  0.1241]])
</code></pre>
<p>通过布尔型索引选取数组中的数据，将总是创建数据的副本，即使返回一模一样的数组也是如此。</p>
<blockquote>
<p>注意：Python关键字and和or在布尔型数组中无效。要使用&amp;与|。</p>
</blockquote>
<p>通过布尔型数组设置值是一种经常用到的手段。为了将data中的所有负值都设置为0，我们只需：</p>
<pre><code class="language-python">In [113]: data[data &lt; 0] = 0

In [114]: data
Out[114]: 
array([[ 0.0929,  0.2817,  0.769 ,  1.2464],
       [ 1.0072,  0.    ,  0.275 ,  0.2289],
       [ 1.3529,  0.8864,  0.    ,  0.    ],
       [ 1.669 ,  0.    ,  0.    ,  0.477 ],
       [ 3.2489,  0.    ,  0.    ,  0.1241],
       [ 0.3026,  0.5238,  0.0009,  1.3438],
       [ 0.    ,  0.    ,  0.    ,  0.    ]])
</code></pre>
<p>通过一维布尔数组设置整行或列的值也很简单：</p>
<pre><code class="language-python">In [115]: data[names != 'Joe'] = 7

In [116]: data
Out[116]: 
array([[ 7.    ,  7.    ,  7.    ,  7.    ],
       [ 1.0072,  0.    ,  0.275 ,  0.2289],
       [ 7.    ,  7.    ,  7.    ,  7.    ],
       [ 7.    ,  7.    ,  7.    ,  7.    ],
       [ 7.    ,  7.    ,  7.    ,  7.    ],
       [ 0.3026,  0.5238,  0.0009,  1.3438],
       [ 0.    ,  0.    ,  0.    ,  0.    ]])
</code></pre>
<p>后面会看到，这类二维数据的操作也可以用pandas方便的来做。</p>
<h2 id="花式索引">花式索引</h2>
<p>花式索引（Fancy indexing）是一个NumPy术语，它指的是利用整数数组进行索引。假设我们有一个8×4数组：</p>
<pre><code class="language-python">In [117]: arr = np.empty((8, 4))

In [118]: for i in range(8):
   .....:     arr[i] = i

In [119]: arr
Out[119]: 
array([[ 0.,  0.,  0.,  0.],
       [ 1.,  1.,  1.,  1.],
       [ 2.,  2.,  2.,  2.],
       [ 3.,  3.,  3.,  3.],
       [ 4.,  4.,  4.,  4.],
       [ 5.,  5.,  5.,  5.],
       [ 6.,  6.,  6.,  6.],
       [ 7.,  7.,  7.,  7.]])
</code></pre>
<p>为了以特定顺序选取行子集，只需传入一个用于指定顺序的整数列表或ndarray即可：</p>
<pre><code class="language-python">In [120]: arr[[4, 3, 0, 6]]
Out[120]: 
array([[ 4.,  4.,  4.,  4.],
       [ 3.,  3.,  3.,  3.],
       [ 0.,  0.,  0.,  0.],
       [ 6.,  6.,  6.,  6.]])
</code></pre>
<p>这段代码确实达到我们的要求了！使用负数索引将会从末尾开始选取行：</p>
<pre><code class="language-python">In [121]: arr[[-3, -5, -7]]
Out[121]: 
array([[ 5.,  5.,  5.,  5.],
       [ 3.,  3.,  3.,  3.],
       [ 1.,  1.,  1.,  1.]])
</code></pre>
<p>一次传入多个索引数组会有一点特别。它返回的是一个一维数组，其中的元素对应各个索引元组：</p>
<pre><code class="language-python">In [122]: arr = np.arange(32).reshape((8, 4))

In [123]: arr
Out[123]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15],
       [16, 17, 18, 19],
       [20, 21, 22, 23],
       [24, 25, 26, 27],
       [28, 29, 30, 31]])

In [124]: arr[[1, 5, 7, 2], [0, 3, 1, 2]]
Out[124]: array([ 4, 23, 29, 10])
</code></pre>
<p>附录A中会详细介绍reshape方法。</p>
<p>最终选出的是元素(1,0)、(5,3)、(7,1)和(2,2)。无论数组是多少维的，花式索引总是一维的。</p>
<p>这个花式索引的行为可能会跟某些用户的预期不一样（包括我在内），选取矩阵的行列子集应该是矩形区域的形式才对。下面是得到该结果的一个办法：</p>
<pre><code class="language-python">In [125]: arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]
Out[125]: 
array([[ 4,  7,  5,  6],
       [20, 23, 21, 22],
       [28, 31, 29, 30],
       [ 8, 11,  9, 10]])
</code></pre>
<p>记住，花式索引跟切片不一样，它总是将数据复制到新数组中。</p>
<h2 id="数组转置和轴对换">数组转置和轴对换</h2>
<p>转置是重塑的一种特殊形式，它返回的是源数据的视图（不会进行任何复制操作）。数组不仅有transpose方法，还有一个特殊的T属性：</p>
<pre><code class="language-python">In [126]: arr = np.arange(15).reshape((3, 5))

In [127]: arr
Out[127]: 
array([[ 0,  1,  2,  3,  4],
       [ 5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14]])

In [128]: arr.T
Out[128]: 
array([[ 0,  5, 10],
       [ 1,  6, 11],
       [ 2,  7, 12],
       [ 3,  8, 13],
       [ 4,  9, 14]])
</code></pre>
<p>在进行矩阵计算时，经常需要用到该操作，比如利用np.dot计算矩阵内积：</p>
<pre><code class="language-python">In [129]: arr = np.random.randn(6, 3)

In [130]: arr
Out[130]: 
array([[-0.8608,  0.5601, -1.2659],
       [ 0.1198, -1.0635,  0.3329],
       [-2.3594, -0.1995, -1.542 ],
       [-0.9707, -1.307 ,  0.2863],
       [ 0.378 , -0.7539,  0.3313],
       [ 1.3497,  0.0699,  0.2467]])

In [131]: np.dot(arr.T, arr)
Out[131]:
array([[ 9.2291,  0.9394,  4.948 ],
       [ 0.9394,  3.7662, -1.3622],
       [ 4.948 , -1.3622,  4.3437]])
</code></pre>
<p>对于高维数组，transpose需要得到一个由轴编号组成的元组才能对这些轴进行转置（比较费脑子）：</p>
<pre><code class="language-python">In [132]: arr = np.arange(16).reshape((2, 2, 4))

In [133]: arr
Out[133]: 
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7]],
       [[ 8,  9, 10, 11],
        [12, 13, 14, 15]]])

In [134]: arr.transpose((1, 0, 2))
Out[134]: 
array([[[ 0,  1,  2,  3],
        [ 8,  9, 10, 11]],
       [[ 4,  5,  6,  7],
        [12, 13, 14, 15]]])
</code></pre>
<p>这里，第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变。</p>
<p>简单的转置可以使用.T，它其实就是进行轴对换而已。ndarray还有一个swapaxes方法，它需要接受一对轴编号：</p>
<pre><code class="language-python">In [135]: arr
Out[135]: 
array([[[ 0,  1,  2,  3],
        [ 4,  5,  6,  7]],
       [[ 8,  9, 10, 11],
        [12, 13, 14, 15]]])

In [136]: arr.swapaxes(1, 2)
Out[136]: 
array([[[ 0,  4],
        [ 1,  5],
        [ 2,  6],
        [ 3,  7]],
       [[ 8, 12],
        [ 9, 13],
        [10, 14],
        [11, 15]]])
</code></pre>
<p>swapaxes也是返回源数据的视图（不会进行任何复制操作）。</p>
<h1 id="42-通用函数快速的元素级数组函数">4.2 通用函数：快速的元素级数组函数</h1>
<p>通用函数（即ufunc）是一种对ndarray中的数据执行元素级运算的函数。你可以将其看做简单函数（接受一个或多个标量值，并产生一个或多个标量值）的矢量化包装器。</p>
<p>许多ufunc都是简单的元素级变体，如sqrt和exp：</p>
<pre><code class="language-python">In [137]: arr = np.arange(10)

In [138]: arr
Out[138]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

In [139]: np.sqrt(arr)
Out[139]: 
array([ 0.    ,  1.    ,  1.4142,  1.7321,  2.    ,  2.2361,  2.4495,
        2.6458,  2.8284,  3.    ])

In [140]: np.exp(arr)
Out[140]: 
array([    1.    ,     2.7183,     7.3891,    20.0855,    54.5982,
         148.4132,   403.4288,  1096.6332,  2980.958 ,  8103.0839])
</code></pre>
<p>这些都是一元（unary）ufunc。另外一些（如add或maximum）接受2个数组（因此也叫二元（binary）ufunc），并返回一个结果数组：</p>
<pre><code class="language-python">In [141]: x = np.random.randn(8)

In [142]: y = np.random.randn(8)

In [143]: x
Out[143]: 
array([-0.0119,  1.0048,  1.3272, -0.9193, -1.5491,  0.0222,  0.7584,
       -0.6605])

In [144]: y
Out[144]: 
array([ 0.8626, -0.01  ,  0.05  ,  0.6702,  0.853 , -0.9559, -0.0235,
       -2.3042])

In [145]: np.maximum(x, y)
Out[145]: 
array([ 0.8626,  1.0048,  1.3272,  0.6702,  0.853 ,  0.0222,  0.7584,   
       -0.6605])
</code></pre>
<p>这里，numpy.maximum计算了x和y中元素级别最大的元素。</p>
<p>虽然并不常见，但有些ufunc的确可以返回多个数组。modf就是一个例子，它是Python内置函数divmod的矢量化版本，它会返回浮点数数组的小数和整数部分：</p>
<pre><code class="language-python">In [146]: arr = np.random.randn(7) * 5

In [147]: arr
Out[147]: array([-3.2623, -6.0915, -6.663 ,  5.3731,  3.6182,  3.45  ,  5.0077])

In [148]: remainder, whole_part = np.modf(arr)

In [149]: remainder
Out[149]: array([-0.2623, -0.0915, -0.663 ,  0.3731,
0.6182,  0.45  ,  0.0077])

In [150]: whole_part
Out[150]: array([-3., -6., -6.,  5.,  3.,  3.,  5.])
</code></pre>
<p>Ufuncs可以接受一个out可选参数，这样就能在数组原地进行操作：</p>
<pre><code class="language-python">In [151]: arr
Out[151]: array([-3.2623, -6.0915, -6.663 ,  5.3731,  3.6182,  3.45  ,  5.0077])

In [152]: np.sqrt(arr)
Out[152]: array([    nan,     nan,     nan,  2.318 ,  1.9022,  1.8574,  2.2378])

In [153]: np.sqrt(arr, arr)
Out[153]: array([    nan,     nan,     nan,  2.318 ,  1.9022,  1.8574,  2.2378])

In [154]: arr
Out[154]: array([    nan,     nan,     nan,  2.318 ,  1.9022,  1.8574,  2.2378])
</code></pre>
<p>表4-3和表4-4分别列出了一些一元和二元ufunc。</p>
<figure data-type="image" tabindex="6"><img src="http://upload-images.jianshu.io/upload_images/7178691-1d494e73b61c7ced.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="http://upload-images.jianshu.io/upload_images/7178691-2be79faf68ab6ff8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="http://upload-images.jianshu.io/upload_images/7178691-4e38d02a66481530.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="9"><img src="http://upload-images.jianshu.io/upload_images/7178691-eff1e61e5464159f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="http://upload-images.jianshu.io/upload_images/7178691-236dba83b6a420cc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<h1 id="43-利用数组进行数据处理">4.3 利用数组进行数据处理</h1>
<p>NumPy数组使你可以将许多种数据处理任务表述为简洁的数组表达式（否则需要编写循环）。用数组表达式代替循环的做法，通常被称为矢量化。一般来说，矢量化数组运算要比等价的纯Python方式快上一两个数量级（甚至更多），尤其是各种数值计算。在后面内容中（见附录A）我将介绍广播，这是一种针对矢量化计算的强大手段。</p>
<p>作为简单的例子，假设我们想要在一组值（网格型）上计算函数<code>sqrt(x^2+y^2)</code>。np.meshgrid函数接受两个一维数组，并产生两个二维矩阵（对应于两个数组中所有的(x,y)对）：</p>
<pre><code class="language-python">In [155]: points = np.arange(-5, 5, 0.01) # 1000 equally spaced points

In [156]: xs, ys = np.meshgrid(points, points)
In [157]: ys
Out[157]: 
array([[-5.  , -5.  , -5.  , ..., -5.  , -5.  , -5.  ],
       [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99],
       [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98],
       ..., 
       [ 4.97,  4.97,  4.97, ...,  4.97,  4.97,  4.97],
       [ 4.98,  4.98,  4.98, ...,  4.98,  4.98,  4.98],
       [ 4.99,  4.99,  4.99, ...,  4.99,  4.99,  4.99]])
</code></pre>
<p>现在，对该函数的求值运算就好办了，把这两个数组当做两个浮点数那样编写表达式即可：</p>
<pre><code class="language-python">In [158]: z = np.sqrt(xs ** 2 + ys ** 2)

In [159]: z
Out[159]: 
array([[ 7.0711,  7.064 ,  7.0569, ...,  7.0499,  7.0569,  7.064 ],
       [ 7.064 ,  7.0569,  7.0499, ...,  7.0428,  7.0499,  7.0569],
       [ 7.0569,  7.0499,  7.0428, ...,  7.0357,  7.0428, 7.0499],
       ..., 
       [ 7.0499,  7.0428,  7.0357, ...,  7.0286,  7.0357,  7.0428],
       [ 7.0569,  7.0499,  7.0428, ...,  7.0357,  7.0428,  7.0499],
       [ 7.064 ,  7.0569,  7.0499, ...,  7.0428,  7.0499,  7.0569]])
</code></pre>
<p>作为第9章的先导，我用matplotlib创建了这个二维数组的可视化：</p>
<pre><code class="language-python">In [160]: import matplotlib.pyplot as plt

In [161]: plt.imshow(z, cmap=plt.cm.gray); plt.colorbar()
Out[161]: &lt;matplotlib.colorbar.Colorbar at 0x7f715e3fa630&gt;

In [162]: plt.title(&quot;Image plot of $\sqrt{x^2 + y^2}$ for a grid of values&quot;)
Out[162]: &lt;matplotlib.text.Text at 0x7f715d2de748&gt;
</code></pre>
<p>见图4-3。这张图是用matplotlib的imshow函数创建的。</p>
<figure data-type="image" tabindex="11"><img src="http://upload-images.jianshu.io/upload_images/7178691-3b22000d4cd38650.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-3 根据网格对函数求值的结果" loading="lazy"></figure>
<h2 id="将条件逻辑表述为数组运算">将条件逻辑表述为数组运算</h2>
<p>numpy.where函数是三元表达式x if condition else y的矢量化版本。假设我们有一个布尔数组和两个值数组：</p>
<pre><code class="language-python">In [165]: xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])

In [166]: yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])

In [167]: cond = np.array([True, False, True, True, False])
</code></pre>
<p>假设我们想要根据cond中的值选取xarr和yarr的值：当cond中的值为True时，选取xarr的值，否则从yarr中选取。列表推导式的写法应该如下所示：</p>
<pre><code class="language-python">In [168]: result = [(x if c else y)
   .....:           for x, y, c in zip(xarr, yarr, cond)]

In [169]: result
Out[169]: [1.1000000000000001, 2.2000000000000002, 1.3, 1.3999999999999999, 2.5]
</code></pre>
<p>这有几个问题。第一，它对大数组的处理速度不是很快（因为所有工作都是由纯Python完成的）。第二，无法用于多维数组。若使用np.where，则可以将该功能写得非常简洁：</p>
<pre><code class="language-python">In [170]: result = np.where(cond, xarr, yarr)

In [171]: result
Out[171]: array([ 1.1,  2.2,  1.3,  1.4,  2.5])
</code></pre>
<p>np.where的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为2，将所有负值替换为－2。若利用np.where，则会非常简单：</p>
<pre><code class="language-python">In [172]: arr = np.random.randn(4, 4)

In [173]: arr
Out[173]: 
array([[-0.5031, -0.6223, -0.9212, -0.7262],
       [ 0.2229,  0.0513, -1.1577,  0.8167],
       [ 0.4336,  1.0107,  1.8249, -0.9975],
       [ 0.8506, -0.1316,  0.9124,  0.1882]])

In [174]: arr &gt; 0
Out[174]: 
array([[False, False, False, False],
       [ True,  True, False,  True],
       [ True,  True,  True, False],
       [ True, False,  True,  True]], dtype=bool)

In [175]: np.where(arr &gt; 0, 2, -2)
Out[175]: 
array([[-2, -2, -2, -2],
       [ 2,  2, -2,  2],
       [ 2,  2,  2, -2],
       [ 2, -2,  2,  2]])
</code></pre>
<p>使用np.where，可以将标量和数组结合起来。例如，我可用常数2替换arr中所有正的值：</p>
<pre><code class="language-python">In [176]: np.where(arr &gt; 0, 2, arr) # set only positive values to 2
Out[176]: 
array([[-0.5031, -0.6223, -0.9212, -0.7262],
       [ 2.    ,  2.    , -1.1577,  2.    ],
       [ 2.    ,  2.    ,  2.    , -0.9975],
       [ 2.    , -0.1316,  2.    ,  2.    ]])
</code></pre>
<p>传递给where的数组大小可以不相等，甚至可以是标量值。</p>
<h2 id="数学和统计方法">数学和统计方法</h2>
<p>可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算。sum、mean以及标准差std等聚合计算（aggregation，通常叫做约简（reduction））既可以当做数组的实例方法调用，也可以当做顶级NumPy函数使用。</p>
<p>这里，我生成了一些正态分布随机数据，然后做了聚类统计：</p>
<pre><code class="language-python">In [177]: arr = np.random.randn(5, 4)

In [178]: arr
Out[178]: 
array([[ 2.1695, -0.1149,  2.0037,  0.0296],
       [ 0.7953,  0.1181, -0.7485,  0.585 ],
       [ 0.1527, -1.5657, -0.5625, -0.0327],
       [-0.929 , -0.4826, -0.0363,  1.0954],
       [ 0.9809, -0.5895,  1.5817, -0.5287]])

In [179]: arr.mean()
Out[179]: 0.19607051119998253

In [180]: np.mean(arr)
Out[180]: 0.19607051119998253

In [181]: arr.sum()
Out[181]: 3.9214102239996507
</code></pre>
<p>mean和sum这类的函数可以接受一个axis选项参数，用于计算该轴向上的统计值，最终结果是一个少一维的数组：</p>
<pre><code class="language-python">In [182]: arr.mean(axis=1)
Out[182]: array([ 1.022 ,  0.1875, -0.502 , -0.0881,  0.3611])

In [183]: arr.sum(axis=0)
Out[183]: array([ 3.1693, -2.6345,  2.2381,  1.1486])
</code></pre>
<p>这里，arr.mean(1)是“计算行的平均值”，arr.sum(0)是“计算每列的和”。</p>
<p>其他如cumsum和cumprod之类的方法则不聚合，而是产生一个由中间结果组成的数组：</p>
<pre><code class="language-python">In [184]: arr = np.array([0, 1, 2, 3, 4, 5, 6, 7])

In [185]: arr.cumsum()
Out[185]: array([ 0,  1,  3,  6, 10, 15, 21, 28])
</code></pre>
<p>在多维数组中，累加函数（如cumsum）返回的是同样大小的数组，但是会根据每个低维的切片沿着标记轴计算部分聚类：</p>
<pre><code class="language-python">In [186]: arr = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])

In [187]: arr
Out[187]: 
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])

In [188]: arr.cumsum(axis=0)
Out[188]: 
array([[ 0,  1,  2],
       [ 3,  5,  7],
       [ 9, 12, 15]])

In [189]: arr.cumprod(axis=1)
Out[189]: 
array([[  0,   0,   0],
       [  3,  12,  60],
       [  6,  42, 336]])
</code></pre>
<p>表4-5列出了全部的基本数组统计方法。后续章节中有很多例子都会用到这些方法。</p>
<figure data-type="image" tabindex="12"><img src="http://upload-images.jianshu.io/upload_images/7178691-a6c6df3ca8e0b98e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="http://upload-images.jianshu.io/upload_images/7178691-866fcde885b1d357.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<h2 id="用于布尔型数组的方法">用于布尔型数组的方法</h2>
<p>在上面这些方法中，布尔值会被强制转换为1（True）和0（False）。因此，sum经常被用来对布尔型数组中的True值计数：</p>
<pre><code class="language-python">In [190]: arr = np.random.randn(100)

In [191]: (arr &gt; 0).sum() # Number of positive values
Out[191]: 42
</code></pre>
<p>另外还有两个方法any和all，它们对布尔型数组非常有用。any用于测试数组中是否存在一个或多个True，而all则检查数组中所有值是否都是True：</p>
<pre><code class="language-python">In [192]: bools = np.array([False, False, True, False])

In [193]: bools.any()
Out[193]: True

In [194]: bools.all()
Out[194]: False
</code></pre>
<p>这两个方法也能用于非布尔型数组，所有非0元素将会被当做True。</p>
<h2 id="排序">排序</h2>
<p>跟Python内置的列表类型一样，NumPy数组也可以通过sort方法就地排序：</p>
<pre><code class="language-python">In [195]: arr = np.random.randn(6)

In [196]: arr
Out[196]: array([ 0.6095, -0.4938,  1.24  , -0.1357,  1.43  , -0.8469])

In [197]: arr.sort()

In [198]: arr
Out[198]: array([-0.8469, -0.4938, -0.1357,  0.6095,  1.24  ,  1.43  ])
</code></pre>
<p>多维数组可以在任何一个轴向上进行排序，只需将轴编号传给sort即可：</p>
<pre><code class="language-python">In [199]: arr = np.random.randn(5, 3)

In [200]: arr
Out[200]: 
array([[ 0.6033,  1.2636, -0.2555],
       [-0.4457,  0.4684, -0.9616],
       [-1.8245,  0.6254,  1.0229],
       [ 1.1074,  0.0909, -0.3501],
       [ 0.218 , -0.8948, -1.7415]])

In [201]: arr.sort(1)

In [202]: arr
Out[202]: 
array([[-0.2555,  0.6033,  1.2636],
       [-0.9616, -0.4457,  0.4684],
       [-1.8245,  0.6254,  1.0229],
       [-0.3501,  0.0909,  1.1074],
       [-1.7415, -0.8948,  0.218 ]])
</code></pre>
<p>顶级方法np.sort返回的是数组的已排序副本，而就地排序则会修改数组本身。计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值：</p>
<pre><code class="language-python">In [203]: large_arr = np.random.randn(1000)

In [204]: large_arr.sort()

In [205]: large_arr[int(0.05 * len(large_arr))] # 5% quantile
Out[205]: -1.5311513550102103
</code></pre>
<p>更多关于NumPy排序方法以及诸如间接排序之类的高级技术，请参阅附录A。在pandas中还可以找到一些其他跟排序有关的数据操作（比如根据一列或多列对表格型数据进行排序）。</p>
<h2 id="唯一化以及其它的集合逻辑">唯一化以及其它的集合逻辑</h2>
<p>NumPy提供了一些针对一维ndarray的基本集合运算。最常用的可能要数np.unique了，它用于找出数组中的唯一值并返回已排序的结果：</p>
<pre><code class="language-python">numpy.unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None)
#返回：
unique_indices:return_index=True时，原始数组中唯一值首次出现的索引。
unique_inverse:return_inverse=True时，从唯一数组重建原始数组的索引。
unique_counts:return_counts=True时，每个唯一值在原始数组中出现的次数。

</code></pre>
<pre><code class="language-python">In [206]: names = np.array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])

In [207]: np.unique(names)
Out[207]: 
array(['Bob', 'Joe', 'Will'],
      dtype='&lt;U4')

In [208]: ints = np.array([3, 3, 3, 2, 2, 1, 1, 4, 4])

In [209]: np.unique(ints)
Out[209]: array([1, 2, 3, 4])
</code></pre>
<p>拿跟np.unique等价的纯Python代码来对比一下：</p>
<pre><code class="language-python">In [210]: sorted(set(names))
Out[210]: ['Bob', 'Joe', 'Will']
</code></pre>
<p>另一个函数np.in1d用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组：</p>
<pre><code class="language-python">In [211]: values = np.array([6, 0, 0, 3, 2, 5, 6])

In [212]: np.in1d(values, [2, 3, 6])
Out[212]: array([ True, False, False,  True,  True, False,  True], dtype=bool)
</code></pre>
<p>NumPy中的集合函数请参见表4-6。<br>
<img src="http://upload-images.jianshu.io/upload_images/7178691-80e85ae6b9c89ada.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></p>
<h1 id="44-用于数组的文件输入输出">4.4 用于数组的文件输入输出</h1>
<p>NumPy能够读写磁盘上的文本数据或二进制数据。这一小节只讨论NumPy的内置二进制格式，因为更多的用户会使用pandas或其它工具加载文本或表格数据（见第6章）。</p>
<p>np.save和np.load是读写磁盘数组数据的两个主要函数。默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为.npy的文件中的：</p>
<pre><code class="language-python">In [213]: arr = np.arange(10)

In [214]: np.save('some_array', arr)
</code></pre>
<p>如果文件路径末尾没有扩展名.npy，则该扩展名会被自动加上。然后就可以通过np.load读取磁盘上的数组：</p>
<pre><code class="language-python">In [215]: np.load('some_array.npy')
Out[215]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
</code></pre>
<p>通过np.savez可以将多个数组保存到一个未压缩文件中，将数组以关键字参数的形式传入即可：</p>
<pre><code class="language-python">In [216]: np.savez('array_archive.npz', a=arr, b=arr)
</code></pre>
<p>加载.npz文件时，你会得到一个类似字典的对象，该对象会对各个数组进行延迟加载：</p>
<pre><code class="language-python">In [217]: arch = np.load('array_archive.npz')

In [218]: arch['b']
Out[218]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
</code></pre>
<p>如果要将数据压缩，可以使用numpy.savez_compressed：</p>
<pre><code class="language-python">In [219]: np.savez_compressed('arrays_compressed.npz', a=arr, b=arr)
</code></pre>
<h1 id="45-线性代数">4.5 线性代数</h1>
<p>线性代数（如矩阵乘法、矩阵分解、行列式以及其他方阵数学等）是任何数组库的重要组成部分。不像某些语言（如MATLAB），通过*对两个二维数组相乘得到的是一个元素级的积，而不是一个矩阵点积。因此，NumPy提供了一个用于矩阵乘法的dot函数（既是一个数组方法也是numpy命名空间中的一个函数）：</p>
<pre><code class="language-python">In [223]: x = np.array([[1., 2., 3.], [4., 5., 6.]])

In [224]: y = np.array([[6., 23.], [-1, 7], [8, 9]])

In [225]: x
Out[225]: 
array([[ 1.,  2.,  3.],
       [ 4.,  5.,  6.]])

In [226]: y
Out[226]: 
array([[  6.,  23.],
       [ -1.,   7.],
       [  8.,   9.]])

In [227]: x.dot(y)
Out[227]: 
array([[  28.,   64.],
       [  67.,  181.]])
</code></pre>
<p>x.dot(y)等价于np.dot(x, y)：</p>
<pre><code class="language-python">In [228]: np.dot(x, y)
Out[228]: 
array([[  28.,   64.],
       [  67.,  181.]])
</code></pre>
<p>一个二维数组跟一个大小合适的一维数组的矩阵点积运算之后将会得到一个一维数组：</p>
<pre><code class="language-python">In [229]: np.dot(x, np.ones(3))
Out[229]: array([  6.,  15.])
</code></pre>
<p>@符（类似Python 3.5）也可以用作中缀运算符，进行矩阵乘法：</p>
<pre><code class="language-python">In [230]: x @ np.ones(3)
Out[230]: array([  6.,  15.])
</code></pre>
<p>numpy.linalg中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西。它们跟MATLAB和R等语言所使用的是相同的行业标准线性代数库，如BLAS、LAPACK、Intel MKL（Math Kernel Library，可能有，取决于你的NumPy版本）等：</p>
<pre><code class="language-python">In [231]: from numpy.linalg import inv, qr

In [232]: X = np.random.randn(5, 5)

In [233]: mat = X.T.dot(X)

In [234]: inv(mat)
Out[234]: 
array([[  933.1189,   871.8258, -1417.6902, -1460.4005,  1782.1391],
       [  871.8258,   815.3929, -1325.9965, -1365.9242,  1666.9347],
       [-1417.6902, -1325.9965,  2158.4424,  2222.0191, -2711.6822],
       [-1460.4005, -1365.9242,  2222.0191,  2289.0575, -2793.422 ],
       [ 1782.1391,  1666.9347, -2711.6822, -2793.422 ,  3409.5128]])

In [235]: mat.dot(inv(mat))
Out[235]: 
array([[ 1.,  0., -0., -0., -0.],
       [-0.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  0.,  0.],
       [-0.,  0.,  0.,  1., -0.],
       [-0.,  0.,  0.,  0.,  1.]])

In [236]: q, r = qr(mat)

In [237]: r
Out[237]: 
array([[-1.6914,  4.38  ,  0.1757,  0.4075, -0.7838],
       [ 0.    , -2.6436,  0.1939, -3.072 , -1.0702],
       [ 0.    ,  0.    , -0.8138,  1.5414,  0.6155],
       [ 0.    ,  0.    ,  0.    , -2.6445, -2.1669],
       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.0002]])
</code></pre>
<p>表达式X.T.dot(X)计算X和它的转置X.T的点积。</p>
<p>表4-7中列出了一些最常用的线性代数函数。</p>
<figure data-type="image" tabindex="14"><img src="http://upload-images.jianshu.io/upload_images/7178691-dcdb66e49e5f70ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<h1 id="46-伪随机数生成">4.6 伪随机数生成</h1>
<p>numpy.random模块对Python内置的random进行了补充，增加了一些用于高效生成多种概率分布的样本值的函数。例如，你可以用normal来得到一个标准正态分布的4×4样本数组：</p>
<pre><code class="language-python">In [238]: samples = np.random.normal(size=(4, 4))

In [239]: samples
Out[239]: 
array([[ 0.5732,  0.1933,  0.4429,  1.2796],
       [ 0.575 ,  0.4339, -0.7658, -1.237 ],
       [-0.5367,  1.8545, -0.92  , -0.1082],
       [ 0.1525,  0.9435, -1.0953, -0.144 ]])
</code></pre>
<p>而Python内置的random模块则只能一次生成一个样本值。从下面的测试结果中可以看出，如果需要产生大量样本值，numpy.random快了不止一个数量级：</p>
<pre><code class="language-python">In [240]: from random import normalvariate

In [241]: N = 1000000

In [242]: %timeit samples = [normalvariate(0, 1) for _ in range(N)]
1.77 s +- 126 ms per loop (mean +- std. dev. of 7 runs, 1 loop each)

In [243]: %timeit np.random.normal(size=N)
61.7 ms +- 1.32 ms per loop (mean +- std. dev. of 7 runs, 10 loops each)
</code></pre>
<p>我们说这些都是伪随机数，是因为它们都是通过算法基于随机数生成器种子，在确定性的条件下生成的。你可以用NumPy的np.random.seed更改随机数生成种子：</p>
<pre><code class="language-python">In [244]: np.random.seed(1234)
</code></pre>
<p>numpy.random的数据生成函数使用了全局的随机种子。要避免全局状态，你可以使用numpy.random.RandomState，创建一个与其它隔离的随机数生成器：</p>
<pre><code class="language-python">In [245]: rng = np.random.RandomState(1234)

In [246]: rng.randn(10)
Out[246]: 
array([ 0.4714, -1.191 ,  1.4327, -0.3127, -0.7206,  0.8872,  0.8596,
       -0.6365,  0.0157, -2.2427])
</code></pre>
<p>表4-8列出了numpy.random中的部分函数。在下一节中，我将给出一些利用这些函数一次性生成大量样本值的范例。</p>
<figure data-type="image" tabindex="15"><img src="http://upload-images.jianshu.io/upload_images/7178691-97ba09c96dab93a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="http://upload-images.jianshu.io/upload_images/7178691-6ed04fae3d1178e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<h1 id="47-示例随机漫步">4.7 示例：随机漫步</h1>
<p>我们通过模拟随机漫步来说明如何运用数组运算。先来看一个简单的随机漫步的例子：从0开始，步长1和－1出现的概率相等。</p>
<p>下面是一个通过内置的random模块以纯Python的方式实现1000步的随机漫步：</p>
<pre><code class="language-python">In [247]: import random
   .....: position = 0
   .....: walk = [position]
   .....: steps = 1000
   .....: for i in range(steps):
   .....:     step = 1 if random.randint(0, 1) else -1
   .....:     position += step
   .....:     walk.append(position)
   .....:
</code></pre>
<p>图4-4是根据前100个随机漫步值生成的折线图：</p>
<pre><code class="language-python">In [249]: plt.plot(walk[:100])
</code></pre>
<figure data-type="image" tabindex="17"><img src="http://upload-images.jianshu.io/upload_images/7178691-0833621694f6dda0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图4-4 简单的随机漫步" loading="lazy"></figure>
<p>不难看出，这其实就是随机漫步中各步的累计和，可以用一个数组运算来实现。因此，我用np.random模块一次性随机产生1000个“掷硬币”结果（即两个数中任选一个），将其分别设置为1或－1，然后计算累计和：</p>
<pre><code class="language-python">In [251]: nsteps = 1000

In [252]: draws = np.random.randint(0, 2, size=nsteps)

In [253]: steps = np.where(draws &gt; 0, 1, -1)

In [254]: walk = steps.cumsum()
</code></pre>
<p>有了这些数据之后，我们就可以沿着漫步路径做一些统计工作了，比如求取最大值和最小值：</p>
<pre><code class="language-python">In [255]: walk.min()
Out[255]: -3

In [256]: walk.max()
Out[256]: 31
</code></pre>
<p>现在来看一个复杂点的统计任务——首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。假设我们想要知道本次随机漫步需要多久才能距离初始0点至少10步远（任一方向均可）。np.abs(walk)&gt;=10可以得到一个布尔型数组，它表示的是距离是否达到或超过10，而我们想要知道的是第一个10或－10的索引。可以用argmax来解决这个问题，它返回的是该布尔型数组第一个最大值的索引（True就是最大值）：</p>
<pre><code class="language-python">In [257]: (np.abs(walk) &gt;= 10).argmax()
Out[257]: 37
</code></pre>
<p>注意，这里使用argmax并不是很高效，因为它无论如何都会对数组进行完全扫描。在本例中，只要发现了一个True，那我们就知道它是个最大值了。</p>
<h2 id="一次模拟多个随机漫步">一次模拟多个随机漫步</h2>
<p>如果你希望模拟多个随机漫步过程（比如5000个），只需对上面的代码做一点点修改即可生成所有的随机漫步过程。只要给numpy.random的函数传入一个二元元组就可以产生一个二维数组，然后我们就可以一次性计算5000个随机漫步过程（一行一个）的累计和了：</p>
<pre><code class="language-python">In [258]: nwalks = 5000

In [259]: nsteps = 1000

In [260]: draws = np.random.randint(0, 2, size=(nwalks, nsteps)) # 0 or 1

In [261]: steps = np.where(draws &gt; 0, 1, -1)

In [262]: walks = steps.cumsum(1)

In [263]: walks
Out[263]: 
array([[  1,   0,   1, ...,   8,   7,   8],
       [  1,   0,  -1, ...,  34,  33,  32],
       [  1,   0,  -1, ...,   4,   5,   4],
       ..., 
       [  1,   2,   1, ...,  24,  25,  26],
       [  1,   2,   3, ...,  14,  13,  14],
       [ -1,  -2,  -3, ..., -24, -23, -22]])
</code></pre>
<p>现在，我们来计算所有随机漫步过程的最大值和最小值：</p>
<pre><code class="language-python">In [264]: walks.max()
Out[264]: 138

In [265]: walks.min()
Out[265]: -133
</code></pre>
<p>得到这些数据之后，我们来计算30或－30的最小穿越时间。这里稍微复杂些，因为不是5000个过程都到达了30。我们可以用any方法来对此进行检查：</p>
<pre><code class="language-python">In [266]: hits30 = (np.abs(walks) &gt;= 30).any(1)

In [267]: hits30
Out[267]: array([False,  True, False, ..., False,  True, False], dtype=bool)

In [268]: hits30.sum() # Number that hit 30 or -30
Out[268]: 3410
</code></pre>
<p>然后我们利用这个布尔型数组选出那些穿越了30（绝对值）的随机漫步（行），并调用argmax在轴1上获取穿越时间：</p>
<pre><code class="language-python">In [269]: crossing_times = (np.abs(walks[hits30]) &gt;= 30).argmax(1)

In [270]: crossing_times.mean()
Out[270]: 498.88973607038122
</code></pre>
<p>请尝试用其他分布方式得到漫步数据。只需使用不同的随机数生成函数即可，如normal用于生成指定均值和标准差的正态分布数据：</p>
<pre><code class="language-python">In [271]: steps = np.random.normal(loc=0, scale=0.25,
   .....:                          size=(nwalks, nsteps))
</code></pre>
<h1 id="48-结论">4.8 结论</h1>
<p>虽然本书剩下的章节大部分是用pandas规整数据，我们还是会用到相似的基于数组的计算。在附录A中，我们会深入挖掘NumPy的特点，进一步学习数组的技巧。</p>
<h1 id="49-numpy高级应用">4.9 Numpy高级应用</h1>
<p>在这篇附录中，我会深入NumPy库的数组计算。这会包括ndarray更内部的细节，和更高级的数组操作和算法。</p>
<p>本章包括了一些杂乱的章节，不需要仔细研究。</p>
<h1 id="a1-ndarray对象的内部机理">A.1 ndarray对象的内部机理</h1>
<p>NumPy的ndarray提供了一种将同质数据块（可以是连续或跨越）解释为多维数组对象的方式。正如你之前所看到的那样，数据类型（dtype）决定了数据的解释方式，比如浮点数、整数、布尔值等。</p>
<p>ndarray如此强大的部分原因是所有数组对象都是数据块的一个跨度视图（strided view）。你可能想知道数组视图arr[::2,::-1]不复制任何数据的原因是什么。简单地说，ndarray不只是一块内存和一个dtype，它还有跨度信息，这使得数组能以各种步幅（step size）在内存中移动。更准确地讲，ndarray内部由以下内容组成：</p>
<ul>
<li>一个指向数据（内存或内存映射文件中的一块数据）的指针。</li>
<li>数据类型或dtype，描述在数组中的固定大小值的格子。</li>
<li>一个表示数组形状（shape）的元组。</li>
<li>一个跨度元组（stride），其中的整数指的是为了前进到当前维度下一个元素需要“跨过”的字节数。</li>
</ul>
<p>图A-1简单地说明了ndarray的内部结构。</p>
<figure data-type="image" tabindex="18"><img src="https://upload-images.jianshu.io/upload_images/7178691-43452f2f413e5094.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-1 Numpy的ndarray对象" loading="lazy"></figure>
<p>例如，一个10×5的数组，其形状为(10,5)：</p>
<pre><code class="language-python">In [10]: np.ones((10, 5)).shape
Out[10]: (10, 5)
</code></pre>
<p>一个典型的（C顺序，稍后将详细讲解）3×4×5的float64（8个字节）数组，其跨度为(160,40,8) —— 知道跨度是非常有用的，通常，跨度在一个轴上越大，沿这个轴进行计算的开销就越大：</p>
<pre><code class="language-python">In [11]: np.ones((3, 4, 5), dtype=np.float64).strides
Out[11]: (160, 40, 8)
</code></pre>
<p>虽然NumPy用户很少会对数组的跨度信息感兴趣，但它们却是构建非复制式数组视图的重要因素。跨度甚至可以是负数，这样会使数组在内存中后向移动，比如在切片obj[::-1]或obj[:,::-1]中就是这样的。</p>
<h2 id="numpy数据类型体系">NumPy数据类型体系</h2>
<p>你可能偶尔需要检查数组中所包含的是否是整数、浮点数、字符串或Python对象。因为浮点数的种类很多（从float16到float128），判断dtype是否属于某个大类的工作非常繁琐。幸运的是，dtype都有一个超类（比如np.integer和np.floating），它们可以跟np.issubdtype函数结合使用：</p>
<pre><code class="language-python">In [12]: ints = np.ones(10, dtype=np.uint16)

In [13]: floats = np.ones(10, dtype=np.float32)

In [14]: np.issubdtype(ints.dtype, np.integer)
Out[14]: True

In [15]: np.issubdtype(floats.dtype, np.floating)
Out[15]: True
</code></pre>
<p>调用dtype的mro方法即可查看其所有的父类：</p>
<pre><code class="language-python">In [16]: np.float64.mro()
Out[16]:
[numpy.float64,
 numpy.floating,
 numpy.inexact,
 numpy.number,
 numpy.generic,
 float,
 object]
</code></pre>
<p>然后得到：</p>
<pre><code class="language-python">In [17]: np.issubdtype(ints.dtype, np.number)
Out[17]: True
</code></pre>
<p>大部分NumPy用户完全不需要了解这些知识，但是这些知识偶尔还是能派上用场的。图A-2说明了dtype体系以及父子类关系。</p>
<figure data-type="image" tabindex="19"><img src="http://upload-images.jianshu.io/upload_images/7178691-b8996bf943a06ab9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-2 NumPy的dtype体系" loading="lazy"></figure>
<h1 id="a2-高级数组操作">A.2 高级数组操作</h1>
<p>除花式索引、切片、布尔条件取子集等操作之外，数组的操作方式还有很多。虽然pandas中的高级函数可以处理数据分析工作中的许多重型任务，但有时你还是需要编写一些在现有库中找不到的数据算法。</p>
<h2 id="数组重塑">数组重塑</h2>
<p>多数情况下，你可以无需复制任何数据，就将数组从一个形状转换为另一个形状。只需向数组的实例方法reshape传入一个表示新形状的元组即可实现该目的。例如，假设有一个一维数组，我们希望将其重新排列为一个矩阵（结果见图A-3）：</p>
<pre><code class="language-python">In [18]: arr = np.arange(8)

In [19]: arr
Out[19]: array([0, 1, 2, 3, 4, 5, 6, 7])

In [20]: arr.reshape((4, 2))
Out[20]: 
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7]])
</code></pre>
<figure data-type="image" tabindex="20"><img src="http://upload-images.jianshu.io/upload_images/7178691-95bbca6d8d04e4c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-3 按C顺序（按行）和按Fortran顺序（按列）进行重塑" loading="lazy"></figure>
<p>多维数组也能被重塑：</p>
<pre><code class="language-python">In [21]: arr.reshape((4, 2)).reshape((2, 4))
Out[21]: 
array([[0, 1, 2, 3],
       [4, 5, 6, 7]])
</code></pre>
<p>作为参数的形状的其中一维可以是－1，它表示该维度的大小由数据本身推断而来：</p>
<pre><code class="language-python">In [22]: arr = np.arange(15)

In [23]: arr.reshape((5, -1))
Out[23]: 
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])
</code></pre>
<p>与reshape将一维数组转换为多维数组的运算过程相反的运算通常称为扁平化（flattening）或散开（raveling）：</p>
<pre><code class="language-python">In [27]: arr = np.arange(15).reshape((5, 3))

In [28]: arr
Out[28]: 
array([[ 0,  1,  2],
       [ 3,  4,  5],
       [ 6,  7,  8],
       [ 9, 10, 11],
       [12, 13, 14]])

In [29]: arr.ravel()
Out[29]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])
</code></pre>
<p>如果结果中的值与原始数组相同，ravel不会产生源数据的副本。flatten方法的行为类似于ravel，只不过它总是返回数据的副本：</p>
<pre><code class="language-python">In [30]: arr.flatten()
Out[30]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])
</code></pre>
<p>数组可以被重塑或散开为别的顺序。这对NumPy新手来说是一个比较微妙的问题，所以在下一小节中我们将专门讲解这个问题。</p>
<h2 id="c和fortran顺序">C和Fortran顺序</h2>
<p>NumPy允许你更为灵活地控制数据在内存中的布局。默认情况下，NumPy数组是按行优先顺序创建的。在空间方面，这就意味着，对于一个二维数组，每行中的数据项是被存放在相邻内存位置上的。另一种顺序是列优先顺序，它意味着每列中的数据项是被存放在相邻内存位置上的。</p>
<p>由于一些历史原因，行和列优先顺序又分别称为C和Fortran顺序。在FORTRAN 77中，矩阵全都是列优先的。</p>
<p>像reshape和reval这样的函数，都可以接受一个表示数组数据存放顺序的order参数。一般可以是'C'或'F'（还有'A'和'K'等不常用的选项，具体请参考NumPy的文档）。图A-3对此进行了说明：</p>
<pre><code class="language-python">In [31]: arr = np.arange(12).reshape((3, 4))

In [32]: arr
Out[32]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])

In [33]: arr.ravel()
Out[33]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])

In [34]: arr.ravel('F')
Out[34]: array([ 0,  4,  8,  1,  5,  9,  2,  6, 10,  3,  7, 11])
</code></pre>
<figure data-type="image" tabindex="21"><img src="http://upload-images.jianshu.io/upload_images/7178691-f486e7c41d7e0eec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-3 按C（行优先）或Fortran（列优先）顺序进行重塑" loading="lazy"></figure>
<p>二维或更高维数组的重塑过程比较令人费解（见图A-3）。C和Fortran顺序的关键区别就是维度的行进顺序：</p>
<ul>
<li>C/行优先顺序：先经过更高的维度（例如，轴1会先于轴0被处理）。</li>
<li>Fortran/列优先顺序：后经过更高的维度（例如，轴0会先于轴1被处理）。</li>
</ul>
<h2 id="数组的合并和拆分">数组的合并和拆分</h2>
<p>numpy.concatenate可以按指定轴将一个由数组组成的序列（如元组、列表等）连接到一起：</p>
<pre><code class="language-python">In [35]: arr1 = np.array([[1, 2, 3], [4, 5, 6]])

In [36]: arr2 = np.array([[7, 8, 9], [10, 11, 12]])

In [37]: np.concatenate([arr1, arr2], axis=0)
Out[37]: 
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])

In [38]: np.concatenate([arr1, arr2], axis=1)
Out[38]: 
array([[ 1,  2,  3,  7,  8,  9],
       [ 4,  5,  6, 10, 11, 12]])
</code></pre>
<p>对于常见的连接操作，NumPy提供了一些比较方便的方法（如vstack和hstack）。因此，上面的运算还可以表达为：</p>
<pre><code class="language-python">In [39]: np.vstack((arr1, arr2))
Out[39]: 
array([[ 1,  2,  3],
       [ 4,  5,  6],
       [ 7,  8,  9],
       [10, 11, 12]])

In [40]: np.hstack((arr1, arr2))
Out[40]: 
array([[ 1,  2,  3,  7,  8,  9],
[ 4,  5,  6, 10, 11, 12]])
</code></pre>
<p>与此相反，split用于将一个数组沿指定轴拆分为多个数组：</p>
<pre><code class="language-python">In [41]: arr = np.random.randn(5, 2)

In [42]: arr
Out[42]: 
array([[-0.2047,  0.4789],
       [-0.5194, -0.5557],
       [ 1.9658,  1.3934],
       [ 0.0929,  0.2817],
       [ 0.769 ,  1.2464]])

In [43]: first, second, third = np.split(arr, [1, 3])

In [44]: first
Out[44]: array([[-0.2047,  0.4789]])

In [45]: second
Out[45]: 
array([[-0.5194, -0.5557],
       [ 1.9658,  1.3934]])
In [46]: third
Out[46]: 
array([[ 0.0929,  0.2817],
       [ 0.769 ,  1.2464]])
</code></pre>
<p>传入到np.split的值[1,3]指示在哪个索引处分割数组。</p>
<p>表A-1中列出了所有关于数组连接和拆分的函数，其中有些是专门为了方便常见的连接运算而提供的。</p>
<figure data-type="image" tabindex="22"><img src="http://upload-images.jianshu.io/upload_images/7178691-c597246722a6bb01.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A-1 数组连接函数" loading="lazy"></figure>
<h2 id="堆叠辅助类r_和c_">堆叠辅助类：r_和c_</h2>
<p>NumPy命名空间中有两个特殊的对象——r_和c_，它们可以使数组的堆叠操作更为简洁：</p>
<pre><code class="language-python">In [47]: arr = np.arange(6)

In [48]: arr1 = arr.reshape((3, 2))

In [49]: arr2 = np.random.randn(3, 2)

In [50]: np.r_[arr1, arr2]
Out[50]: 
array([[ 0.    ,  1.    ],
       [ 2.    ,  3.    ],
       [ 4.    ,  5.    ],
       [ 1.0072, -1.2962],
       [ 0.275 ,  0.2289],
       [ 1.3529,  0.8864]])

In [51]: np.c_[np.r_[arr1, arr2], arr]
Out[51]: 
array([[ 0.    ,  1.    ,  0.    ],
       [ 2.    ,  3.    ,  1.    ],
       [ 4.    ,  5.    ,  2.    ],
       [ 1.0072, -1.2962,  3.    ],
       [ 0.275 ,  0.2289,  4.    ],
       [ 1.3529,  0.8864,  5.    ]])
</code></pre>
<p>它还可以将切片转换成数组：</p>
<pre><code class="language-python">In [52]: np.c_[1:6, -10:-5]
Out[52]: 
array([[  1, -10],
       [  2,  -9],
       [  3,  -8],
       [  4,  -7],
       [  5,  -6]])
</code></pre>
<p>r_和c_的具体功能请参考其文档。</p>
<h2 id="元素的重复操作tile和repeat">元素的重复操作：tile和repeat</h2>
<p>对数组进行重复以产生更大数组的工具主要是repeat和tile这两个函数。repeat会将数组中的各个元素重复一定次数，从而产生一个更大的数组：</p>
<pre><code class="language-python">In [53]: arr = np.arange(3)

In [54]: arr
Out[54]: array([0, 1, 2])

In [55]: arr.repeat(3)
Out[55]: array([0, 0, 0, 1, 1, 1, 2, 2, 2])
</code></pre>
<blockquote>
<p>笔记：跟其他流行的数组编程语言（如MATLAB）不同，NumPy中很少需要对数组进行重复（replicate）。这主要是因为广播（broadcasting，我们将在下一节中讲解该技术）能更好地满足该需求。</p>
</blockquote>
<p>默认情况下，如果传入的是一个整数，则各元素就都会重复那么多次。如果传入的是一组整数，则各元素就可以重复不同的次数：</p>
<pre><code class="language-python">In [56]: arr.repeat([2, 3, 4])
Out[56]: array([0, 0, 1, 1, 1, 2, 2, 2, 2])
</code></pre>
<p>对于多维数组，还可以让它们的元素沿指定轴重复：</p>
<pre><code class="language-python">In [57]: arr = np.random.randn(2, 2)

In [58]: arr
Out[58]: 
array([[-2.0016, -0.3718],
       [ 1.669 , -0.4386]])

In [59]: arr.repeat(2, axis=0)
Out[59]: 
array([[-2.0016, -0.3718],
       [-2.0016, -0.3718],
       [ 1.669 , -0.4386],
       [ 1.669 , -0.4386]])
</code></pre>
<p>注意，如果没有设置轴向，则数组会被扁平化，这可能不会是你想要的结果。同样，在对多维进行重复时，也可以传入一组整数，这样就会使各切片重复不同的次数：</p>
<pre><code class="language-python">In [60]: arr.repeat([2, 3], axis=0)
Out[60]: 
array([[-2.0016, -0.3718],
       [-2.0016, -0.3718],
       [ 1.669 , -0.4386],
       [ 1.669 , -0.4386],
       [ 1.669 , -0.4386]])

In [61]: arr.repeat([2, 3], axis=1)
Out[61]: 
array([[-2.0016, -2.0016, -0.3718, -0.3718, -0.3718],
       [ 1.669 ,  1.669 , -0.4386, -0.4386, -0.4386]])
</code></pre>
<p>tile的功能是沿指定轴向堆叠数组的副本。你可以形象地将其想象成“铺瓷砖”：</p>
<pre><code class="language-python">In [62]: arr
Out[62]: 
array([[-2.0016, -0.3718],
       [ 1.669 , -0.4386]])

In [63]: np.tile(arr, 2)
Out[63]: 
array([[-2.0016, -0.3718, -2.0016, -0.3718],
       [ 1.669 , -0.4386,  1.669 , -0.4386]])
</code></pre>
<p>第二个参数是瓷砖的数量。对于标量，瓷砖是水�����铺设的，而不是垂直铺设。它可以是一个表示“铺设”布局的元组：</p>
<pre><code class="language-python">In [64]: arr
Out[64]: 
array([[-2.0016, -0.3718],
       [ 1.669 , -0.4386]])

In [65]: np.tile(arr, (2, 1))
Out[65]: 
array([[-2.0016, -0.3718],
       [ 1.669 , -0.4386],
       [-2.0016, -0.3718],
       [ 1.669 , -0.4386]])

In [66]: np.tile(arr, (3, 2))
Out[66]: 
array([[-2.0016, -0.3718, -2.0016, -0.3718],
       [ 1.669 , -0.4386,  1.669 , -0.4386],
       [-2.0016, -0.3718, -2.0016, -0.3718],
       [ 1.669 , -0.4386,  1.669 , -0.4386],
       [-2.0016, -0.3718, -2.0016, -0.3718],
       [ 1.669 , -0.4386,  1.669 , -0.4386]])
</code></pre>
<h2 id="花式索引的等价函数take和put">花式索引的等价函数：take和put</h2>
<p>在第4章中我们讲过，获取和设置数组子集的一个办法是通过整数数组使用花式索引：</p>
<pre><code class="language-python">In [67]: arr = np.arange(10) * 100

In [68]: inds = [7, 1, 2, 6]

In [69]: arr[inds]
Out[69]: array([700, 100, 200, 600])
</code></pre>
<p>ndarray还有其它方法用于获取单个轴向上的选区：</p>
<pre><code class="language-python">In [70]: arr.take(inds)
Out[70]: array([700, 100, 200, 600])

In [71]: arr.put(inds, 42)

In [72]: arr
Out[72]: array([  0,  42,  42, 300, 400, 500,  42,  42,800, 900])

In [73]: arr.put(inds, [40, 41, 42, 43])

In [74]: arr
Out[74]: array([  0,  41,  42, 300, 400, 500,  43,  40, 800, 900])
</code></pre>
<p>要在其它轴上使用take，只需传入axis关键字即可：</p>
<pre><code class="language-python">In [75]: inds = [2, 0, 2, 1]

In [76]: arr = np.random.randn(2, 4)

In [77]: arr
Out[77]: 
array([[-0.5397,  0.477 ,  3.2489, -1.0212],
       [-0.5771,  0.1241,  0.3026,  0.5238]])

In [78]: arr.take(inds, axis=1)
Out[78]: 
array([[ 3.2489, -0.5397,  3.2489,  0.477 ],
       [ 0.3026, -0.5771,  0.3026,  0.1241]])
</code></pre>
<p>put不接受axis参数，它只会在数组的扁平化版本（一维，C顺序）上进行索引。因此，在需要用其他轴向的索引设置元素时，最好还是使用花式索引。</p>
<h1 id="a3-广播">A.3 广播</h1>
<p>广播（broadcasting）指的是不同形状的数组之间的算术运算的执行方式。它是一种非常强大的功能，但也容易令人误解，即使是经验丰富的老手也是如此。将标量值跟数组合并时就会发生最简单的广播：</p>
<pre><code class="language-python">In [79]: arr = np.arange(5)

In [80]: arr
Out[80]: array([0, 1, 2, 3, 4])

In [81]: arr * 4
Out[81]: array([ 0,  4,  8, 12, 16])
</code></pre>
<p>这里我们说：在这个乘法运算中，标量值4被广播到了其他所有的元素上。<br>
Broadcast（广播）的规则：</p>
<ol>
<li>让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐</li>
<li>输出数组的shape是输入数组shape的各个轴上的最大值</li>
<li>如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错</li>
<li>当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值<br>
两个array的shape长度与shape的每个对应值都相等的时候，那么结果就是对应元素逐元素运算，运算的结果shape不变。shape长度不相等时，先把短的shape前面一直补1，直到与长的shape长度相等时，此时，两个array的shape对应位置上的值 ：</li>
<li>相等;</li>
<li>其中一个为1;<br>
满足其一才能进行广播。<br>
譬如：</li>
</ol>
<pre><code class="language-python">#可以广播
A      (4d array):  8 x 1 x 6 x 1
B      (3d array):      7 x 1 x 5
Result (4d array):  8 x 7 x 6 x 5
#不可以广播
A  (2d array):      2 x 1
B  (3d array):  8 x 4 x 3（倒数第二维不匹配）
</code></pre>
<p>看一个例子，我们可以通过减去列平均值的方式对数组的每一列进行距平化处理。这个问题解决起来非常简单：</p>
<pre><code class="language-python">In [82]: arr = np.random.randn(4, 3)

In [83]: arr.mean(0)
Out[83]: array([-0.3928, -0.3824, -0.8768])

In [84]: demeaned = arr - arr.mean(0)

In [85]: demeaned
Out[85]: 
array([[ 0.3937,  1.7263,  0.1633],
       [-0.4384, -1.9878, -0.9839],
       [-0.468 ,  0.9426, -0.3891],
       [ 0.5126, -0.6811,  1.2097]])

In [86]: demeaned.mean(0)
Out[86]: array([-0.,  0., -0.])
</code></pre>
<p>图A-4形象地展示了该过程。用广播的方式对行进行距平化处理会稍微麻烦一些。幸运的是，只要遵循一定的规则，低维度的值是可以被广播到数组的任意维度的（比如对二维数组各列减去行平均值）。</p>
<figure data-type="image" tabindex="23"><img src="http://upload-images.jianshu.io/upload_images/7178691-6aaf022ab88452a9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-4 一维数组在轴0上的广播" loading="lazy"></figure>
<p>于是就得到了：</p>
<figure data-type="image" tabindex="24"><img src="http://upload-images.jianshu.io/upload_images/7178691-fcaba8455960862a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<p>虽然我是一名经验丰富的NumPy老手，但经常还是得停下来画张图并想想广播的原则。再来看一下最后那个例子，假设你希望对各行减去那个平均值。由于arr.mean(0)的长度为3，所以它可以在0轴向上进行广播：因为arr的后缘维度是3，所以它们是兼容的。根据该原则，要在1轴向上做减法（即各行减去行平均值），较小的那个数组的形状必须是(4,1)：</p>
<pre><code class="language-python">In [87]: arr
Out[87]: 
array([[ 0.0009,  1.3438, -0.7135],
       [-0.8312, -2.3702, -1.8608],
       [-0.8608,  0.5601, -1.2659],
       [ 0.1198, -1.0635,  0.3329]])

In [88]: row_means = arr.mean(1)

In [89]: row_means.shape
Out[89]: (4,)

In [90]: row_means.reshape((4, 1))
Out[90]: 
array([[ 0.2104],
       [-1.6874],
       [-0.5222],
       [-0.2036]])

In [91]: demeaned = arr - row_means.reshape((4, 1))

In [92]: demeaned.mean(1)
Out[92]: array([ 0., -0.,  0.,  0.])
</code></pre>
<p>图A-5说明了该运算的过程。</p>
<figure data-type="image" tabindex="25"><img src="http://upload-images.jianshu.io/upload_images/7178691-9b0310d6773c3d38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-5 二维数组在轴1上的广播" loading="lazy"></figure>
<p>图A-6展示了另外一种情况，这次是在一个三维数组上沿0轴向加上一个二维数组。</p>
<figure data-type="image" tabindex="26"><img src="http://upload-images.jianshu.io/upload_images/7178691-965eb28b60046cd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-6 三维数组在轴0上的广播" loading="lazy"></figure>
<h2 id="沿其它轴向广播">沿其它轴向广播</h2>
<p>高维度数组的广播似乎更难以理解，而实际上它也是遵循广播原则的。如果不然，你就会得到下面这样一个错误：</p>
<pre><code class="language-python">In [93]: arr - arr.mean(1)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-93-7b87b85a20b2&gt; in &lt;module&gt;()
----&gt; 1 arr - arr.mean(1)
ValueError: operands could not be broadcast together with shapes (4,3) (4,)
</code></pre>
<p>人们经常需要通过算术运算过程将较低维度的数组在除0轴以外的其他轴向上广播。根据广播的原则，较小数组的“广播维”必须为1。在上面那个行距平化的例子中，这就意味着要将行平均值的形状变成(4,1)而不是(4,)：</p>
<pre><code class="language-python">In [94]: arr - arr.mean(1).reshape((4, 1))
Out[94]: 
array([[-0.2095,  1.1334, -0.9239],
       [ 0.8562, -0.6828, -0.1734],
       [-0.3386,  1.0823, -0.7438],
       [ 0.3234, -0.8599,  0.5365]])
</code></pre>
<p>对于三维的情况，在三维中的任何一维上广播其实也就是将数据重塑为兼容的形状而已。图A-7说明了要在三维数组各维度上广播的形状需求。</p>
<figure data-type="image" tabindex="27"><img src="http://upload-images.jianshu.io/upload_images/7178691-b40936aab8e757d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图A-7：能在该三维数组上广播的二维数组的形状" loading="lazy"></figure>
<p>于是就有了一个非常普遍的问题（尤其是在通用算法中），即专门为了广播而添加一个长度为1的新轴。虽然reshape是一个办法，但插入轴需要构造一个表示新形状的元组。这是一个很郁闷的过程。因此，NumPy数组提供了一种通过索引机制插入轴的特殊语法。下面这段代码通过特殊的np.newaxis属性以及“全”切片来插入新轴：</p>
<pre><code class="language-python">In [95]: arr = np.zeros((4, 4))

In [96]: arr_3d = arr[:, np.newaxis, :]

In [97]: arr_3d.shape
Out[97]: (4, 1, 4)

In [98]: arr_1d = np.random.normal(size=3)

In [99]: arr_1d[:, np.newaxis]
Out[99]: 
array([[-2.3594],
       [-0.1995],
       [-1.542 ]])

In [100]: arr_1d[np.newaxis, :]
Out[100]: array([[-2.3594, -0.1995, -1.542 ]])
</code></pre>
<p>因此，如果我们有一个三维数组，并希望对轴2进行距平化，那么只需要编写下面这样的代码就可以了：</p>
<pre><code class="language-python">In [101]: arr = np.random.randn(3, 4, 5)

In [102]: depth_means = arr.mean(2)

In [103]: depth_means
Out[103]: 
array([[-0.4735,  0.3971, -0.0228,  0.2001],
       [-0.3521, -0.281 , -0.071 , -0.1586],
       [ 0.6245,  0.6047,  0.4396, -0.2846]])

In [104]: depth_means.shape
Out[104]: (3, 4)

In [105]: demeaned = arr - depth_means[:, :, np.newaxis]

In [106]: demeaned.mean(2)
Out[106]: 
array([[ 0.,  0., -0., -0.],
       [ 0.,  0., -0.,  0.],
       [ 0.,  0., -0., -0.]])
</code></pre>
<p>有些读者可能会想，在对指定轴进行距平化时，有没有一种既通用又不牺牲性能的方法呢？实际上是有的，但需要一些索引方面的技巧：</p>
<pre><code class="language-python">def demean_axis(arr, axis=0):
    means = arr.mean(axis)

    # This generalizes things like [:, :, np.newaxis] to N dimensions
    indexer = [slice(None)] * arr.ndim#slice(None)等价于:,
    indexer[axis] = np.newaxis
    return arr - means[indexer]
</code></pre>
<h2 id="通过广播设置数组的值">通过广播设置数组的值</h2>
<p>算术运算所遵循的广播原则同样也适用于通过索引机制设置数组值的操作。对于最简单的情况，我们可以这样做：</p>
<pre><code class="language-python">In [107]: arr = np.zeros((4, 3))

In [108]: arr[:] = 5

In [109]: arr
Out[109]: 
array([[ 5.,  5.,  5.],
       [ 5.,  5.,  5.],
       [ 5.,  5.,  5.],
       [ 5.,  5.,  5.]])
</code></pre>
<p>但是，假设我们想要用一个一维数组来设置目标数组的各列，只要保证形状兼容就可以了：</p>
<pre><code class="language-python">In [110]: col = np.array([1.28, -0.42, 0.44, 1.6])
In [111]: arr[:] = col[:, np.newaxis]

In [112]: arr
Out[112]: 
array([[ 1.28,  1.28,  1.28],
       [-0.42, -0.42, -0.42],
       [ 0.44,  0.44,  0.44],
       [ 1.6 ,  1.6 ,  1.6 ]])

In [113]: arr[:2] = [[-1.37], [0.509]]

In [114]: arr
Out[114]: 
array([[-1.37 , -1.37 , -1.37 ],
       [ 0.509,  0.509,  0.509],
       [ 0.44 ,  0.44 ,  0.44 ],
       [ 1.6  ,  1.6  ,  1.6  ]])
</code></pre>
<h1 id="a4-ufunc高级应用">A.4 ufunc高级应用</h1>
<p>虽然许多NumPy用户只会用到通用函数所提供的快速的元素级运算，但通用函数实际上还有一些高级用法能使我们丢开循环而编写出更为简洁的代码。</p>
<h2 id="ufunc实例方法">ufunc实例方法</h2>
<p>NumPy的各个二元ufunc都有一些用于执行特定矢量化运算的特殊方法。表A-2汇总了这些方法，下面我将通过几个具体的例子对它们进行说明。</p>
<p>reduce接受一个数组参数，并通过一系列的二元运算对其值进行聚合（可指明轴向）。例如，我们可以用np.add.reduce对数组中各个元素进行求和：</p>
<pre><code class="language-python">In [115]: arr = np.arange(10)

In [116]: np.add.reduce(arr)
Out[116]: 45

In [117]: arr.sum()
Out[117]: 45
</code></pre>
<p>起始值取决于ufunc（对于add的情况，就是0）。如果设置了轴号，约简运算就会沿该轴向执行。这就使你能用一种比较简洁的方式得到某些问题的答案。在下面这个例子中，我们用np.logical_and检查数组各行中的值是否是有序的：</p>
<pre><code class="language-python">In [118]: np.random.seed(12346)  # for reproducibility

In [119]: arr = np.random.randn(5, 5)

In [120]: arr[::2].sort(1) # sort a few rows

In [121]: arr[:, :-1] &lt; arr[:, 1:]
Out[121]: 
array([[ True,  True,  True,  True],
       [False,  True, False, False],
       [ True,  True,  True,  True],
       [ True, False,  True,  True],
       [ True,  True,  True,  True]], dtype=bool)

In [122]: np.logical_and.reduce(arr[:, :-1] &lt; arr[:, 1:], axis=1)
Out[122]: array([ True, False,  True, False,  True], dtype=bool)
</code></pre>
<p>注意，logical_and.reduce跟all方法是等价的。</p>
<p>ccumulate跟reduce的关系就像cumsum跟sum的关系那样。它产生一个跟原数组大小相同的中间“累计”值数组：</p>
<pre><code class="language-python">In [123]: arr = np.arange(15).reshape((3, 5))

In [124]: np.add.accumulate(arr, axis=1)
Out[124]: 
array([[ 0,  1,  3,  6, 10],
       [ 5, 11, 18, 26, 35],
       [10, 21, 33, 46, 60]])
</code></pre>
<p>outer用于计算两个数组的叉积：</p>
<pre><code class="language-python">In [125]: arr = np.arange(3).repeat([1, 2, 2])

In [126]: arr
Out[126]: array([0, 1, 1, 2, 2])

In [127]: np.multiply.outer(arr, np.arange(5))
Out[127]: 
array([[0, 0, 0, 0, 0],
       [0, 1, 2, 3, 4],
       [0, 1, 2, 3, 4],
       [0, 2, 4, 6, 8],
       [0, 2, 4, 6, 8]])
</code></pre>
<p>outer输出结果的维度是两个输入数据的维度之和：</p>
<pre><code class="language-python">In [128]: x, y = np.random.randn(3, 4), np.random.randn(5)

In [129]: result = np.subtract.outer(x, y)

In [130]: result.shape
Out[130]: (3, 4, 5)
</code></pre>
<p>最后一个方法reduceat用于计算“局部约简”，其实就是一个对数据各切片进行聚合的groupby运算。它接受一组用于指示如何对值进行拆分和聚合的“面元边界”：</p>
<pre><code class="language-python">In [131]: arr = np.arange(10)

In [132]: np.add.reduceat(arr, [0, 5, 8])
Out[132]: array([10, 18, 17])
</code></pre>
<p>最终结果是在arr[0:5]、arr[5:8]以及arr[8:]上执行的约简。跟其他方法一样，这里也可以传入一个axis参数：</p>
<pre><code class="language-python">In [133]: arr = np.multiply.outer(np.arange(4), np.arange(5))

In [134]: arr
Out[134]: 
array([[ 0,  0,  0,  0,  0],
       [ 0,  1,  2,  3,  4],
       [ 0,  2,  4,  6,  8],
       [ 0,  3,  6,  9, 12]])

In [135]: np.add.reduceat(arr, [0, 2, 4], axis=1)
Out[135]: 
array([[ 0,  0,  0],
       [ 1,  5,  4],
       [ 2, 10,  8],
       [ 3, 15, 12]])
</code></pre>
<p>表A-2总结了部分的ufunc方法。</p>
<figure data-type="image" tabindex="28"><img src="http://upload-images.jianshu.io/upload_images/7178691-c997bd45000f7b72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A ufunc方法" loading="lazy"></figure>
<h2 id="编写新的ufunc">编写新的ufunc</h2>
<p>有多种方法可以让你编写自己的NumPy ufuncs。最常见的是使用NumPy C API，但它超越了本书的范围。在本节，我们讲纯粹的Python ufunc。</p>
<p>numpy.frompyfunc接受一个Python函数以及两个分别表示输入输出参数数量的参数。例如，下面是一个能够实现元素级加法的简单函数：</p>
<pre><code class="language-python">In [136]: def add_elements(x, y):
   .....:     return x + y

In [137]: add_them = np.frompyfunc(add_elements, 2, 1)

In [138]: add_them(np.arange(8), np.arange(8))
Out[138]: array([0, 2, 4, 6, 8, 10, 12, 14], dtype=object)
</code></pre>
<p>用frompyfunc创建的函数总是返回Python对象数组，这一点很不方便。幸运的是，还有另一个办法，即numpy.vectorize。虽然没有frompyfunc那么强大，但可以让你指定输出类型：</p>
<pre><code class="language-python">In [139]: add_them = np.vectorize(add_elements, otypes=[np.float64])

In [140]: add_them(np.arange(8), np.arange(8))
Out[140]: array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.])
</code></pre>
<p>虽然这两个函数提供了一种创建ufunc型函数的手段，但它们非常慢，因为它们在计算每个元素时都要执行一次Python函数调用，这就会比NumPy自带的基于C的ufunc慢很多：</p>
<pre><code class="language-python">In [141]: arr = np.random.randn(10000)

In [142]: %timeit add_them(arr, arr)
4.12 ms +- 182 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

In [143]: %timeit np.add(arr, arr)
6.89 us +- 504 ns per loop (mean +- std. dev. of 7 runs, 100000 loops each)
</code></pre>
<p>本章的后面，我会介绍使用Numba（http://numba.pydata.org/），创建快速Python ufuncs。</p>
<h1 id="a5-结构化和记录式数组">A.5 结构化和记录式数组</h1>
<p>你可能已经注意到了，到目前为止我们所讨论的ndarray都是一种同质数据容器，也就是说，在它所表示的内存块中，各元素占用的字节数相同（具体根据dtype而定）。从表面上看，它似乎不能用于表示异质或表格型的数据。结构化数组是一种特殊的ndarray，其中的各个元素可以被看做C语言中的结构体（struct，这就是“结构化”的由来）或SQL表中带有多个命名字段的行：</p>
<pre><code class="language-python">In [144]: dtype = [('x', np.float64), ('y', np.int32)]

In [145]: sarr = np.array([(1.5, 6), (np.pi, -2)], dtype=dtype)

In [146]: sarr
Out[146]: 
array([( 1.5   ,  6), ( 3.1416, -2)],
      dtype=[('x', '&lt;f8'), ('y', '&lt;i4')])
</code></pre>
<p>定义结构化dtype（请参考NumPy的在线文档）的方式有很多。最典型的办法是元组列表，各元组的格式为(field_name,field_data_type)。这样，数组的元素就成了元组式的对象，该对象中各个元素可以像字典那样进行访问：</p>
<pre><code class="language-python">In [147]: sarr[0]
Out[147]: ( 1.5, 6)

In [148]: sarr[0]['y']
Out[148]: 6
</code></pre>
<p>字段名保存在dtype.names属性中。在访问结构化数组的某个字段时，返回的是该数据的视图，所以不会发生数据复制：</p>
<pre><code class="language-python">In [149]: sarr['x']
Out[149]: array([ 1.5   ,  3.1416])
</code></pre>
<h2 id="嵌套dtype和多维字段">嵌套dtype和多维字段</h2>
<p>在定义结构化dtype时，你可以再设置一个形状（可以是一个整数，也可以是一个元组）：</p>
<pre><code class="language-python">In [150]: dtype = [('x', np.int64, 3), ('y', np.int32)]

In [151]: arr = np.zeros(4, dtype=dtype)

In [152]: arr
Out[152]: 
array([([0, 0, 0], 0), ([0, 0, 0], 0), ([0, 0, 0], 0), ([0, 0, 0], 0)],
      dtype=[('x', '&lt;i8', (3,)), ('y', '&lt;i4')])
</code></pre>
<p>在这种情况下，各个记录的x字段所表示的是一个长度为3的数组：</p>
<pre><code class="language-python">In [153]: arr[0]['x']
Out[153]: array([0, 0, 0])
</code></pre>
<p>这样，访问arr['x']即可得到一个二维数组，而不是前面那个例子中的一维数组：</p>
<pre><code class="language-python">In [154]: arr['x']
Out[154]: 
array([[0, 0, 0],
       [0, 0, 0],
       [0, 0, 0],
       [0, 0, 0]])
</code></pre>
<p>这就使你能用单个数组的内存块存放复杂的嵌套结构。你还可以嵌套dtype，作出更复杂的结构。下面是一个简单的例子：</p>
<pre><code class="language-python">In [155]: dtype = [('x', [('a', 'f8'), ('b', 'f4')]), ('y', np.int32)]

In [156]: data = np.array([((1, 2), 5), ((3, 4), 6)], dtype=dtype)

In [157]: data['x']
Out[157]: 
array([( 1.,  2.), ( 3.,  4.)],
      dtype=[('a', '&lt;f8'), ('b', '&lt;f4')])

In [158]: data['y']
Out[158]: array([5, 6], dtype=int32)

In [159]: data['x']['a']
Out[159]: array([ 1.,  3.])
</code></pre>
<p>pandas的DataFrame并不直接支持该功能，但它的分层索引机制跟这个差不多。</p>
<h2 id="为什么要用结构化数组">为什么要用结构化数组</h2>
<p>跟pandas的DataFrame相比，NumPy的结构化数组是一种相对较低级的工具。它可以将单个内存块解释为带有任意复杂嵌套列的表格型结构。由于数组中的每个元素在内存中都被表示为固定的字节数，所以结构化数组能够提供非常快速高效的磁盘数据读写（包括内存映像）、网络传输等功能。</p>
<p>结构化数组的另一个常见用法是，将数据文件写成定长记录字节流，这是C和C++代码中常见的数据序列化手段（业界许多历史系统中都能找得到）。只要知道文件的格式（记录的大小、元素的顺序、字节数以及数据类型等），就可以用np.fromfile将数据读入内存。这种用法超出了本书的范围，知道这点就可以了。</p>
<h1 id="a6-更多有关排序的话题">A.6 更多有关排序的话题</h1>
<p>跟Python内置的列表一样，ndarray的sort实例方法也是就地排序。也就是说，数组内容的重新排列是不会产生新数组的：</p>
<pre><code class="language-python">In [160]: arr = np.random.randn(6)

In [161]: arr.sort()

In [162]: arr
Out[162]: array([-1.082 ,  0.3759,  0.8014,  1.1397,  1.2888,  1.8413])
</code></pre>
<p>在对数组进行就地排序时要注意一点，如果目标数组只是一个视图，则原始数组将会被修改：</p>
<pre><code class="language-python">In [163]: arr = np.random.randn(3, 5)

In [164]: arr
Out[164]: 
array([[-0.3318, -1.4711,  0.8705, -0.0847, -1.1329],
       [-1.0111, -0.3436,  2.1714,  0.1234, -0.0189],
       [ 0.1773,  0.7424,  0.8548,  1.038 , -0.329 ]])

In [165]: arr[:, 0].sort()  # Sort first column values in-place

In [166]: arr
Out[166]: 
array([[-1.0111, -1.4711,  0.8705, -0.0847, -1.1329],
       [-0.3318, -0.3436,  2.1714,  0.1234, -0.0189],
       [ 0.1773,  0.7424,  0.8548,  1.038 , -0.329 ]])
</code></pre>
<p>相反，numpy.sort会为原数组创建一个已排序副本。另外，它所接受的参数（比如kind）跟ndarray.sort一样：</p>
<pre><code class="language-python">In [167]: arr = np.random.randn(5)

In [168]: arr
Out[168]: array([-1.1181, -0.2415, -2.0051,  0.7379, -1.0614])

In [169]: np.sort(arr)
Out[169]: array([-2.0051, -1.1181, -1.0614, -0.2415,  0.7379])

In [170]: arr
Out[170]: array([-1.1181, -0.2415, -2.0051,  0.7379, -1.0614])
</code></pre>
<p>这两个排序方法都可以接受一个axis参数，以便沿指定轴向对各块数据进行单独排序：</p>
<pre><code class="language-python">In [171]: arr = np.random.randn(3, 5)

In [172]: arr
Out[172]: 
array([[ 0.5955, -0.2682,  1.3389, -0.1872,  0.9111],
       [-0.3215,  1.0054, -0.5168,  1.1925, -0.1989],
       [ 0.3969, -1.7638,  0.6071, -0.2222, -0.2171]])

In [173]: arr.sort(axis=1)

In [174]: arr
Out[174]: 
array([[-0.2682, -0.1872,  0.5955,  0.9111,  1.3389],
       [-0.5168, -0.3215, -0.1989,  1.0054,  1.1925],
       [-1.7638, -0.2222, -0.2171,  0.3969,  0.6071]])
</code></pre>
<p>你可能注意到了，这两个排序方法都不可以被设置为降序。其实这也无所谓，因为数组切片会产生视图（也就是说，不会产生副本，也不需要任何其他的计算工作）。许多Python用户都很熟悉一个有关列表的小技巧：values[::-1]可以返回一个反序的列表。对ndarray也是如此：</p>
<pre><code class="language-python">In [175]: arr[:, ::-1]
Out[175]: 
array([[ 1.3389,  0.9111,  0.5955, -0.1872, -0.2682],
       [ 1.1925,  1.0054, -0.1989, -0.3215, -0.5168],
       [ 0.6071,  0.3969, -0.2171, -0.2222, -1.7638]])
</code></pre>
<h2 id="间接排序argsort和lexsort">间接排序：argsort和lexsort</h2>
<p>在数据分析工作中，常常需要根据一个或多个键对数据集进行排序。例如，一个有关学生信息的数据表可能需要以姓和名进行排序（先姓后名）。这就是间接排序的一个例子，如果你阅读过有关pandas的章节，那就已经见过不少高级例子了。给定一个或多个键，你就可以得到一个由整数组成的索引数组（我亲切地称之为索引器），其中的索引值说明了数据在新顺序下的位置。argsort和numpy.lexsort就是实现该功能的两个主要方法。下面是一个简单的例子：</p>
<pre><code class="language-python">In [176]: values = np.array([5, 0, 1, 3, 2])

In [177]: indexer = values.argsort()

In [178]: indexer
Out[178]: array([1, 2, 4, 3, 0])

In [179]: values[indexer]
Out[179]: array([0, 1, 2, 3, 5])
</code></pre>
<p>一个更复杂的例子，下面这段代码根据数组的第一行对其进行排序：</p>
<pre><code class="language-python">In [180]: arr = np.random.randn(3, 5)

In [181]: arr[0] = values

In [182]: arr
Out[182]: 
array([[ 5.    ,  0.    ,  1.    ,  3.    ,  2.    ],
       [-0.3636, -0.1378,  2.1777, -0.4728,  0.8356],
       [-0.2089,  0.2316,  0.728 , -1.3918,  1.9956]])

In [183]: arr[:, arr[0].argsort()]
Out[183]: 
array([[ 0.    ,  1.    ,  2.    ,  3.    ,  5.    ],
       [-0.1378,  2.1777,  0.8356, -0.4728, -0.3636],
       [ 0.2316,  0.728 ,  1.9956, -1.3918, -0.2089]])
</code></pre>
<p>lexsort跟argsort差不多，只不过它可以一次性对多个键数组执行间接排序（字典序）。假设我们想对一些以姓和名标识的数据进行排序：</p>
<pre><code class="language-python">In [184]: first_name = np.array(['Bob', 'Jane', 'Steve', 'Bill', 'Barbara'])

In [185]: last_name = np.array(['Jones', 'Arnold', 'Arnold', 'Jones', 'Walters'])

In [186]: sorter = np.lexsort((first_name, last_name))

In [187]: sorter
Out[187]: array([1, 2, 3, 0, 4])

In [188]: zip(last_name[sorter], first_name[sorter])
Out[188]: &lt;zip at 0x7fa203eda1c8&gt;
</code></pre>
<p>刚开始使用lexsort的时候可能会比较容易头晕，这是因为键的应用顺序是从最后一个传入的算起的。不难看出，last_name是先于first_name被应用的。</p>
<blockquote>
<p>笔记：Series和DataFrame的sort_index以及Series的order方法就是通过这些函数的变体（它们还必须考虑缺失值）实现的。</p>
</blockquote>
<h2 id="其他排序算法">其他排序算法</h2>
<p>稳定的（stable）排序算法会保持等价元素的相对位置。对于相对位置具有实际意义的那些间接排序而言，这一点非常重要：</p>
<pre><code class="language-python">In [189]: values = np.array(['2:first', '2:second', '1:first', '1:second',
.....:                    '1:third'])

In [190]: key = np.array([2, 2, 1, 1, 1])

In [191]: indexer = key.argsort(kind='mergesort')

In [192]: indexer
Out[192]: array([2, 3, 4, 0, 1])

In [193]: values.take(indexer)
Out[193]: 
array(['1:first', '1:second', '1:third', '2:first', '2:second'],
      dtype='&lt;U8')
</code></pre>
<p>mergesort（合并排序）是唯一的稳定排序，它保证有O(n log n)的性能（空间复杂度），但是其平均性能比默认的quicksort（快速排序）要差。表A-3列出了可用的排序算法及其相关的性能指标。大部分用户完全不需要知道这些东西，但了解一下总是好的。</p>
<figure data-type="image" tabindex="29"><img src="http://upload-images.jianshu.io/upload_images/7178691-970f54f58b6b3356.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表A-3 数组排序算法" loading="lazy"></figure>
<h2 id="部分排序数组">部分排序数组</h2>
<p>排序的目的之一可能是确定数组中最大或最小的元素。NumPy有两个优化方法，numpy.partition和np.argpartition，可以在第k个最小元素划分的数组：</p>
<pre><code class="language-python">In [194]: np.random.seed(12345)

In [195]: arr = np.random.randn(20)

In [196]: arr
Out[196]: 
array([-0.2047,  0.4789, -0.5194, -0.5557,  1.9658,  1.3934,  0.0929,
        0.2817,  0.769 ,  1.2464,  1.0072, -1.2962,  0.275 ,  0.2289,
        1.3529,  0.8864, -2.0016, -0.3718,  1.669 , -0.4386])

In [197]: np.partition(arr, 3)
Out[197]: 
array([-2.0016, -1.2962, -0.5557, -0.5194, -0.3718, -0.4386, -0.2047,
        0.2817,  0.769 ,  0.4789,  1.0072,  0.0929,  0.275 ,  0.2289,
        1.3529,  0.8864,  1.3934,  1.9658,  1.669 ,  1.2464])
</code></pre>
<p>当你调用partition(arr, 3)，结果中的头三个元素是最小的三个，没有特定的顺序。numpy.argpartition与numpy.argsort相似，会返回索引，重排数据为等价的顺序：</p>
<pre><code class="language-python">In [198]: indices = np.argpartition(arr, 3)

In [199]: indices
Out[199]: 
array([16, 11,  3,  2, 17, 19,  0,  7,  8,  1, 10,  6, 12, 13, 14, 15,  5,
        4, 18,  9])

In [200]: arr.take(indices)
Out[200]: 
array([-2.0016, -1.2962, -0.5557, -0.5194, -0.3718, -0.4386, -0.2047,
        0.2817,  0.769 ,  0.4789,  1.0072,  0.0929,  0.275 ,  0.2289,
        1.3529,  0.8864,  1.3934,  1.9658,  1.669 ,  1.2464])
</code></pre>
<h2 id="numpysearchsorted在有序数组中查找元素">numpy.searchsorted：在有序数组中查找元素</h2>
<p>searchsorted是一个在有序数组上执行二分查找的数组方法，只要将值插入到它返回的那个位置就能维持数组的有序性：</p>
<pre><code class="language-python">In [201]: arr = np.array([0, 1, 7, 12, 15])

In [202]: arr.searchsorted(9)
Out[202]: 3
</code></pre>
<p>你可以传入一组值就能得到一组索引：</p>
<pre><code class="language-python">In [203]: arr.searchsorted([0, 8, 11, 16])
Out[203]: array([0, 3, 3, 5])
</code></pre>
<p>从上面的结果中可以看出，对于元素0，searchsorted会返回0。这是因为其默认行为是返回相等值组的左侧索引：</p>
<pre><code class="language-python">In [204]: arr = np.array([0, 0, 0, 1, 1, 1, 1])

In [205]: arr.searchsorted([0, 1])
Out[205]: array([0, 3])

In [206]: arr.searchsorted([0, 1], side='right')
Out[206]: array([3, 7])
</code></pre>
<p>再来看searchsorted的另一个用法，假设我们有一个数据数组（其中的值在0到10000之间），还有一个表示“面元边界”的数组，我们希望用它将数据数组拆分开：</p>
<pre><code class="language-python">In [207]: data = np.floor(np.random.uniform(0, 10000, size=50))

In [208]: bins = np.array([0, 100, 1000, 5000, 10000])

In [209]: data
Out[209]: 
array([ 9940.,  6768.,  7908.,  1709.,   268.,  8003., 9037.,   246.,
        4917.,  5262.,  5963.,   519.,  8950.,  7282.,  8183.,  5002.,
        8101.,   959.,  2189.,  2587.,  4681.,  4593.,  7095.,  1780.,
        5314.,  1677.,  7688.,  9281.,  6094.,  1501.,  4896.,  3773.,
        8486.,  9110.,  3838.,  3154.,  5683.,  1878.,  1258.,  6875.,
        7996.,  5735.,  9732.,  6340.,  8884.,  4954.,  3516.,  7142.,
        5039.,  2256.])
</code></pre>
<p>然后，为了得到各数据点所属区间的编号（其中1表示面元[0,100)），我们可以直接使用searchsorted：</p>
<pre><code class="language-python">In [210]: labels = bins.searchsorted(data)

In [211]: labels
Out[211]: 
array([4, 4, 4, 3, 2, 4, 4, 2, 3, 4, 4, 2, 4, 4, 4, 4, 4, 2, 3, 3, 3, 3, 4,
       3, 4, 3, 4, 4, 4, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3,
       3, 4, 4, 3])
</code></pre>
<p>通过pandas的groupby使用该结果即可非常轻松地对原数据集进行拆分：</p>
<pre><code class="language-python">In [212]: pd.Series(data).groupby(labels).mean()
Out[212]: 
2     498.000000
3    3064.277778
4    7389.035714
dtype: float64
</code></pre>
<h1 id="a7-用numba编写快速numpy函数">A.7 用Numba编写快速NumPy函数</h1>
<p>Numba是一个开源项目，它可以利用CPUs、GPUs或其它硬件为类似NumPy的数据创建快速函数。它使用了LLVM项目（http://llvm.org/），将Python代码转换为机器代码。</p>
<p>为了介绍Numba，来考虑一个纯粹的Python函数，它使用for循环计算表达式(x - y).mean()：</p>
<pre><code class="language-python">import numpy as np

def mean_distance(x, y):
    nx = len(x)
    result = 0.0
    count = 0
    for i in range(nx):
        result += x[i] - y[i]
        count += 1
    return result / count
</code></pre>
<p>这个函数很慢：</p>
<pre><code class="language-python">In [209]: x = np.random.randn(10000000)

In [210]: y = np.random.randn(10000000)

In [211]: %timeit mean_distance(x, y)
1 loop, best of 3: 2 s per loop

In [212]: %timeit (x - y).mean()
100 loops, best of 3: 14.7 ms per loop
</code></pre>
<p>NumPy的版本要比它快过100倍。我们可以转换这个函数为编译的Numba函数，使用numba.jit函数：</p>
<pre><code class="language-python">In [213]: import numba as nb

In [214]: numba_mean_distance = nb.jit(mean_distance)
</code></pre>
<p>也可以写成装饰器：</p>
<pre><code class="language-python">@nb.jit
def mean_distance(x, y):
    nx = len(x)
    result = 0.0
    count = 0
    for i in range(nx):
        result += x[i] - y[i]
        count += 1
    return result / count
</code></pre>
<p>它要比矢量化的NumPy快：</p>
<pre><code class="language-python">In [215]: %timeit numba_mean_distance(x, y)
100 loops, best of 3: 10.3 ms per loop
</code></pre>
<p>Numba不能编译Python代码，但它支持纯Python写的一个部分，可以编写数值算法。</p>
<p>Numba是一个深厚的库，支持多种硬件、编译模式和用户插件。它还可以编译NumPy Python API的一部分，而不用for循环。Numba也可以识别可以便以为机器编码的结构体，但是若调用CPython API，它就不知道如何编译。Numba的jit函数有一个选项，nopython=True，它限制了可以被转换为Python代码的代码，这些代码可以编译为LLVM，但没有任何Python C API调用。jit(nopython=True)有一个简短的别名numba.njit。</p>
<p>前面的例子，我们还可以这样写：</p>
<pre><code class="language-python">from numba import float64, njit

@njit(float64(float64[:], float64[:]))
def mean_distance(x, y):
    return (x - y).mean()
</code></pre>
<p>我建议你学习Numba的线上文档（http://numba.pydata.org/）。下一节介绍一个创建自定义Numpy ufunc对象的例子。</p>
<h2 id="用numba创建自定义numpyufunc对象">用Numba创建自定义numpy.ufunc对象</h2>
<p>numba.vectorize创建了一个编译的NumPy ufunc，它与内置的ufunc很像。考虑一个numpy.add的Python例子：</p>
<pre><code class="language-python">from numba import vectorize

@vectorize
def nb_add(x, y):
    return x + y
</code></pre>
<p>现在有：</p>
<pre><code class="language-python">In [13]: x = np.arange(10)

In [14]: nb_add(x, x)
Out[14]: array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.])

In [15]: nb_add.accumulate(x, 0)
Out[15]: array([  0.,   1.,   3.,   6.,  10.,  15.,  21.,  28.,  36.,  45.])
</code></pre>
<h1 id="a8-高级数组输入输出">A.8 高级数组输入输出</h1>
<p>我在第4章中讲过，np.save和np.load可用于读写磁盘上以二进制格式存储的数组。其实还有一些工具可用于更为复杂的场景。尤其是内存映像（memory map），它使你能处理在内存中放不下的数据集。</p>
<h2 id="内存映像文件">内存映像文件</h2>
<p>内存映像文件是一种将磁盘上的非常大的二进制数据文件当做内存中的数组进行处理的方式。NumPy实现了一个类似于ndarray的memmap对象，它允许将大文件分成小段进行读写，而不是一次性将整个数组读入内存。另外，memmap也拥有跟普通数组一样的方法，因此，基本上只要是能用于ndarray的算法就也能用于memmap。</p>
<p>要创建一个内存映像，可以使用函数np.memmap并传入一个文件路径、数据类型、形状以及文件模式：</p>
<pre><code class="language-python">In [214]: mmap = np.memmap('mymmap', dtype='float64', mode='w+',
   .....:                  shape=(10000, 10000))

In [215]: mmap
Out[215]: 
memmap([[ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        ..., 
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.],
        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])
</code></pre>
<p>对memmap切片将会返回磁盘上的数据的视图：</p>
<pre><code class="language-python">In [216]: section = mmap[:5]
</code></pre>
<p>如果将数据赋值给这些视图：数据会先被缓存在内存中（就像是Python的文件对象），调用flush即可将其写入磁盘：</p>
<pre><code class="language-python">In [217]: section[:] = np.random.randn(5, 10000)

In [218]: mmap.flush()

In [219]: mmap
Out[219]: 
memmap([[ 0.7584, -0.6605,  0.8626, ...,  0.6046, -0.6212,  2.0542],
        [-1.2113, -1.0375,  0.7093, ..., -1.4117, -0.1719, -0.8957],
        [-0.1419, -0.3375,  0.4329, ...,  1.2914, -0.752 , -0.44  ],
        ..., 
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]])

In [220]: del mmap
</code></pre>
<p>只要某个内存映像超出了作用域，它就会被垃圾回收器回收，之前对其所做的任何修改都会被写入磁盘。当打开一个已经存在的内存映像时，仍然需要指明数据类型和形状，因为磁盘上的那个文件只是一块二进制数据而已，没有任何元数据：</p>
<pre><code class="language-python">In [221]: mmap = np.memmap('mymmap', dtype='float64', shape=(10000, 10000))

In [222]: mmap
Out[222]: 
memmap([[ 0.7584, -0.6605,  0.8626, ...,  0.6046, -0.6212,  2.0542],
        [-1.2113, -1.0375,  0.7093, ..., -1.4117, -0.1719, -0.8957],
        [-0.1419, -0.3375,  0.4329, ...,  1.2914, -0.752 , -0.44  ],
        ..., 
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ],
        [ 0.    ,  0.    ,  0.    , ...,  0.    ,  0.    ,  0.    ]])
</code></pre>
<p>内存映像可以使用前面介绍的结构化或嵌套dtype。</p>
<h2 id="hdf5及其他数组存储方式">HDF5及其他数组存储方式</h2>
<p>PyTables和h5py这两个Python项目可以将NumPy的数组数据存储为高效且可压缩的HDF5格式（HDF意思是“层次化数据格式”）。你可以安全地将好几百GB甚至TB的数据存储为HDF5格式。要学习Python使用HDF5，请参考pandas线上文档。</p>
<h1 id="a9-性能建议">A.9 性能建议</h1>
<p>使用NumPy的代码的性能一般都很不错，因为数组运算一般都比纯Python循环快得多。下面大致列出了一些需要注意的事项：</p>
<ul>
<li>将Python循环和条件逻辑转换为数组运算和布尔数组运算。</li>
<li>尽量使用广播。</li>
<li>避免复制数据，尽量使用数组视图（即切片）。</li>
<li>利用ufunc及其各种方法。</li>
</ul>
<p>如果单用NumPy无论如何都达不到所需的性能指标，就可以考虑一下用C、Fortran或Cython（等下会稍微介绍一下）来编写代码。我自己在工作中经常会用到Cython（http://cython.org），因为它不用花费我太多精力就能得到C语言那样的性能。</p>
<h2 id="连续内存的重要性">连续内存的重要性</h2>
<p>虽然这个话题有点超出本书的范围，但还是要提一下，因为在某些应用场景中，数组的内存布局可以对计算速度造成极大的影响。这是因为性能差别在一定程度上跟CPU的高速缓存（cache）体系有关。运算过程中访问连续内存块（例如，对以C顺序存储的数组的行求和）一般是最快的，因为内存子系统会将适当的内存块缓存到超高速的L1或L2CPU Cache中。此外，NumPy的C语言基础代码（某些）对连续存储的情况进行了优化处理，这样就能避免一些跨越式的内存访问。</p>
<p>一个数组的内存布局是连续的，就是说元素是以它们在数组中出现的顺序（即Fortran型（列优先）或C型（行优先））存储在内存中的。默认情况下，NumPy数组是以C型连续的方式创建的。列优先的数组（比如C型连续数组的转置）也被称为Fortran型连续。通过ndarray的flags属性即可查看这些信息：</p>
<pre><code class="language-python">In [225]: arr_c = np.ones((1000, 1000), order='C')

In [226]: arr_f = np.ones((1000, 1000), order='F')

In [227]: arr_c.flags

Out[227]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  UPDATEIFCOPY : False

In [228]: arr_f.flags
Out[228]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : True
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  UPDATEIFCOPY : False

In [229]: arr_f.flags.f_contiguous
Out[229]: True
</code></pre>
<p>在这个例子中，对两个数组的行进行求和计算，理论上说，arr_c会比arr_f快，因为arr_c的行在内存中是连续的。我们可以在IPython中用%timeit来确认一下：</p>
<pre><code class="language-python">In [230]: %timeit arr_c.sum(1)
784 us +- 10.4 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)

In [231]: %timeit arr_f.sum(1)
934 us +- 29 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)
</code></pre>
<p>如果想从NumPy中提升性能，这里就应该是下手的地方。如果数组的内存顺序不符合你的要求，使用copy并传入'C'或'F'即可解决该问题：</p>
<pre><code class="language-python">In [232]: arr_f.copy('C').flags
Out[232]: 
  C_CONTIGUOUS : True
  F_CONTIGUOUS : False
  OWNDATA : True
  WRITEABLE : True
  ALIGNED : True
  UPDATEIFCOPY : False
</code></pre>
<p>注意，在构造数组的视图时，其结果不一定是连续的：</p>
<pre><code class="language-python">In [233]: arr_c[:50].flags.contiguous
Out[233]: True

In [234]: arr_c[:, :50].flags
Out[234]: 
  C_CONTIGUOUS : False
  F_CONTIGUOUS : False
  OWNDATA : False
  WRITEABLE : True
  ALIGNED : True
  UPDATEIFCOPY : False
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[待安装包]]></title>
        <id>https://bailingnan.github.io/post/dai-an-zhuang-bao/</id>
        <link href="https://bailingnan.github.io/post/dai-an-zhuang-bao/">
        </link>
        <updated>2020-02-07T02:42:25.000Z</updated>
        <content type="html"><![CDATA[<p>flake8<br>
SpeedTorch<br>
ohmyzsh<br>
pypy<br>
<strong>modin</strong><br>
<strong>numba</strong><br>
cupy<br>
Cython<br>
hyperparameter_hunter<br>
<strong>torch-optimizer</strong> 拓展pytorch优化器<br>
DeepSpeed 微软分布式训练工具<br>
dvc<br>
hiddenlayer<br>
syncthing<br>
ignite<br>
pytorch-lightning<br>
fastai<br>
prefetch_generator<br>
torchsummary<br>
apex<br>
dali<br>
optuna<br>
pip-review<br>
autogluon<br>
arthas<br>
greys-anatomy<br>
implicit<br>
eli5<br>
icecream<br>
stackprinter<br>
dlrm<br>
buffalo<br>
cupy<br>
acptum<br>
featuretools<br>
boruta_py<br>
Categorical-encoding<br>
Tsfresh<br>
Scikit-Optimize<br>
Hyperopt<br>
ray<br>
ENAS-pytorch<br>
MLBox<br>
h2o<br>
AutoKeras<br>
TPOT<br>
Auto-Sklearn</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matplotlib笔记]]></title>
        <id>https://bailingnan.github.io/post/li-yong-python-jin-xing-shu-ju-fen-xi-di-09-zhang-hui-tu-he-ke-shi-hua/</id>
        <link href="https://bailingnan.github.io/post/li-yong-python-jin-xing-shu-ju-fen-xi-di-09-zhang-hui-tu-he-ke-shi-hua/">
        </link>
        <updated>2020-02-04T09:09:53.000Z</updated>
        <content type="html"><![CDATA[<p>信息可视化（也叫绘图）是数据分析中最重要的工作之一。它可能是探索过程的一部分，例如，帮助我们找出异常值、必要的数据转换、得出有关模型的idea等。另外，做一个可交互的数据可视化也许是工作的最终目标。Python有许多库进行静态或动态的数据可视化，但我这里重要关注于matplotlib（http://matplotlib.org/）和基于它的库。</p>
<p>matplotlib是一个用于创建出版质量图表的桌面绘图包（主要是2D方面）。该项目是由John Hunter于2002年启动的，其目的是为Python构建一个MATLAB式的绘图接口。matplotlib和IPython社区进行合作，简化了从IPython shell（包括现在的Jupyter notebook）进行交互式绘图。matplotlib支持各种操作系统上许多不同的GUI后端，而且还能将图片导出为各种常见的矢量（vector）和光栅（raster）图：PDF、SVG、JPG、PNG、BMP、GIF等。除了几张，本书中的大部分图都是用它生成的。</p>
<p>随着时间的发展，matplotlib衍生出了多个数据可视化的工具集，它们使用matplotlib作为底层。其中之一是seaborn（http://seaborn.pydata.org/），本章后面会学习它。</p>
<p>学习本章代码案例的最简单方法是在Jupyter notebook进行交互式绘图。在Jupyter notebook中执行下面的语句：</p>
<pre><code class="language-python">%matplotlib notebook
</code></pre>
<h1 id="91-matplotlib-api入门">9.1 matplotlib API入门</h1>
<p>matplotlib的通常引入约定是：</p>
<pre><code class="language-python">In [11]: import matplotlib.pyplot as plt
</code></pre>
<p>在Jupyter中运行%matplotlib notebook（或在IPython中运行%matplotlib），就可以创建一个简单的图形。如果一切设置正确，会看到图9-1：</p>
<pre><code class="language-python">In [12]: import numpy as np

In [13]: data = np.arange(10)

In [14]: data
Out[14]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

In [15]: plt.plot(data)
</code></pre>
<figure data-type="image" tabindex="1"><img src="http://upload-images.jianshu.io/upload_images/7178691-7032e333a6ecdd37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-1 简单的线图" loading="lazy"></figure>
<p>虽然seaborn这样的库和pandas的内置绘图函数能够处理许多普通的绘图任务，但如果需要自定义一些高级功能的话就必须学习matplotlib API。</p>
<blockquote>
<p>笔记：虽然本书没有详细地讨论matplotlib的各种功能，但足以将你引入门。matplotlib的示例库和文档是学习高级特性的最好资源。</p>
</blockquote>
<h2 id="figure和subplot">Figure和Subplot</h2>
<p>matplotlib的图像都位于Figure对象中。你可以用plt.figure创建一个新的Figure：</p>
<pre><code class="language-python">In [16]: fig = plt.figure()
</code></pre>
<p>如果用的是IPython，这时会弹出一个空窗口，但在Jupyter中，必须再输入更多命令才能看到。plt.figure有一些选项，特别是figsize，它用于确保当图片保存到磁盘时具有一定的大小和纵横比。</p>
<p>不能通过空Figure绘图。必须用add_subplot创建一个或多个subplot才行：</p>
<pre><code class="language-python">In [17]: ax1 = fig.add_subplot(2, 2, 1)
</code></pre>
<p>这条代码的意思是：图像应该是2×2的（即最多4张图），且当前选中的是4个subplot中的第一个（编号从1开始）。如果再把后面两个subplot也创建出来，最终得到的图像如图9-2所示：</p>
<pre><code class="language-python">In [18]: ax2 = fig.add_subplot(2, 2, 2)

In [19]: ax3 = fig.add_subplot(2, 2, 3)
</code></pre>
<figure data-type="image" tabindex="2"><img src="http://upload-images.jianshu.io/upload_images/7178691-b8cff158e64eae74.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-2 带有三个subplot的Figure" loading="lazy"></figure>
<blockquote>
<p>提示：使用Jupyter notebook有一点不同，即每个小窗重新执行后，图形会被重置。因此，对于复杂的图形，，你必须将所有的绘图命令存在一个小窗里。</p>
</blockquote>
<p>这里，我们运行同一个小窗里的所有命令：</p>
<pre><code class="language-python">fig = plt.figure()
ax1 = fig.add_subplot(2, 2, 1)
ax2 = fig.add_subplot(2, 2, 2)
ax3 = fig.add_subplot(2, 2, 3)
</code></pre>
<p>如果这时执行一条绘图命令（如plt.plot([1.5, 3.5, -2, 1.6])），matplotlib就会在最后一个用过的subplot（如果没有则创建一个）上进行绘制，隐藏创建figure和subplot的过程。因此，如果我们执行下列命令，你就会得到如图9-3所示的结果：</p>
<pre><code class="language-python">In [20]: plt.plot(np.random.randn(50).cumsum(), 'k--')
</code></pre>
<figure data-type="image" tabindex="3"><img src="http://upload-images.jianshu.io/upload_images/7178691-7bcbd5e56fdbbd92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-3 绘制一次之后的图像" loading="lazy"></figure>
<p>&quot;k--&quot;是一个线型选项，用于告诉matplotlib绘制黑色虚线图。上面那些由fig.add_subplot所返回的对象是AxesSubplot对象，直接调用它们的实例方法就可以在其它空着的格子里面画图了，如图9-4所示：</p>
<pre><code class="language-python">In [21]: ax1.hist(np.random.randn(100), bins=20, color='k', alpha=0.3)

In [22]: ax2.scatter(np.arange(30), np.arange(30) + 3 * np.random.randn(30))
</code></pre>
<figure data-type="image" tabindex="4"><img src="http://upload-images.jianshu.io/upload_images/7178691-2297bcaf355db24c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-4 继续绘制两次之后的图像" loading="lazy"></figure>
<p>你可以在matplotlib的文档中找到各种图表类型。</p>
<p>创建包含subplot网格的figure是一个非常常见的任务，matplotlib有一个更为方便的方法plt.subplots，它可以创建一个新的Figure，并返回一个含有已创建的subplot对象的NumPy数组：</p>
<pre><code class="language-python">In [24]: fig, axes = plt.subplots(2, 3)

In [25]: axes
Out[25]: 
array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb626374048&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb62625db00&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb6262f6c88&gt;],
       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb6261a36a0&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb626181860&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7fb6260fd4e0&gt;]], dtype
=object)
</code></pre>
<p>这是非常实用的，因为可以轻松地对axes数组进行索引，就好像是一个二维数组一样，例如axes[0,1]。你还可以通过sharex和sharey指定subplot应该具有相同的X轴或Y轴。在比较相同范围的数据时，这也是非常实用的，否则，matplotlib会自动缩放各图表的界限。有关该方法的更多信息，请参见表9-1。</p>
<pre><code class="language-python">matplotlib.pyplot.subplots(nrows=1, ncols=1, sharex=False, sharey=False, squeeze=True, subplot_kw=None, gridspec_kw=None, **fig_kw)[source]
</code></pre>
<figure data-type="image" tabindex="5"><img src="http://upload-images.jianshu.io/upload_images/7178691-88bb55faca7d01ba.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-1 pyplot.subplots的选项" loading="lazy"></figure>
<h2 id="调整subplot周围的间距">调整subplot周围的间距</h2>
<p>默认情况下，matplotlib会在subplot外围留下一定的边距，并在subplot之间留下一定的间距。间距跟图像的高度和宽度有关，因此，如果你调整了图像大小（不管是编程还是手工），间距也会自动调整。利用Figure的subplots_adjust方法可以轻而易举地修改间距，此外，它也是个顶级函数：</p>
<pre><code class="language-python">subplots_adjust(left=None, bottom=None, right=None, top=None,
                wspace=None, hspace=None)
</code></pre>
<p>wspace和hspace用于控制宽度和高度的百分比，可以用作subplot之间的间距。下面是一个简单的例子，其中我将间距收缩到了0（如图9-5所示）：</p>
<pre><code class="language-python">fig, axes = plt.subplots(2, 2, sharex=True, sharey=True)
for i in range(2):
    for j in range(2):
        axes[i, j].hist(np.random.randn(500), bins=50, color='k', alpha=0.5)
plt.subplots_adjust(wspace=0, hspace=0)
</code></pre>
<figure data-type="image" tabindex="6"><img src="http://upload-images.jianshu.io/upload_images/7178691-80be7ffc3dec88a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-5 各subplot之间没有间距" loading="lazy"></figure>
<p>不难看出，其中的轴标签重叠了。matplotlib不会检查标签是否重叠，所以对于这种情况，你只能自己设定刻度位置和刻度标签。后面几节将会详细介绍该内容。</p>
<h2 id="颜色-标记和线型">颜色、标记和线型</h2>
<p>matplotlib的plot函数接受一组X和Y坐标，还可以接受一个表示颜色和线型的字符串缩写。例如，要根据x和y绘制绿色虚线，你可以执行如下代码：</p>
<pre><code class="language-python">ax.plot(x, y, 'g--')
</code></pre>
<p>这种在一个字符串中指定颜色和线型的方式非常方便。在实际中，如果你是用代码绘图，你可能不想通过处理字符串来获得想要的格式。通过下面这种更为明确的方式也能得到同样的效果：</p>
<pre><code class="language-python">ax.plot(x, y, linestyle='--', color='g')
</code></pre>
<p>常用的颜色可以使用颜色缩写，你也可以指定颜色码（例如，'#CECECE'）。你可以通过查看plot的文档字符串查看所有线型的合集（在IPython和Jupyter中使用plot?）。</p>
<p>可选参数[fmt] 是一个字符串来定义图的基本属性如：颜色（color），点型（marker），线型（linestyle）。<br>
具体形式  fmt = '[color][marker][line]'</p>
<pre><code class="language-python">=============    ===============================
    character        color
    =============    ===============================
    ``'b'``          blue 蓝
    ``'g'``          green 绿
    ``'r'``          red 红
    ``'c'``          cyan 蓝绿
    ``'m'``          magenta 洋红
    ``'y'``          yellow 黄
    ``'k'``          black 黑
    ``'w'``          white 白
    =============    ===============================
=============    ===============================
    character        description
    =============    ===============================
    ``'.'``          point marker点标记
    ``','``          pixel marker像素标记（极小点）
    ``'o'``          circle marker实心圈标记
    ``'v'``          triangle_down marker倒三角标记
    ``'^'``          triangle_up marker上三角标记
    ``'&lt;'``          triangle_left marker
    ``'&gt;'``          triangle_right marker
    ``'1'``          tri_down marker
    ``'2'``          tri_up marker
    ``'3'``          tri_left marker
    ``'4'``          tri_right marker
    ``'s'``          square marker
    ``'p'``          pentagon marker
    ``'*'``          star marker
    ``'h'``          hexagon1 marker
    ``'H'``          hexagon2 marker
    ``'+'``          plus marker十字标记
    ``'x'``          x markerx标记
    ``'D'``          diamond marker
    ``'d'``          thin_diamond marker
    ``'|'``          vline marker
    ``'_'``          hline marker
    =============    ===============================
=============    ===============================
    character        description
    =============    ===============================
    ``'-'``          solid line style 实线
    ``'--'``         dashed line style 虚线
    ``'-.'``         dash-dot line style 点画线
    ``':'``          dotted line style 点线
    ``''``           无线条
    =============    ===============================
</code></pre>
<p>线图可以使用标记强调数据点。因为matplotlib可以创建连续线图，在点之间进行插值，因此有时可能不太容易看出真实数据点的位置。标记也可以放到格式字符串中，但标记类型和线型必须放在颜色后面（见图9-6）：</p>
<pre><code class="language-python">In [30]: from numpy.random import randn

In [31]: plt.plot(randn(30).cumsum(), 'ko--')
</code></pre>
<figure data-type="image" tabindex="7"><img src="http://upload-images.jianshu.io/upload_images/7178691-404d816f3e1d6621.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-6 带有标记的线型图示例" loading="lazy"></figure>
<p>还可以将其写成更为明确的形式：</p>
<pre><code class="language-python">plot(randn(30).cumsum(), color='k', linestyle='dashed', marker='o')
</code></pre>
<p>在线型图中，非实际数据点默认是按线性方式插值的。可以通过drawstyle选项修改（见图9-7）：</p>
<pre><code class="language-python">In [33]: data = np.random.randn(30).cumsum()

In [34]: plt.plot(data, 'k--', label='Default')
Out[34]: [&lt;matplotlib.lines.Line2D at 0x7fb624d86160&gt;]

In [35]: plt.plot(data, 'k-', drawstyle='steps-post', label='steps-post')
Out[35]: [&lt;matplotlib.lines.Line2D at 0x7fb624d869e8&gt;]

In [36]: plt.legend(loc='best')
</code></pre>
<figure data-type="image" tabindex="8"><img src="http://upload-images.jianshu.io/upload_images/7178691-3ec7642e1a592f08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-7 不同drawstyle选项的线型图" loading="lazy"></figure>
<p>你可能注意到运行上面代码时有输出&lt;matplotlib.lines.Line2D at ...&gt;。matplotlib会返回引用了新添加的子组件的对象。大多数时候，你可以放心地忽略这些输出。这里，因为我们传递了label参数到plot，我们可以创建一个plot图例，指明每条使用plt.legend的线。</p>
<blockquote>
<p>笔记：你必须调用plt.legend（或使用ax.legend，如果引用了轴的话）来创建图例，无论你绘图时是否传递label标签选项。</p>
</blockquote>
<h2 id="刻度-标签和图例">刻度、标签和图例</h2>
<p>对于大多数的图表装饰项，其主要实现方式有二：使用过程型的pyplot接口（例如，matplotlib.pyplot）以及更为面向对象的原生matplotlib API。</p>
<p>pyplot接口的设计目的就是交互式使用，含有诸如xlim、xticks和xticklabels之类的方法。它们分别控制图表的范围、刻度位置、刻度标签等。其使用方式有以下两种：</p>
<ul>
<li>调用时不带参数，则返回当前的参数值（例如，plt.xlim()返回当前的X轴绘图范围）。</li>
<li>调用时带参数，则设置参数值（例如，plt.xlim([0,10])会将X轴的范围设置为0到10）。</li>
</ul>
<p>所有这些方法都是对当前或最近创建的AxesSubplot起作用的。它们各自对应subplot对象上的两个方法，以xlim为例，就是ax.get_xlim和ax.set_xlim。我更喜欢使用subplot的实例方法（因为我喜欢明确的事情，而且在处理多个subplot时这样也更清楚一些）。当然你完全可以选择自己觉得方便的那个。</p>
<h2 id="设置标题-轴标签-刻度以及刻度标签">设置标题、轴标签、刻度以及刻度标签</h2>
<p>为了说明自定义轴，我将创建一个简单的图像并绘制一段随机漫步（如图9-8所示）：</p>
<pre><code class="language-python">In [37]: fig = plt.figure()

In [38]: ax = fig.add_subplot(1, 1, 1)

In [39]: ax.plot(np.random.randn(1000).cumsum())
</code></pre>
<figure data-type="image" tabindex="9"><img src="http://upload-images.jianshu.io/upload_images/7178691-caf9300dacb61fa4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-8 用于演示xticks的简单线型图（带有标签）" loading="lazy"></figure>
<p>要改变x轴刻度，最简单的办法是使用set_xticks和set_xticklabels。前者告诉matplotlib要将刻度放在数据范围中的哪些位置，默认情况下，这些位置也就是刻度标签。但我们可以通过set_xticklabels将任何其他的值用作标签：</p>
<pre><code class="language-python">In [40]: ticks = ax.set_xticks([0, 250, 500, 750, 1000])

In [41]: labels = ax.set_xticklabels(['one', 'two', 'three', 'four', 'five'],
   ....:                             rotation=30, fontsize='small')
</code></pre>
<p>rotation选项设定x刻度标签倾斜30度。最后，再用set_xlabel为X轴设置一个名称，并用set_title设置一个标题（见图9-9的结果）：</p>
<pre><code class="language-python">In [42]: ax.set_title('My first matplotlib plot')
Out[42]: &lt;matplotlib.text.Text at 0x7fb624d055f8&gt;

In [43]: ax.set_xlabel('Stages')
</code></pre>
<figure data-type="image" tabindex="10"><img src="http://upload-images.jianshu.io/upload_images/7178691-741f968323bd818f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-9 用于演示xticks的简单线型图" loading="lazy"></figure>
<p>Y轴的修改方式与此类似，只需将上述代码中的x替换为y即可。轴的类有集合方法，可以批量设定绘图选项。前面的例子，也可以写为：</p>
<pre><code class="language-python">props = {
    'title': 'My first matplotlib plot',
    'xlabel': 'Stages'
}
ax.set(**props)
</code></pre>
<h2 id="添加图例">添加图例</h2>
<p>图例（legend）是另一种用于标识图表元素的重要工具。添加图例的方式有多种。最简单的是在添加subplot的时候传入label参数：</p>
<pre><code class="language-python">In [44]: from numpy.random import randn

In [45]: fig = plt.figure(); ax = fig.add_subplot(1, 1, 1)

In [46]: ax.plot(randn(1000).cumsum(), 'k', label='one')
Out[46]: [&lt;matplotlib.lines.Line2D at 0x7fb624bdf860&gt;]

In [47]: ax.plot(randn(1000).cumsum(), 'k--', label='two')
Out[47]: [&lt;matplotlib.lines.Line2D at 0x7fb624be90f0&gt;]

In [48]: ax.plot(randn(1000).cumsum(), 'k.', label='three')
Out[48]: [&lt;matplotlib.lines.Line2D at 0x7fb624be9160&gt;]
</code></pre>
<p>在此之后，你可以调用ax.legend()或plt.legend()来自动创建图例（结果见图9-10）：</p>
<pre><code class="language-python">In [49]: ax.legend(loc='best')
</code></pre>
<figure data-type="image" tabindex="11"><img src="http://upload-images.jianshu.io/upload_images/7178691-651ff89750c0a89b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-10 带有三条线以及图例的简单线型图" loading="lazy"></figure>
<p>legend方法有几个其它的loc位置参数选项。请查看文档字符串（使用ax.legend?）。</p>
<p>loc告诉matplotlib要将图例放在哪。如果你不是吹毛求疵的话，&quot;best&quot;是不错的选择，因为它会选择最不碍事的位置。要从图例中去除一个或多个元素，不传入label或传入label='<em>nolegend</em>'即可。（中文第一版这里把best错写成了beat）</p>
<h2 id="注解以及在subplot上绘图">注解以及在Subplot上绘图</h2>
<p>除标准的绘图类型，你可能还希望绘制一些子集的注解，可能是文本、箭头或其他图形等。注解和文字可以通过text、arrow和annotate函数进行添加。text可以将文本绘制在图表的指定坐标(x,y)，还可以加上一些自定义格式：</p>
<pre><code class="language-python">ax.text(x, y, 'Hello world!',
        family='monospace', fontsize=10)
</code></pre>
<p>注解中可以既含有文本也含有箭头。例如，我们根据最近的标准普尔500指数价格（来自Yahoo!Finance）绘制一张曲线图，并标出2008年到2009年金融危机期间的一些重要日期。你可以在Jupyter notebook的一个小窗中试验这段代码（图9-11是结果）：</p>
<pre><code class="language-python">from datetime import datetime

fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)

data = pd.read_csv('examples/spx.csv', index_col=0, parse_dates=True)
spx = data['SPX']

spx.plot(ax=ax, style='k-')

crisis_data = [
    (datetime(2007, 10, 11), 'Peak of bull market'),
    (datetime(2008, 3, 12), 'Bear Stearns Fails'),
    (datetime(2008, 9, 15), 'Lehman Bankruptcy')
]

for date, label in crisis_data:
    ax.annotate(label, xy=(date, spx.asof(date) + 75),
                xytext=(date, spx.asof(date) + 225),
                arrowprops=dict(facecolor='black', headwidth=4, width=2,
                                headlength=4),
                horizontalalignment='left', verticalalignment='top')

# Zoom in on 2007-2010
ax.set_xlim(['1/1/2007', '1/1/2011'])
ax.set_ylim([600, 1800])

ax.set_title('Important dates in the 2008-2009 financial crisis')
</code></pre>
<figure data-type="image" tabindex="12"><img src="http://upload-images.jianshu.io/upload_images/7178691-3127eaa51f5e4c2c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-11 2008-2009年金融危机期间的重要日期" loading="lazy"></figure>
<p>这张图中有几个重要的点要强调：ax.annotate方法可以在指定的x和y坐标轴绘制标签。我们使用set_xlim和set_ylim人工设定起始和结束边界，而不使用matplotlib的默认方法。最后，用ax.set_title添加图标标题。</p>
<p>更多有关注解的示例，请访问matplotlib的在线示例库。</p>
<p>图形的绘制要麻烦一些。matplotlib有一些表示常见图形的对象。这些对象被称为块（patch）。其中有些（如Rectangle和Circle），可以在matplotlib.pyplot中找到，但完整集合位于matplotlib.patches。</p>
<p>要在图表中添加一个图形，你需要创建一个块对象shp，然后通过ax.add_patch(shp)将其添加到subplot中（如图9-12所示）：</p>
<pre><code class="language-python">fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)

rect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color='k', alpha=0.3)
circ = plt.Circle((0.7, 0.2), 0.15, color='b', alpha=0.3)
pgon = plt.Polygon([[0.15, 0.15], [0.35, 0.4], [0.2, 0.6]],
                   color='g', alpha=0.5)

ax.add_patch(rect)
ax.add_patch(circ)
ax.add_patch(pgon)
</code></pre>
<figure data-type="image" tabindex="13"><img src="http://upload-images.jianshu.io/upload_images/7178691-1f8a3d7a3a02d7d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-12 由三个块图形组成的图" loading="lazy"></figure>
<p>如果查看许多常见图表对象的具体实现代码，你就会发现它们其实就是由块patch组装而成的。</p>
<h2 id="将图表保存到文件">将图表保存到文件</h2>
<p>利用plt.savefig可以将当前图表保存到文件。该方法相当于Figure对象的实例方法savefig。例如，要将图表保存为SVG文件，你只需输入：</p>
<pre><code class="language-python">plt.savefig('figpath.svg')
</code></pre>
<p>文件类型是通过文件扩展名推断出来的。因此，如果你使用的是.pdf，就会得到一个PDF文件。我在发布图片时最常用到两个重要的选项是dpi（控制“每英寸点数”分辨率）和bbox_inches（可以剪除当前图表周围的空白部分）。要得到一张带有最小白边且分辨率为400DPI的PNG图片，你可以：</p>
<pre><code class="language-python">plt.savefig('figpath.png', dpi=400, bbox_inches='tight')
</code></pre>
<p>savefig并非一定要写入磁盘，也可以写入任何文件型的对象，比如BytesIO：</p>
<pre><code class="language-python">from io import BytesIO
buffer = BytesIO()
plt.savefig(buffer)
plot_data = buffer.getvalue()
</code></pre>
<p>表9-2列出了savefig的其它选项。</p>
<figure data-type="image" tabindex="14"><img src="http://upload-images.jianshu.io/upload_images/7178691-4bee796bf7262423.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-2 Figure.savefig的选项" loading="lazy"></figure>
<h2 id="matplotlib配置">matplotlib配置</h2>
<p>matplotlib自带一些配色方案，以及为生成出版质量的图片而设定的默认配置信息。幸运的是，几乎所有默认行为都能通过一组全局参数进行自定义，它们可以管理图像大小、subplot边距、配色方案、字体大小、网格类型等。一种Python编程方式配置系统的方法是使用rc方法。例如，要将全局的图像默认大小设置为10×10，你可以执行：</p>
<pre><code class="language-python">plt.rc('figure', figsize=(10, 10))
</code></pre>
<p>rc的第一个参数是希望自定义的对象，如'figure'、'axes'、'xtick'、'ytick'、'grid'、'legend'等。其后可以跟上一系列的关键字参数。一个简单的办法是将这些选项写成一个字典：</p>
<pre><code class="language-python">font_options = {'family' : 'monospace',
                'weight' : 'bold',
                'size'   : 'small'}
plt.rc('font', **font_options)
</code></pre>
<p>要了解全部的自定义选项，请查阅matplotlib的配置文件matplotlibrc（位于matplotlib/mpl-data目录中）。如果对该文件进行了自定义，并将其放在你自己的.matplotlibrc目录中，则每次使用matplotlib时就会加载该文件。</p>
<p>下一节，我们会看到，seaborn包有若干内置的绘图主题或类型，它们使用了matplotlib的内部配置。</p>
<h1 id="92-使用pandas和seaborn绘图">9.2 使用pandas和seaborn绘图</h1>
<p>matplotlib实际上是一种比较低级的工具。要绘制一张图表，你组装一些基本组件就行：数据展示（即图表类型：线型图、柱状图、盒形图、散布图、等值线图等）、图例、标题、刻度标签以及其他注解型信息。</p>
<p>在pandas中，我们有多列数据，还有行和列标签。pandas自身就有内置的方法，用于简化从DataFrame和Series绘制图形。另一个库seaborn（https://seaborn.pydata.org/），由Michael Waskom创建的静态图形库。Seaborn简化了许多常见可视类型的创建。</p>
<blockquote>
<p>提示：引入seaborn会修改matplotlib默认的颜色方案和绘图类型，以提高可读性和美观度。即使你不使用seaborn API，你可能也会引入seaborn，作为提高美观度和绘制常见matplotlib图形的简化方法。</p>
</blockquote>
<h2 id="线型图">线型图</h2>
<p>Series和DataFrame都有一个用于生成各类图表的plot方法。默认情况下，它们所生成的是线型图（如图9-13所示）：</p>
<pre><code class="language-python">In [60]: s = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))

In [61]: s.plot()
</code></pre>
<figure data-type="image" tabindex="15"><img src="http://upload-images.jianshu.io/upload_images/7178691-f28e5ab2ac94c7a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-13 简单的Series图表示例" loading="lazy"></figure>
<p>该Series对象的索引会被传给matplotlib，并用以绘制X轴。可以通过use_index=False禁用该功能。X轴的刻度和界限可以通过xticks和xlim选项进行调节，Y轴就用yticks和ylim。plot参数的完整列表请参见表9-3。我只会讲解其中几个，剩下的就留给读者自己去研究了。</p>
<figure data-type="image" tabindex="16"><img src="http://upload-images.jianshu.io/upload_images/7178691-6d9fbf863c09370a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="17"><img src="http://upload-images.jianshu.io/upload_images/7178691-44e50562aeb5eb49.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-3 Series.plot方法的参数" loading="lazy"></figure>
<p>pandas的大部分绘图方法都有一个可选的ax参数，它可以是一个matplotlib的subplot对象。这使你能够在网格布局中更为灵活地处理subplot的位置。</p>
<p>DataFrame的plot方法会在一个subplot中为各列绘制一条线，并自动创建图例（如图9-14所示）：</p>
<pre><code class="language-python">In [62]: df = pd.DataFrame(np.random.randn(10, 4).cumsum(0),
   ....:                   columns=['A', 'B', 'C', 'D'],
   ....:                   index=np.arange(0, 100, 10))

In [63]: df.plot()
</code></pre>
<figure data-type="image" tabindex="18"><img src="http://upload-images.jianshu.io/upload_images/7178691-a1234d5e5ee41a40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-14 简单的DataFrame绘图" loading="lazy"></figure>
<p>plot属性包含一批不同绘图类型的方法。例如，df.plot()等价于df.plot.line()。后面会学习这些方法。</p>
<blockquote>
<p>笔记：plot的其他关键字参数会被传给相应的matplotlib绘图函数，所以要更深入地自定义图表，就必须学习更多有关matplotlib API的知识。</p>
</blockquote>
<p>DataFrame还有一些用于对列进行灵活处理的选项，例如，是要将所有列都绘制到一个subplot中还是创建各自的subplot。详细信息请参见表9-4。</p>
<figure data-type="image" tabindex="19"><img src="http://upload-images.jianshu.io/upload_images/7178691-96651ecaa90f1c68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="表9-4 专用于DataFrame的plot参数" loading="lazy"></figure>
<blockquote>
<p>注意： 有关时间序列的绘图，请见第11章。</p>
</blockquote>
<h2 id="柱状图">柱状图</h2>
<p>plot.bar()和plot.barh()分别绘制水平和垂直的柱状图。这时，Series和DataFrame的索引将会被用作X（bar）或Y（barh）刻度（如图9-15所示）：</p>
<pre><code class="language-python">In [64]: fig, axes = plt.subplots(2, 1)

In [65]: data = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))

In [66]: data.plot.bar(ax=axes[0], color='k', alpha=0.7)
Out[66]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb62493d470&gt;

In [67]: data.plot.barh(ax=axes[1], color='k', alpha=0.7)
</code></pre>
<figure data-type="image" tabindex="20"><img src="http://upload-images.jianshu.io/upload_images/7178691-cd54c7ccfa3f0687.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-15 水平和垂直的柱状图" loading="lazy"></figure>
<p>color='k'和alpha=0.7设定了图形的颜色为黑色，并使用部分的填充透明度。对于DataFrame，柱状图会将每一行的值分为一组，并排显示，如图9-16所示：</p>
<pre><code class="language-python">In [69]: df = pd.DataFrame(np.random.rand(6, 4),
   ....:                   index=['one', 'two', 'three', 'four', 'five', 'six'],
   ....:                   columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))

In [70]: df
Out[70]: 
Genus         A         B         C         D
one    0.370670  0.602792  0.229159  0.486744
two    0.420082  0.571653  0.049024  0.880592
three  0.814568  0.277160  0.880316  0.431326
four   0.374020  0.899420  0.460304  0.100843
five   0.433270  0.125107  0.494675  0.961825
six    0.601648  0.478576  0.205690  0.560547

In [71]: df.plot.bar()
</code></pre>
<figure data-type="image" tabindex="21"><img src="http://upload-images.jianshu.io/upload_images/7178691-bfc141acb37d99b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-16 DataFrame的柱状图" loading="lazy"></figure>
<p>注意，DataFrame各列的名称&quot;Genus&quot;被用作了图例的标题。</p>
<p>设置stacked=True即可为DataFrame生成堆积柱状图，这样每行的值就会被堆积在一起（如图9-17所示）：</p>
<pre><code class="language-python">In [73]: df.plot.barh(stacked=True, alpha=0.5)
</code></pre>
<figure data-type="image" tabindex="22"><img src="http://upload-images.jianshu.io/upload_images/7178691-c19e4246eb897978.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-17 DataFrame的堆积柱状图" loading="lazy"></figure>
<blockquote>
<p>笔记：柱状图有一个非常不错的用法：利用value_counts图形化显示Series中各值的出现频率，比如s.value_counts().plot.bar()。</p>
</blockquote>
<p>再以本书前面用过的那个有关小费的数据集为例，假设我们想要做一张堆积柱状图以展示每天各种聚会规模的数据点的百分比。我用read_csv将数据加载进来，然后根据日期和聚会规模创建一张交叉表：</p>
<pre><code class="language-python">In [75]: tips = pd.read_csv('examples/tips.csv')

In [76]: party_counts = pd.crosstab(tips['day'], tips['size'])

In [77]: party_counts
Out[77]: 
size  1   2   3   4  5  6
day                      
Fri   1  16   1   1  0  0
Sat   2  53  18  13  1  0
Sun   0  39  15  18  3  1
Thur  1  48   4   5  1  3

# Not many 1- and 6-person parties
In [78]: party_counts = party_counts.loc[:, 2:5]
</code></pre>
<p>然后进行规格化，使得各行的和为1，并生成图表（如图9-18所示）：</p>
<pre><code class="language-python"># Normalize to sum to 1
In [79]: party_pcts = party_counts.div(party_counts.sum(1), axis=0)

In [80]: party_pcts
Out[80]: 
size         2         3         4         5
day                                         
Fri   0.888889  0.055556  0.055556  0.000000
Sat   0.623529  0.211765  0.152941  0.011765
Sun   0.520000  0.200000  0.240000  0.040000
Thur  0.827586  0.068966  0.086207  0.017241

In [81]: party_pcts.plot.bar()
</code></pre>
<figure data-type="image" tabindex="23"><img src="http://upload-images.jianshu.io/upload_images/7178691-2918f67936823834.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-18 每天各种聚会规模的比例" loading="lazy"></figure>
<p>于是，通过该数据集就可以看出，聚会规模在周末会变大。</p>
<p>对于在绘制一个图形之前，需要进行合计的数据，使用seaborn可以减少工作量。用seaborn来看每天的小费比例（图9-19是结果）：</p>
<pre><code class="language-python">In [83]: import seaborn as sns

In [84]: tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip'])

In [85]: tips.head()
Out[85]: 
   total_bill   tip smoker  day    time  size   tip_pct
0       16.99  1.01     No  Sun  Dinner     2  0.063204
1       10.34  1.66     No  Sun  Dinner     3  0.191244
2       21.01  3.50     No  Sun  Dinner     3  0.199886
3       23.68  3.31     No  Sun  Dinner     2  0.162494
4       24.59  3.61     No  Sun  Dinner     4  0.172069

In [86]: sns.barplot(x='tip_pct', y='day', data=tips, orient='h')
</code></pre>
<figure data-type="image" tabindex="24"><img src="http://upload-images.jianshu.io/upload_images/7178691-c33e8b3add99904b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-19 小费的每日比例，带有误差条" loading="lazy"></figure>
<p>seaborn的绘制函数使用data参数，它可能是pandas的DataFrame。其它的参数是关于列的名字。因为一天的每个值有多次观察，柱状图的值是tip_pct的平均值。绘制在柱状图上的黑线代表95%置信区间（可以通过可选参数配置）。</p>
<p>seaborn.barplot有颜色选项，使我们能够通过一个额外的值设置（见图9-20）：</p>
<pre><code class="language-python">In [88]: sns.barplot(x='tip_pct', y='day', hue='time', data=tips, orient='h')
</code></pre>
<figure data-type="image" tabindex="25"><img src="http://upload-images.jianshu.io/upload_images/7178691-06abe2f070222115.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-20 根据天和时间的小费比例" loading="lazy"></figure>
<p>注意，seaborn已经自动修改了图形的美观度：默认调色板，图形背景和网格线的颜色。你可以用seaborn.set在不同的图形外观之间切换：</p>
<pre><code class="language-python">In [90]: sns.set(style=&quot;whitegrid&quot;)
</code></pre>
<h2 id="直方图和密度图">直方图和密度图</h2>
<p>直方图（histogram）是一种可以对值频率进行离散化显示的柱状图。数据点被拆分到离散的、间隔均匀的面元中，绘制的是各面元中数据点的数量。再以前面那个小费数据为例，通过在Series使用plot.hist方法，我们可以生成一张“小费占消费总额百分比”的直方图（如图9-21所示）：</p>
<pre><code class="language-python">In [92]: tips['tip_pct'].plot.hist(bins=50)
</code></pre>
<figure data-type="image" tabindex="26"><img src="http://upload-images.jianshu.io/upload_images/7178691-255279376f7649a3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-21 小费百分比的直方图" loading="lazy"></figure>
<p>与此相关的一种图表类型是密度图，它是通过计算“可能会产生观测数据的连续概率分布的估计”而产生的。一般的过程是将该分布近似为一组核（即诸如正态分布之类的较为简单的分布）。因此，密度图也被称作KDE（Kernel Density Estimate，核密度估计）图。使用plot.kde和标准混合正态分布估计即可生成一张密度图（见图9-22）：</p>
<pre><code class="language-python">In [94]: tips['tip_pct'].plot.density()
</code></pre>
<figure data-type="image" tabindex="27"><img src="http://upload-images.jianshu.io/upload_images/7178691-ee929d033159516a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-22  小费百分比的密度图" loading="lazy"></figure>
<p>seaborn的distplot方法绘制直方图和密度图更加简单，还可以同时画出直方图和连续密度估计图。作为例子，考虑一个双峰分布，由两个不同的标准正态分布组成（见图9-23）：</p>
<pre><code class="language-python">In [96]: comp1 = np.random.normal(0, 1, size=200)

In [97]: comp2 = np.random.normal(10, 2, size=200)

In [98]: values = pd.Series(np.concatenate([comp1, comp2]))

In [99]: sns.distplot(values, bins=100, color='k')
</code></pre>
<figure data-type="image" tabindex="28"><img src="http://upload-images.jianshu.io/upload_images/7178691-975f04d750c4efe2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-23 标准混合密度估计的标准直方图" loading="lazy"></figure>
<h2 id="散布图或点图">散布图或点图</h2>
<p>点图或散布图是观察两个一维数据序列之间的关系的有效手段。在下面这个例子中，我加载了来自statsmodels项目的macrodata数据集，选择了几个变量，然后计算对数差：</p>
<pre><code class="language-python">In [100]: macro = pd.read_csv('examples/macrodata.csv')

In [101]: data = macro[['cpi', 'm1', 'tbilrate', 'unemp']]

In [102]: trans_data = np.log(data).diff().dropna()

In [103]: trans_data[-5:]
Out[103]: 
          cpi        m1  tbilrate     unemp
198 -0.007904  0.045361 -0.396881  0.105361
199 -0.021979  0.066753 -2.277267  0.139762
200  0.002340  0.010286  0.606136  0.160343
201  0.008419  0.037461 -0.200671  0.127339
202  0.008894  0.012202 -0.405465  0.042560
</code></pre>
<p>然后可以使用seaborn的regplot方法，它可以做一个散布图，并加上一条线性回归的线（见图9-24）：</p>
<pre><code class="language-python">In [105]: sns.regplot('m1', 'unemp', data=trans_data)
Out[105]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb613720be0&gt;

In [106]: plt.title('Changes in log %s versus log %s' % ('m1', 'unemp'))
</code></pre>
<figure data-type="image" tabindex="29"><img src="http://upload-images.jianshu.io/upload_images/7178691-2133d20739478a80.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-24 seaborn的回归/散布图" loading="lazy"></figure>
<p>在探索式数据分析工作中，同时观察一组变量的散布图是很有意义的，这也被称为散布图矩阵（scatter plot matrix）。纯手工创建这样的图表很费工夫，所以seaborn提供了一个便捷的pairplot函数，它支持在对角线上放置每个变量的直方图或密度估计（见图9-25）：</p>
<pre><code class="language-python">In [107]: sns.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2})
</code></pre>
<figure data-type="image" tabindex="30"><img src="http://upload-images.jianshu.io/upload_images/7178691-20aa530a44e06f61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-25 statsmodels macro data的散布图矩阵" loading="lazy"></figure>
<p>你可能注意到了plot_kws参数。它可以让我们传递配置选项到非对角线元素上的图形使用。对于更详细的配置选项，可以查阅seaborn.pairplot文档字符串。</p>
<p>##分面网格（facet grid）和类型数据<br>
要是数据集有额外的分组维度呢？有多个分类变量的数据可视化的一种方法是使用小面网格。seaborn有一个有用的内置函数factorplot，可以简化制作多种分面图（见图9-26）：</p>
<pre><code class="language-python"> In [108]: sns.factorplot(x='day', y='tip_pct', hue='time', col='smoker',
   .....:                kind='bar', data=tips[tips.tip_pct &lt; 1])
</code></pre>
<figure data-type="image" tabindex="31"><img src="http://upload-images.jianshu.io/upload_images/7178691-737ba19a0cbdd46f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-26 按照天/时间/吸烟者的小费百分比" loading="lazy"></figure>
<p>除了在分面中用不同的颜色按时间分组，我们还可以通过给每个时间值添加一行来扩展分面网格：</p>
<pre><code class="language-python">In [109]: sns.factorplot(x='day', y='tip_pct', row='time',
   .....:                col='smoker',
   .....:                kind='bar', data=tips[tips.tip_pct &lt; 1])
</code></pre>
<figure data-type="image" tabindex="32"><img src="http://upload-images.jianshu.io/upload_images/7178691-4e52192441c609f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-27 按天的tip_pct，通过time/smoker分面" loading="lazy"></figure>
<p>factorplot支持其它的绘图类型，你可能会用到。例如，盒图（它可以显示中位数，四分位数，和异常值）就是一个有用的可视化类型（见图9-28）：</p>
<pre><code class="language-python">In [110]: sns.factorplot(x='tip_pct', y='day', kind='box',
   .....:                data=tips[tips.tip_pct &lt; 0.5])
</code></pre>
<figure data-type="image" tabindex="33"><img src="http://upload-images.jianshu.io/upload_images/7178691-356fb27a7c658920.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图9-28 按天的tip_pct的盒图" loading="lazy"></figure>
<p>使用更通用的seaborn.FacetGrid类，你可以创建自己的分面网格。请查阅seaborn的文档（https://seaborn.pydata.org/）。</p>
<h1 id="93-其它的python可视化工具">9.3 其它的Python可视化工具</h1>
<p>与其它开源库类似，Python创建图形的方式非常多（根本罗列不完）。自从2010年，许多开发工作都集中在创建交互式图形以便在Web上发布。利用工具如Boken（https://bokeh.pydata.org/en/latest/）和Plotly（https://github.com/plotly/plotly.py），现在可以创建动态交互图形，用于网页浏览器。</p>
<p>对于创建用于打印或网页的静态图形，我建议默认使用matplotlib和附加的库，比如pandas和seaborn。对于其它数据可视化要求，学习其它的可用工具可能是有用的。我鼓励你探索绘图的生态系统，因为它将持续发展。</p>
<h1 id="94-总结">9.4 总结</h1>
<p>本章的目的是熟悉一些基本的数据可视化操作，使用pandas，matplotlib，和seaborn。如果视觉显示数据分析的结果对你的工作很重要，我鼓励你寻求更多的资源来了解更高效的数据可视化。这是一个活跃的研究领域，你可以通过在线和纸质的形式学习许多优秀的资源。</p>
<p>下一章，我们将重点放在pandas的数据聚合和分组操作上。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pycharm常用快捷键及技巧(macOS)]]></title>
        <id>https://bailingnan.github.io/post/pycharm-chang-yong-kuai-jie-jian-ji-ji-qiao-macos/</id>
        <link href="https://bailingnan.github.io/post/pycharm-chang-yong-kuai-jie-jian-ji-ji-qiao-macos/">
        </link>
        <updated>2020-01-31T16:42:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mac键盘符号和修饰键说明">Mac键盘符号和修饰键说明</h1>
<ul>
<li><code>⌘</code>:Command</li>
<li><code>⇧</code>:Shift</li>
<li><code>⌥</code>:Option</li>
<li><code>⌃</code>:Control</li>
<li><code>↩︎</code>:Return/Enter</li>
<li><code>⌫</code>:Delete</li>
<li><code>⌦</code>:向前删除键（Fn+Delete）</li>
<li><code>↑</code>:上箭头</li>
<li><code>↓</code>:下箭头</li>
<li><code>←</code>:左箭头</li>
<li><code>→</code>:右箭头</li>
<li><code>⇞</code>:Page Up（Fn+↑）</li>
<li><code>⇟</code>:Page Down（Fn+↓）</li>
<li><code>Home</code>:Fn + ←</li>
<li><code>End</code>:Fn + →</li>
<li><code>⇥</code>:右制表符（Tab键）</li>
<li><code>⇤</code>:左制表符（Shift+Tab）</li>
<li><code>⎋</code>:Escape (Esc)</li>
<li>一直按住<code>fn</code>可调出F1~F10</li>
</ul>
<h1 id="editing编辑">Editing（编辑）</h1>
<ul>
<li><code>⌘Z</code>:撤销操作</li>
<li><code>⌘Y</code>:删除整行</li>
<li><code>⇧F6</code>:重命名文件</li>
<li><code>⌘S</code>:保存所有</li>
<li><code>⌦</code>:删除文件（Fn+Delete）</li>
<li><code>⌘⌥L</code>:格式化代码</li>
<li><code>Home</code>:Fn + ←，跳转到行首</li>
<li><code>End</code>:Fn + →，跳转到行末</li>
<li><code>⇧↑/⇧↓</code>:向上/向下选中行</li>
<li><code>⌘D</code>: 复制当前行或选定的块</li>
<li><code>⌘/</code>:注释/取消注释与行注释</li>
<li><code>⌘⌥/</code>:注释/取消注释与块注释</li>
<li><code>⌘J</code>:插入自定义动态代码模板</li>
<li><code>⌃Space</code>:基本的代码补全（补全任何类、方法、变量）</li>
<li><code>⌃⇧Space</code>:智能代码补全（过滤器方法列表和变量的预期类型）</li>
<li><code>⇧↩</code>:开始新的一行</li>
<li><code>⌘⇧U</code>:大小写切换,光标在行内任意位置都能另起一行，且不破坏当行结构</li>
<li><code>⌘⇧↩</code>:自动结束代码，行末自动添加分号</li>
<li><code>⌘P</code>:显示方法的参数信息</li>
<li><code>⌃J</code>:快速查看文档</li>
<li><code>⇧F1</code>:查看外部文档（在某些代码上会触发打开浏览器显示相关文档）</li>
<li><code>⌘F1</code>:在错误或警告处显示具体描述信息</li>
<li><code>⌘N, ⌃↩, ⌃N</code>:生成代码（getter、setter、构造函数、hashCode/equals,toString）</li>
<li><code>⌥↑</code>:连续选中代码块</li>
<li><code>⌥↓</code>:减少当前选中的代码块</li>
<li><code>⌥↩</code>:显示意向动作和快速修复代码</li>
<li><code>⌘⇧] / ⌘⇧[</code>:选择直到代码块结束/开始</li>
<li><code>⌘+ / ⌘-</code>:展开 / 折叠代码块</li>
<li><code>⌘⇧+</code>:展开所有代码块</li>
<li><code>⌘⇧-</code>:折叠所有代码块</li>
</ul>
<h1 id="searchreplace查询替换">Search/Replace（查询/替换）</h1>
<ul>
<li><code>Double ⇧</code>:查询任何东西</li>
<li><code>⌘F</code>:文件内查找</li>
</ul>
<h1 id="compile-and-run编译和运行">Compile and Run（编译和运行）</h1>
<ul>
<li><code>⌃⇧F10</code>:Run</li>
<li><code>⌃⇧F9</code>:Debug</li>
</ul>
<h1 id="navigation导航">Navigation（导航）</h1>
<ul>
<li><code>⌘B</code>:进入光标所在的方法/变量的接口或是定义处</li>
<li><code>⌘⌥B</code>:跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口</li>
<li><code>⌥ Space, ⌘Y</code>:快速打开光标所在方法、类的定义</li>
<li><code>⌃⇧B</code>:跳转到类型声明处</li>
<li><code>⌘U</code>:前往当前光标所在方法的父类的方法 / 接口定义</li>
<li><code>⌃H</code>:显示当前类的层次结构</li>
<li><code>⌘⇧H</code>:显示方法层次结构</li>
<li><code>⌃⌥H</code>:显示调用层次结构</li>
</ul>
<h1 id="调试">调试</h1>
<ul>
<li><code>step over</code>:在单步执行时，在函数内遇到子函数时不会进入子函数内单步执行，而是将子函数整个执行完再停止，也就是把子函数整个作为一步。在不存在子函数的情况下是和step into效果一样的。简单的说就是，<strong>程序代码越过子函数，但子函数会执行，且不进入</strong>。</li>
<li><code>step into</code>:在单步执行时，遇到子函数就进入并且继续单步执行，<strong>有的会跳到源代码里面去执行</strong>。</li>
<li><code>step into my code</code>:在单步执行时，遇到子函数就进入并且继续单步执行，<strong>不会进入到源码中</strong>。</li>
<li><code>step out</code>:假如进入了一个函数体中，你看了两行代码，不想看了，跳出当前函数体内，返回到调用此函数的地方，即使用此功能即可。</li>
<li><code>Resume program</code>:继续恢复程序，直接运行到下一断点处。跳过不想看的地方，直接设置下一个断点，然后<code>Resume program</code>。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyTorch常用代码段]]></title>
        <id>https://bailingnan.github.io/post/pytorch-chang-yong-dai-ma-duan/</id>
        <link href="https://bailingnan.github.io/post/pytorch-chang-yong-dai-ma-duan/">
        </link>
        <updated>2020-01-30T19:09:37.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1基本配置">1.基本配置</h1>
<h2 id="导入包和版本查询">导入包和版本查询</h2>
<pre><code class="language-Python">import torch
import torch.nn as nn
import torchvision
print(torch.__version__)# PyTorch version
print(torch.version.cuda)#Corresponding CUDA version
print(torch.backends.cudnn.version())#Corresponding cuDNN version
print(torch.cuda.get_device_name(0))#GPU type
</code></pre>
<h2 id="可复现性">可复现性</h2>
<p>在硬件设备（CPU、GPU）不同时，完全的可复现性无法保证，即使随机种子相同。但是，在同一个设备上，应该保证可复现性。具体做法是，在程序开始的时候固定torch的随机种子，同时也把numpy的随机种子固定。</p>
<pre><code class="language-Python">np.random.seed(0)
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
</code></pre>
<h2 id="显卡设置">显卡设置</h2>
<p>如果只需要一张显卡</p>
<pre><code class="language-Python"># Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
</code></pre>
<p>如果需要指定多张显卡，比如0，1号显卡。</p>
<pre><code class="language-Python">import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
</code></pre>
<p>也可以在命令行运行代码时设置显卡：</p>
<pre><code>CUDA_VISIBLE_DEVICES=0,1 python train.py
</code></pre>
<p>清除显存:</p>
<pre><code class="language-Python">torch.cuda.empty_cache()
</code></pre>
<p>也可以使用在命令行重置GPU的指令：</p>
<pre><code>nvidia-smi --gpu-reset -i [gpu_id]
</code></pre>
<p>或在命令行可以先使用ps找到程序的PID，再使用kill结束该进程</p>
<pre><code class="language-python">ps aux | grep python
kill -9 [pid]
</code></pre>
<h2 id="设置为cudnn-benchmark模式">设置为cuDNN benchmark模式</h2>
<p>Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。</p>
<pre><code class="language-python">torch.backends.cudnn.benchmark = True
</code></pre>
<p>如果想要避免这种结果波动，设置</p>
<pre><code class="language-python">torch.backends.cudnn.deterministic = True
</code></pre>
<h1 id="2张量tensor处理">2.张量(Tensor)处理</h1>
<h2 id="张量基本信息">张量基本信息</h2>
<pre><code class="language-Python">tensor = torch.randn(3,4,5)
print(tensor.type())  # 数据类型
print(tensor.size())  # 张量的shape，是个元组
print(tensor.dim())   # 维度的数量
</code></pre>
<h2 id="命名变量">命名变量</h2>
<pre><code class="language-Python"># 在PyTorch 1.3之前，需要使用注释
# Tensor[N, C, H, W]
images = torch.randn(32, 3, 56, 56)
images.sum(dim=1)
images.select(dim=1, index=0)

# PyTorch 1.3之后
NCHW = [‘N’, ‘C’, ‘H’, ‘W’]
images = torch.randn(32, 3, 56, 56, names=NCHW)
images.sum('C')
images.select('C', index=0)
# 也可以这么设置
tensor = torch.rand(3,4,1,2,names=('C', 'N', 'H', 'W'))
# 使用align_to可以对维度方便地排序
tensor = tensor.align_to('N', 'C', 'H', 'W')
</code></pre>
<h2 id="数据类型转换">数据类型转换</h2>
<pre><code class="language-Python"># 设置默认类型，pytorch中的FloatTensor远远快于DoubleTensor
torch.set_default_tensor_type(torch.FloatTensor)

# 类型转换
tensor = tensor.cuda()
tensor = tensor.cpu()
tensor = tensor.float()
tensor = tensor.long()
</code></pre>
<h2 id="torchtensor与npndarray转换">torch.Tensor与np.ndarray转换</h2>
<p>除了CharTensor，其他所有CPU上的张量都支持转换为numpy格式然后再转换回来。</p>
<pre><code class="language-Python">ndarray = tensor.cpu().numpy()
tensor = torch.from_numpy(ndarray).float()
tensor = torch.from_numpy(ndarray.copy()).float() # If ndarray has negative stride.
</code></pre>
<h2 id="从只包含一个元素的张量中提取值">从只包含一个元素的张量中提取值</h2>
<p><code>value = torch.rand(1).item()</code></p>
<h2 id="张量形变">张量形变</h2>
<pre><code class="language-Python"># 在将卷积层输入全连接层的情况下通常需要对张量做形变处理，
# 相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。
tensor = torch.rand(2,3,4)
shape = (6, 4)
tensor = torch.reshape(tensor, shape)
</code></pre>
<h2 id="张量复制">张量复制</h2>
<pre><code class="language-Python"># Operation                 |  New/Shared memory | Still in computation graph |
tensor.clone()            # |        New         |          Yes               |
tensor.detach()           # |      Shared        |          No                |
tensor.detach.clone()()   # |        New         |          No                |
</code></pre>
<h2 id="张量拼接">张量拼接</h2>
<pre><code class="language-Python">'''
注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，
而torch.stack会新增一维。例如当参数是3个10x5的张量，torch.cat的结果是30x5的张量，
而torch.stack的结果是3x10x5的张量。
'''
tensor = torch.cat(list_of_tensors, dim=0)
tensor = torch.stack(list_of_tensors, dim=0)
</code></pre>
<h2 id="将整数标签转为one-hot编码">将整数标签转为one-hot编码</h2>
<pre><code class="language-python"># pytorch的标记默认从0开始
tensor = torch.tensor([0, 2, 1, 3])
N = tensor.size(0)
num_classes = 4
one_hot = torch.zeros(N, num_classes).long()
one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())
</code></pre>
<h2 id="得到非零元素">得到非零元素</h2>
<pre><code class="language-python">torch.nonzero(tensor)               # index of non-zero elements,包含点坐标的列表向量
torch.nonzero(tensor==0)            # index of zero elements
torch.nonzero(tensor).size(0)       # number of non-zero elements
torch.nonzero(tensor == 0).size(0)  # number of zero elements
</code></pre>
<h2 id="判断两个张量相等">判断两个张量相等</h2>
<pre><code class="language-Python">torch.allclose(tensor1, tensor2)  # float tensor
torch.equal(tensor1, tensor2)     # int tensor
</code></pre>
<h2 id="张量扩展">张量扩展</h2>
<pre><code class="language-python"># Expand tensor of shape 64*512 to shape 64*512*7*7.
tensor = torch.rand(64,512)
torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)
</code></pre>
<h2 id="矩阵乘法">矩阵乘法</h2>
<pre><code class="language-python"># Matrix multiplcation: (m*n) * (n*p) * -&gt; (m*p).
result = torch.mm(tensor1, tensor2)

# Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)
result = torch.bmm(tensor1, tensor2)

# Element-wise multiplication.
result = tensor1 * tensor2
</code></pre>
<h2 id="计算两组数据之间的两两欧式距离">计算两组数据之间的两两欧式距离</h2>
<p>利用broadcast机制</p>
<pre><code class="language-python">dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))
</code></pre>
<h1 id="3模型定义和操作">3.模型定义和操作</h1>
<h2 id="计算模型整体参数量">计算模型整体参数量</h2>
<pre><code class="language-python">num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())
</code></pre>
<h2 id="查看网络中的参数">查看网络中的参数</h2>
<p>可以通过model.state_dict()或者model.named_parameters()函数查看现在的全部可训练参数（包括通过继承得到的父类中的参数）</p>
<pre><code class="language-python">params = list(model.named_parameters())
(name, param) = params[28]
print(name)
print(param.grad)
print('-------------------------------------------------')
(name2, param2) = params[29]
print(name2)
print(param2.grad)
print('----------------------------------------------------')
(name1, param1) = params[30]
print(name1)
print(param1.grad)
</code></pre>
<h2 id="类似-keras-的-modelsummary-输出模型信息使用pytorch-summary">类似 Keras 的 model.summary() 输出模型信息（使用pytorch-summary ）</h2>
<h2 id="模型权重初始化">模型权重初始化</h2>
<p>注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。</p>
<pre><code class="language-python"># Common practise for initialization.
for layer in model.modules():
    if isinstance(layer, torch.nn.Conv2d):
        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',
                                      nonlinearity='relu')
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.BatchNorm2d):
        torch.nn.init.constant_(layer.weight, val=1.0)
        torch.nn.init.constant_(layer.bias, val=0.0)
    elif isinstance(layer, torch.nn.Linear):
        torch.nn.init.xavier_normal_(layer.weight)
        if layer.bias is not None:
            torch.nn.init.constant_(layer.bias, val=0.0)

# Initialization with given tensor.
layer.weight = torch.nn.Parameter(tensor)
</code></pre>
<h2 id="提取模型中的某一层">提取模型中的某一层</h2>
<p>modules()会返回模型中所有模块的迭代器，它能够访问到最内层，比如self.layer1.conv1这个模块，还有一个与它们相对应的是name_children()属性以及named_modules(),这两个不仅会返回模块的迭代器，还会返回网络层的名字。</p>
<pre><code class="language-python"># 取模型中的前两层
new_model = nn.Sequential(*list(model.children())[:2] 
# 如果希望提取出模型中的所有卷积层，可以像下面这样操作：
for layer in model.named_modules():
    if isinstance(layer[1],nn.Conv2d):
         conv_model.add_module(layer[0],layer[1])
</code></pre>
<h2 id="部分层使用预训练模型">部分层使用预训练模型</h2>
<p>注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是</p>
<pre><code class="language-python">model.load_state_dict(torch.load('model.pth'), strict=False)
</code></pre>
<h1 id="4模型训练和测试">4.模型训练和测试</h1>
<h2 id="自定义loss">自定义loss</h2>
<p>继承torch.nn.Module类写自己的loss。</p>
<pre><code class="language-python">class MyLoss(torch.nn.Moudle):
    def __init__(self):
        super(MyLoss, self).__init__()
        
    def forward(self, x, y):
        loss = torch.mean((x - y) ** 2)
        return loss
</code></pre>
<h2 id="标签平滑label-smoothing">标签平滑（label smoothing）</h2>
<p>写一个label_smoothing.py的文件，然后在训练代码里引用，用LSR代替交叉熵损失即可。label_smoothing.py内容如下：</p>
<pre><code class="language-python">import torch
import torch.nn as nn


class LSR(nn.Module):

    def __init__(self, e=0.1, reduction='mean'):
        super().__init__()

        self.log_softmax = nn.LogSoftmax(dim=1)
        self.e = e
        self.reduction = reduction
    
    def _one_hot(self, labels, classes, value=1):
        &quot;&quot;&quot;
            Convert labels to one hot vectors
        
        Args:
            labels: torch tensor in format [label1, label2, label3, ...]
            classes: int, number of classes
            value: label value in one hot vector, default to 1
        
        Returns:
            return one hot format labels in shape [batchsize, classes]
        &quot;&quot;&quot;

        one_hot = torch.zeros(labels.size(0), classes)

        #labels and value_added  size must match
        labels = labels.view(labels.size(0), -1)
        value_added = torch.Tensor(labels.size(0), 1).fill_(value)

        value_added = value_added.to(labels.device)
        one_hot = one_hot.to(labels.device)

        one_hot.scatter_add_(1, labels, value_added)

        return one_hot

    def _smooth_label(self, target, length, smooth_factor):
        &quot;&quot;&quot;convert targets to one-hot format, and smooth
        them.
        Args:
            target: target in form with [label1, label2, label_batchsize]
            length: length of one-hot format(number of classes)
            smooth_factor: smooth factor for label smooth
        
        Returns:
            smoothed labels in one hot format
        &quot;&quot;&quot;
        one_hot = self._one_hot(target, length, value=1 - smooth_factor)
        one_hot += smooth_factor / (length - 1)

        return one_hot.to(target.device)

    def forward(self, x, target):

        if x.size(0) != target.size(0):
            raise ValueError('Expected input batchsize ({}) to match target batch_size({})'
                    .format(x.size(0), target.size(0)))

        if x.dim() &lt; 2:
            raise ValueError('Expected input tensor to have least 2 dimensions(got {})'
                    .format(x.size(0)))

        if x.dim() != 2:
            raise ValueError('Only 2 dimension tensor are implemented, (got {})'
                    .format(x.size()))


        smoothed_target = self._smooth_label(target, x.size(1), self.e)
        x = self.log_softmax(x)
        loss = torch.sum(- x * smoothed_target, dim=1)

        if self.reduction == 'none':
            return loss
        
        elif self.reduction == 'sum':
            return torch.sum(loss)
        
        elif self.reduction == 'mean':
            return torch.mean(loss)
        
        else:
            raise ValueError('unrecognized option, expect reduction to be one of none, mean, sum')
</code></pre>
<p>或者直接在训练文件里做label smoothing</p>
<pre><code class="language-python">for images, labels in train_loader:
    images, labels = images.cuda(), labels.cuda()
    N = labels.size(0)
    # C is the number of classes.
    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()
    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)

    score = model(images)
    log_prob = torch.nn.functional.log_softmax(score, dim=1)
    loss = -torch.sum(log_prob * smoothed_labels) / N
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()    
</code></pre>
<h2 id="l1-正则化">L1 正则化</h2>
<pre><code class="language-python">l1_regularization = torch.nn.L1Loss(reduction='sum')
loss = ...  # Standard cross-entropy loss
for param in model.parameters():
    loss += torch.sum(torch.abs(param))
loss.backward()
</code></pre>
<h2 id="不对偏置项进行权重衰减weight-decay">不对偏置项进行权重衰减（weight decay）</h2>
<p>pytorch里的weight decay相当于l2正则</p>
<pre><code class="language-python">bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')
others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')
parameters = [{'parameters': bias_list, 'weight_decay': 0},                
              {'parameters': others_list}]
optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)
</code></pre>
<h2 id="梯度裁剪gradient-clipping">梯度裁剪（gradient clipping）</h2>
<pre><code class="language-python">torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)
</code></pre>
<h2 id="得到当前学习率">得到当前学习率</h2>
<pre><code class="language-python"># If there is one global learning rate (which is the common case).
lr = next(iter(optimizer.param_groups))['lr']

# If there are multiple learning rates for different layers.
all_lr = []
for param_group in optimizer.param_groups:
    all_lr.append(param_group['lr'])
</code></pre>
<p>另一种方法，在一个batch训练代码里，当前的lr是</p>
<pre><code class="language-python">optimizer.param_groups[0]['lr']
</code></pre>
<h2 id="学习率衰减">学习率衰减</h2>
<pre><code class="language-python"># Reduce learning rate when validation accuarcy plateau.
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)
for t in range(0, 80):
    train(...)
    val(...)
    scheduler.step(val_acc)

# Cosine annealing learning rate.
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)
# Reduce learning rate by 10 at given epochs.
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)
for t in range(0, 80):
    scheduler.step()    
    train(...)
    val(...)

# Learning rate warmup by 10 epochs.
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)
for t in range(0, 10):
    scheduler.step()
    train(...)
    val(...)
</code></pre>
<h2 id="优化器链式更新">优化器链式更新</h2>
<p>从1.4版本开始，<code>torch.optim.lr_scheduler</code> 支持链式更新（chaining），即用户可以定义两个 schedulers，并交替在训练中使用。</p>
<pre><code class="language-python">import torch
from torch.optim import SGD
from torch.optim.lr_scheduler import ExponentialLR, StepLR
model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]
optimizer = SGD(model, 0.1)
scheduler1 = ExponentialLR(optimizer, gamma=0.9)
scheduler2 = StepLR(optimizer, step_size=3, gamma=0.1)
for epoch in range(4):
    print(epoch, scheduler2.get_last_lr()[0])
    optimizer.step()
    scheduler1.step()
    scheduler2.step()
</code></pre>
<h2 id="模型训练可视化">模型训练可视化</h2>
<p>PyTorch可以使用tensorboard来可视化训练过程。<br>
安装和运行TensorBoard。</p>
<pre><code class="language-python">pip install tensorboard
tensorboard --logdir=runs
</code></pre>
<p>使用SummaryWriter类来收集和可视化相应的数据，放了方便查看，可以使用不同的文件夹，比如'Loss/train'和'Loss/test'。</p>
<pre><code class="language-python">from torch.utils.tensorboard import SummaryWriter
import numpy as np

writer = SummaryWriter()

for n_iter in range(100):
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
</code></pre>
<h2 id="保存与加载断点">保存与加载断点</h2>
<p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p>
<pre><code class="language-python">start_epoch = 0
# Load checkpoint.
if resume: # resume为参数，第一次训练时设为0，中断再训练时设为1
    model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    assert os.path.isfile(model_path)
    checkpoint = torch.load(model_path)
    best_acc = checkpoint['best_acc']
    start_epoch = checkpoint['epoch']
    model.load_state_dict(checkpoint['model'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    print('Load checkpoint at epoch {}.'.format(start_epoch))
    print('Best accuracy so far {}.'.format(best_acc))

# Train the model
for epoch in range(start_epoch, num_epochs): 
    ... 

    # Test the model
    ...
        
    # save checkpoint
    is_best = current_acc &gt; best_acc
    best_acc = max(current_acc, best_acc)
    checkpoint = {
        'best_acc': best_acc,
        'epoch': epoch + 1,
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict(),
    }
    model_path = os.path.join('model', 'checkpoint.pth.tar')
    best_model_path = os.path.join('model', 'best_checkpoint.pth.tar')
    torch.save(checkpoint, model_path)
    if is_best:
        shutil.copy(model_path, best_model_path)
</code></pre>
<h1 id="5其他注意事项">5.其他注意事项</h1>
<ol>
<li>建议有参数的层和汇合（pooling）层使用<code>torch.nn</code>模块定义，激活函数直接使用<code>torch.nn.functional。torch.nn</code>模块和<code>torch.nn.functional</code>的区别在于，<code>torch.nn</code>模块在计算时底层调用了<code>torch.nn.functional</code>，但<code>torch.nn</code>模块包括该层参数，还可以应对训练和测试两种网络状态。使用<code>torch.nn.functional</code>时要注意网络状态，如</li>
</ol>
<pre><code class="language-python">def forward(self, x):
  ...
  x = torch.nn.functional.dropout(x, p=0.5, training=self.training)
</code></pre>
<ol start="2">
<li>不要使用太大的线性层。因为nn.Linear(m,n)使用的是O(mn)的内存，线性层太大很容易超出现有显存。</li>
<li>不要在太长的序列上使用RNN。因为RNN反向传播使用的是BPTT算法，其需要的内存和输入序列的长度呈线性关系。</li>
<li>model(x) 前用 <code>model.train()</code> 和 <code>model.eval()</code> 切换网络状态。</li>
<li>不需要计算梯度的代码块用 with torch.no_grad() 包含起来。</li>
<li><code>model.eval()</code> 和 <code>torch.no_grad()</code> 的区别在于，<code>model.eval()</code> 是将网络切换为测试状态，例如 BN 和dropout在训练和测试阶段使用不同的计算方法。<code>torch.no_grad()</code>是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 <code>loss.backward()</code>。</li>
<li><code>model.zero_grad()</code>会把整个模型的参数的梯度都归零, 而<code>optimizer.zero_grad()</code>只会把传入其中的参数的梯度归零。</li>
<li>torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。</li>
<li><code>loss.backward()</code>前用 <code>optimizer.zero_grad()</code> 清除累积梯度。</li>
<li><code>torch.utils.data.DataLoader</code> 中尽量设置 <code>pin_memory=True</code>，对特别小的数据集如 MNIST 设置 <code>pin_memory=False</code> 反而更快一些。<code>num_workers</code> 的设置需要在实验中找到最快的取值。</li>
<li>用 <code>del</code>及时删除不用的中间变量，节约 GPU 存储。</li>
<li>使用 <code>inplace</code> 操作可节约 GPU 存储，如</li>
</ol>
<pre><code class="language-python">x = torch.nn.functional.relu(x, inplace=True)
</code></pre>
<ol start="13">
<li>减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</li>
<li>使用半精度浮点数 <code>half()</code>会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。</li>
<li>时常使用 <code>assert tensor.size() == (N, D, H, W)</code> 作为调试手段，确保张量维度和你设想中一致。</li>
<li>除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。</li>
<li>统计代码各部分耗时</li>
</ol>
<pre><code class="language-python">with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:
    ...
print(profile)

# 或者在命令行运行
python -m torch.utils.bottleneck main.py
</code></pre>
<ol start="18">
<li>使用TorchSnooper来调试PyTorch代码，程序在执行的时候，就会自动 print 出来每一行的执行结果的 tensor 的形状、数据类型、设备、是否需要梯度的信息。</li>
</ol>
<pre><code class="language-python"># pip install torchsnooper
import torchsnooper

# 对于函数，使用修饰器
@torchsnooper.snoop()

# 如果不是函数，使用 with 语句来激活 TorchSnooper，把训练的那个循环装进 with 语句中去。
with torchsnooper.snoop():
    原本的代码
</code></pre>
<ol start="19">
<li>模型可解释性，使用captum库</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux常用命令]]></title>
        <id>https://bailingnan.github.io/post/linux-chang-yong-ming-ling/</id>
        <link href="https://bailingnan.github.io/post/linux-chang-yong-ming-ling/">
        </link>
        <updated>2020-01-22T08:16:23.000Z</updated>
        <content type="html"><![CDATA[<h1 id="一-linux文件与目录">一、Linux文件与目录</h1>
<ul>
<li>
<h2 id="11-linux文件权限概念">1.1 Linux文件权限概念</h2>
<ul>
<li>切换至root身份:<code>su -</code></li>
<li>离开root身份:<code>exit</code></li>
<li>文件名第一个字符为.的文件为隐藏文件</li>
</ul>
</li>
<li>
<h2 id="12-linux目录配置">1.2 Linux目录配置</h2>
</li>
<li>
<p>FHS针对目录树架构仅定义出三层目录下面应该放置什么数据而已，分别是下面这三个目录的定义：</p>
<ul>
<li><code>/</code>（root, 根目录）:与开机系统有关；</li>
<li><code>/usr</code> （unix software resource）:与软件安装/执行有关；</li>
<li><code>/var</code>（variable）:与系统运行过程有关。</li>
</ul>
</li>
<li>
<p>FHS要求根目录中必须存在的目录:</p>
<ul>
<li>
<p><code>/bin</code>:系统有很多放置可执行文件的目录，但<code>/bin</code>比较特殊。因为<code>/bin</code>放置的是在 单人维护模式下还能够被操作的指令。 在<code>/bin</code>下面的指令可以被root与一般帐号所使用，主要有：cat, chmod, chown, date, mv, mkdir, cp, bash等等常用的指令。</p>
</li>
<li>
<p><code>/boot</code>:主要在放置开机会使用到的文件，包括 Linux 核心文件以及开机菜单与开机所需配置文件等等Linux kernel 常用的文件名为：vmlinuz，如果使用的是 grub2 这个开机管理程序， 则还会存在<code>/boot/grub2/</code>这个目录。</p>
</li>
<li>
<p><code>/dev</code>:存放硬件相关的文件。在 Linux 系统上，任何设备与周边设备都是以文件的型态存在于这个目录当中的。你只要通过存取这个目录下面的某个文件，就等于存取某个设备。比要重要的文件有<code>/dev/null</code>, <code>/dev/zero</code>, <code>/dev/tty</code>, <code>/dev/loop</code>, <code>/dev/sd</code>等等。</p>
</li>
<li>
<p><code>/etc</code>:存放配置文件的目录。系统主要的配置文件几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。一般来说，这个目录下的各文件属性是可以让一般使用者查阅的，但是只有 root 有权力修改。FHS建议不要放置可执行文件 （binary）在这个目录中喔。比较重要的文件有： <code>/etc/modprobe.d/</code>, <code>/etc/passwd</code>, <code>/etc/fstab</code>, <code>/etc/issue</code>等等。另外 FHS 还规范几个重要的目录最好要存在 <code>/etc/</code>目录下：</p>
<ul>
<li><code>/etc/opt</code>（必要）：这个目录在放置第三方协力软件 <code>/opt</code> 的相关配置文件。</li>
<li><code>/etc/X11/</code>（建议）：与 X Window 有关的各种配置文件都在这里，尤其是 xorg.conf 这个 X Server 的配置文件。</li>
<li><code>/etc/sgml/</code>（建议）：与 SGML 格式有关的各项配置文件。</li>
<li><code>/etc/xml/</code>（建议）：与 XML 格式有关的各项配置文件。</li>
</ul>
</li>
<li>
<p><code>/lib</code>:系统的函数库非常的多，而<code>/lib</code>放置的则是在开机时会用到的函数库， 以及 在<code>/bin</code>或<code>/sbin</code>下面的指令会调用的函数库而已。 什么是函数库呢？你可以将 他想成是“外挂”，某些指令必须要有这些“外挂”才能够顺利完成程序的执行 之意。 另外 FSH 还要求下面的目录必须要存在：<code>/lib/modules/</code>：这个目录 主要放置可抽换式的核心相关模块（驱动程序）</p>
</li>
<li>
<p><code>/media</code>:media是“媒体”的英文，顾名思义，这个<code>/media</code>下面放置的就是可移除的设备！ 包括软盘、光盘、DVD等等设备都暂时挂载于此。常见的文件名 有：<code>/media/floppy</code>, <code>/media/cdrom</code>等等。</p>
</li>
<li>
<p><code>/mnt</code>:如果你想要暂时挂载某些额外的设备，一般建议你可以放置到这个目录中。 在古早时候，这个目录的用途与<code>/media</code>相同啦！只是有了<code>/media</code>之后，这个 目录就用来暂时挂载用了。</p>
</li>
<li>
<p><code>/opt</code>:这个是给第三方协力软件放置的目录。什么是第三方协力软件啊？ 举例来说，KDE 这个桌面管理系统是一个独立的计划，不过他可以安装到 Linux 系统中，因此KDE的软件就建议放置到此目录下了。 另外，如果你想要自行安装额外的软件（非原本的 distribution 提供的），那么也能够将你的软件安装到这里来。 不过，以前的 Linux 系统中，我们还是习惯放置在<code>/usr/local</code>目录下呢！</p>
</li>
<li>
<p><code>/run</code>:早期的 FHS 规定系统开机后所产生的各项信息应该要放置到 <code>/var/run</code> 目录下，新版的 FHS 则规范到 <code>/run</code> 下面。 由于 <code>/run</code> 可以使用内存来仿真，因此性能上会好很多！</p>
</li>
<li>
<p><code>/sbin</code>:存放管理员root可以执行的命令。Linux 有非常多指令是用来设置系统环境的，这些指令只有 root 才能够利用 来“设置”系统，其他使用者最多只能用来“查询”而已。放在<code>/sbin</code>下面的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些服务器软件程序，一般则放置到<code>/usr/sbin/</code>当中。至于本机自行安装的软件所产生的系统可执行文件（system binary）， 则放置到<code>/usr/local/sbin/</code> 当中了。常见的指令包括：fdisk, fsck, ifconfig, mkfs等等。</p>
</li>
<li>
<p><code>/srv</code>:srv 可以视为“service”的缩写，是一些网络服务启动之后，这些服务所需要取用的数据目录。 常见的服务例如 WWW, FTP 等等。举例来说，WWW 服务器需要的网页数据就可以放置在<code>/srv/www/</code>里面。 不过，系统的服务数据 如果尚未要提供给网际网络任何人浏览的话，默认还是建议放置到 <code>/var/lib</code>下面即可。</p>
</li>
<li>
<p><code>tem</code>:这是让一般使用者或者是正在执行的程序暂时放置文件的地方。 这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要数据不可放置在此目录啊！ 因为FHS甚至建议在开机时，应该要将<code>/tmp</code>下的数据都删除唷!</p>
</li>
<li>
<p><code>/var</code>:第二层 FHS 设置，主要为放置变动性的数据，后续介绍。</p>
</li>
<li>
<p><code>/usr</code>:第二层 FHS 设置，后续介绍。</p>
</li>
</ul>
</li>
<li>
<p>FHS 建议根目录中可以存在的目录：</p>
<ul>
<li><code>/home</code>：这是系统默认的使用者主文件夹（home directory）。在你新增一个一般使 用者帐号时，默认的使用者主文件夹都会规范到这里来。</li>
<li><code>/lib&lt;equal&gt;</code>:用来存放与 <code>/lib</code> 不同的格式的二进制函数库，例如支持 64 位的 <code>/lib64</code> 函数库等。</li>
<li><code>/root</code>:系统管理员（root）的主文件夹。之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时， 该目录就能够拥有 root 的主文件夹，所以我们会 希望 root 的主文件夹与根目录放置在同一个分区中。</li>
<li><code>/lost+found</code>:这个目录是使用标准的 ext2/ext3/ext4 文件系统格式才会产生的一个目录， 目的在于当文件系统发生错误时， 将一些遗失的片段放置到这个目录下。 不过如果使用的是 xfs 文件系统的话，就不会存在这个目录了！</li>
<li><code>/proc</code>:这个目录本身是一个“虚拟文件系统（virtual filesystem）”喔！他放置的数据都是在内存当中， 例如系统核心、行程信息（process）、周边设备的状态及网络状态等等。因为这个目录下的数据都是在内存当中， 所以本身不占任何硬盘空间啊！比较重要的文件例如：<code>/proc/cpuinfo</code>, <code>/proc/dma</code>, <code>/proc/interrupts</code>, <code>/proc/ioports</code>, <code>/proc/net/*</code> 等等。</li>
<li><code>/sys</code>:这个目录其实跟/proc非常类似，也是一个虚拟的文件系统，主要也是记录 核心与系统硬件信息较相关的信息。 包括目前已载入的核心模块与核心侦测到的硬件设备信息等等。这个目录同样不占硬盘容量喔！</li>
</ul>
</li>
<li>
<p>因为是所有系统默认的软件（distribution发布者提供的软件）都会放置到<code>/usr</code>下面，因此这个目录有点类似 Windows 系统的“C:\Windows\ （当中的一部份） + C:\Program files\”这两个目 录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。一般来说，<code>/usr</code>的次目录 建议有下面这些：</p>
</li>
<li>
<p>FHS 要求必须要存在的目录:</p>
<ul>
<li><code>/usr/bin/</code>:所有一般用户能够使用的指令都放在这里！<code>/usr/bin</code> 与 <code>/bin</code> 是一模一样了！另外，FHS 要求在此目录下不应该有子目录！</li>
<li><code>/usr/lib/</code>:基本上，与 <code>/lib</code> 功能相同，所以 <code>/lib</code> 就是链接到此目录中的！</li>
<li><code>/usr/local/</code>:系统管理员在本机自行安装自己下载的软件（非 distribution 默认提供者），建议安装到此目录， 这样会比较便于管理。举例来说，你的 distribution 提供的软件较旧，你想安装较新的软件但又不想移除旧版，此时你可以将新版软件安装于<code>/usr/local/</code>目录下，可与原先的旧版软件有分别啦！ 你可以自行到<code>/usr/local</code>去看看，该目录下也是具有bin, etc, include, lib...的次目录喔！</li>
<li><code>/usr/sbin/</code>:非系统正常运行所需要的系统指令。最常见的就是某些网络服务器软件 的服务指令（daemon）啰！不过基本功能与 <code>/sbin</code> 也差不多， 因此目前 <code>/sbin</code> 就是链接到此目录中的。</li>
<li><code>/usr/share/</code>:主要放置只读架构的数据文件，当然也包括共享文件。在这个目录下放置的数据几乎是不分硬件架构均可读取的数据，因为几乎都是文字文件嘛！在此目录下常见的还有这些次目录：
<ul>
<li><code>/usr/share/man</code>：线上说明文档。</li>
<li><code>/usr/share/doc</code>：软件杂项的文件说明。</li>
<li><code>/usr/share/zoneinfo</code>：与时区有关的时区文件。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>FHS 建议可以存在的目录：</p>
<ul>
<li><code>/usr/games/</code>:与游戏比较相关的数据放置处。</li>
<li><code>/usr/include/</code>:c/c++等程序语言的文件开始（header）与包含档（include）放置处， 当我们以tarball方式 （*.tar.gz 的方式安装软件）安装某些数据时，会使用到里头的许多包含档喔！</li>
<li><code>/usr/libexec/</code>:某些不被一般使用者惯用的可执行文件或脚本（script）等等，都会放 置在此目录中。例如大部分的 X 窗口下面的操作指令， 很多都是放在此目录下的。</li>
<li><code>/usr/lib&lt;qual&gt;/</code>:与 <code>/lib&lt;qual&gt;/</code>功能相同，因此目前 <code>/lib&lt;qual&gt;</code> 就是链接到此目录中。</li>
<li><code>/usr/src/</code>:一般源代码建议放置到这里，src有source的意思。至于核心源代码则建议放置到<code>/usr/src/linux/</code>目录下。</li>
</ul>
</li>
<li>
<p>如果<code>/usr</code>是安装时会占用较大硬盘容量的目录，那么<code>/var</code>就是在系统运行后才会渐渐占用硬盘容量的目录。 因为<code>/var</code>目录主要针对常态性变动的文件，包括高速缓存（cache）、登录文件 （log file）以及某些软件运行所产生的文件， 包括程序文件（lock file, run file），或者例如 MySQL数据库的文件等等。常见的次目录有：</p>
</li>
<li>
<p>FHS 要求必须要存在的目录:</p>
<ul>
<li><code>/var/cache/</code>:应用程序本身运行过程中会产生的一些暂存盘；</li>
<li><code>/var/lib/</code>:程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。举例来说，MySQL的数据库放置 到<code>/var/lib/mysql/</code>而rpm的数据库则放到<code>/var/lib/rpm</code>去！</li>
<li><code>/var/lock/</code>:某些设备或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该设备时，就可能产生一些错误的状况，因此就得要将该设备上锁（lock），以确保该设备只会给单一软件所使用。目前此目录也已经挪到 <code>/run/lock</code>中！</li>
<li><code>/var/log/</code>:重要到不行！这是登录文件放置的目录！里面比较重要的文件 如<code>/var/log/messages</code>, <code>/var/log/wtmp</code>（记录登陆者的信息）等。</li>
<li><code>/var/mail/</code>:放置个人电子邮件信箱的目录，不过这个目录也被放置到<code>/var/spool/mail/</code> 目录中！ 通常这两个目录是互为链接文件啦！</li>
<li><code>/var/run/</code>:某些程序或者是服务启动后，会将他们的PID放置在这个目录下喔！至于 PID的意义我们会在后续章节提到的。与 <code>/run</code> 相同，这个目录链接到 <code>/run</code> 去了！</li>
<li><code>/var/spool/</code>:这个目录通常放置一些伫列数据，所谓的“伫列”就是排队等待其他程序使用的数据啦！ 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到<code>/var/spool/mail/</code>中， 但使用者收下该信件后该封信原则上就会 被删除。信件如果暂时寄不出去会被放到<code>/var/spool/mqueue/</code>中， 等到被送出后就被删除。如果是工作调度数据（crontab），就会被放置到<code>/var/spool/cron/</code>目录中！</li>
</ul>
</li>
<li>
<h2 id="13-文件与目录管理">1.3 文件与目录管理</h2>
<ul>
<li>
<p>网络文件常常提到类似“./run.sh”之类的数据，这个指令的意义为何？答：由于指令的执行需要变量（bash章节才会提到）的支持，若你的可执行文件放置在本目录，并且本目录并非正规的可执行文件目录（/bin, /usr/bin等为正规），此时要执行指令就得要严格指定该可执行文件。“./”代表“本目录”的意思，所以“./run.sh”代表“执行本目录下，名为run.sh的文件”。</p>
</li>
<li>
<p>cd （change directory, 变换目录）</p>
<ul>
<li><code>cd ~dmtsai</code>: 代表去到 dmtsai 这个使用者的主文件夹，亦即 <code>/home/dmtsai</code></li>
<li><code>cd ~</code>:表示回到自己的主文件夹，亦即是 <code>/root</code> 这个目录</li>
<li><code>cd</code>:没有加上任何路径，也还是代表回到自己主文件夹的意思</li>
<li><code>cd ..</code>:表示去到目前的上层目录</li>
<li><code>cd -</code>:表示回到刚刚的那个目录</li>
<li><code>cd ../postfix</code>:由<code>/var/spool/mail</code> 去到<code>/var/spool/postfix</code></li>
</ul>
</li>
<li>
<p>一登陆Linux系统后，每个帐号都会在自己帐号的主文件夹中(<code>/home</code>)。</p>
</li>
<li>
<p>pwd （显示目前所在的目录）</p>
<ul>
<li><code>pwd [-P]</code>😛 ：显示出确实的路径，而非使用链接 （link） 路径。加上 <code>pwd -P</code> 的选项后，会不以链接文件的数据显示，而是显示正确的完整路径。</li>
<li><code>pwd</code>:单纯显示出目前的工作目录。</li>
</ul>
</li>
<li>
<p>mkdir （创建新目录）</p>
<ul>
<li><code>mkdir [-mp] 目录名称</code>:
<ul>
<li><code>-m</code> ：设置文件的权限喔！直接设置，不需要看默认权限 （umask） 的脸色～</li>
<li><code>-p</code> ：帮助你直接将所需要的目录（包含上层目录）递回创建起来！</li>
<li>示例:
<ul>
<li><code>mkdir test1/test2/test3/test4</code>:错误。mkdir: cannot create directory ‘test1/test2/test3/test4’: No such file or directory</li>
<li><code>mkdir -p test1/test2/test3/test4</code>:正确。</li>
</ul>
</li>
</ul>
</li>
<li>rmdir （删除“空”的目录）
<ul>
<li><code>rmdir [-p] 目录名称</code>:
<ul>
<li><code>-p</code> ：连同“上层”“空的”目录也一起删除。</li>
</ul>
</li>
<li>示例:
<ul>
<li><code>rmdir test1</code>:rmdir: failed to remove ‘test1’: Directory not empty</li>
<li><code>rmdir -p test1/test2/test3/test4</code>:利用 <code>-p</code> 这个选项，立刻就可以将 <code>test1/test2/test3/test4</code> 一次删除,包括test1</li>
<li>如果要将非空目录下的东西都杀掉呢？！ 这个时候就必须使用<code>rm -r 目录名称</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>文件与目录的检视： ls</p>
<ul>
<li><code>ls [-aAdfFhilnrRSt] 文件名或目录名称</code>
<ul>
<li><code>-a</code> ：全部的文件，连同隐藏文件（ 开头为 . 的文件） 一起列出来（常用）</li>
<li><code>-d</code> ：仅列出目录本身，而不是列出目录内的文件数据（常用）</li>
<li><code>-l</code> ：长数据串行出，包含文件的属性与权限等等数据（常用）</li>
<li>示例：
<ul>
<li><code>ls -al ~</code>: 将主文件夹下的所有文件列出来（含属性与隐藏文件）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>cp （复制文件或目录）</p>
<ul>
<li><code>cp [-adfilprsu] 来源文件（source） 目标文件（destination）</code></li>
<li><code>cp [options] source1 source2 source3 .... directory</code>
<ul>
<li><code>-a</code> ：相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明；（常用）</li>
<li><code>-i</code> ：若目标文件（destination）已经存在时，在覆盖时会先询问动作的进行（常用）</li>
<li><code>-r</code> ：递回持续复制，用于目录的复制行为；（常用）</li>
<li><code>-p</code> ：连同文件的属性（权限、用户、时间）一起复制过去，而非使用默认属性（备份常用）；</li>
<li><code>--preserve=all</code> ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了。</li>
<li>如果来源文件有两个以上，则最后一个目的文件一定要是“目录”才行！</li>
<li>如果目标目录或者目标文件不存在，则相当于重命名。</li>
<li>示例
<ul>
<li><code>cp ~/.bashrc /tmp/bashrc</code>:将主文件夹下的 .bashrc 复制到 <code>/tmp</code> 下，并更名为 bashrc</li>
<li><code>cp -i ~/.bashrc /tmp/bashrc</code>:cp: overwrite <code>/tmp/bashrc'? n不覆盖，y为覆盖，重复作两次动作，由于</code>/tmp<code>下面已经存在 bashrc 了，加上</code>-i` 选项后，则在覆盖前会询问使用者是否确定！可以按下 n 或者 y 来二次确认</li>
<li><code>cp /var/log/wtmp .</code>:复制到当前目录</li>
<li><code>cp /etc/ /tmp</code>:复制 <code>/etc/</code> 这个目录下的所有内容到 <code>/tmp</code> 下面，cp: omitting directory <code>/etc</code>，如果是目录则不能直接复制，要加上 <code>-r</code> 的选项</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>rm （移除文件或目录）</p>
<ul>
<li><code>rm [-fir] 文件或目录</code>：
<ul>
<li><code>-f</code> ：就是 force 的意思，忽略不存在的文件，不会出现警告讯息；</li>
<li><code>-r</code> ：递回删除啊！最常用在目录的删除了！这是非常危险的选项！！！</li>
<li><code>-rf</code>: 如子目录里面还有子目录时，那就要使用 -r 这个选项</li>
<li><code>-rf/</code>: 会将系统文件全部删除，非常危险  <s>删库跑路</s></li>
<li>示例：
<ul>
<li><code>rm bashrc*</code>:通过万用字符*的帮忙，将<code>/tmp</code>下面开头为bashrc的文件名通通删除</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>mv （移动文件与目录，或更名）</p>
<ul>
<li><code>mv [-fiu] source destination</code></li>
<li><code>mv [options] source1 source2 source3 .... directory</code>
<ul>
<li><code>-f</code> ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖；</li>
<li><code>-i</code> ：若目标文件 （destination） 已经存在时，就会询问是否覆盖！</li>
<li><code>-u</code> ：若目标文件已经存在，且 source 比较新，才会更新 （update）</li>
<li>示例:
<ul>
<li>复制一文件，创建一目录，将文件移动到目录中：
<ul>
<li><code>cd /tmp</code></li>
<li><code>cp ~/.bashrc bashrc</code></li>
<li><code>mkdir mvtest</code></li>
<li><code>mv bashrc mvtest</code></li>
</ul>
</li>
<li>文件改名：
<ul>
<li><code>mv mvtest mvtest2</code></li>
</ul>
</li>
<li>再创建两个文件，再全部移动到 <code>/tmp/mvtest2</code> 当中:
<ul>
<li><code>cp ~/.bashrc bashrc1</code></li>
<li><code>cp ~/.bashrc bashrc2</code></li>
<li><code>mv bashrc1 bashrc2 mvtest2</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>find（指定目录查找文件）</p>
<ul>
<li><code>find path -option</code> <code>path</code>是你要查找的路径，<code>-option</code>是选项，例如 <code>-name</code>就是根据名称来找。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="二-pip">二、pip</h1>
<ul>
<li><code>pip install --upgrade pip</code>或<code>pip install -U pip</code>:升级pip自身</li>
<li><code>pip list</code>：查看已经通过pip安装的包</li>
<li><code>pip install &lt;包名&gt; --upgrade</code>或<code>pip install -U &lt;包名&gt;</code>:升级包</li>
<li><code>pip install &lt;包名&gt; -i https://mirrors.aliyun.com/pypi/simple</code>:指定单次安装源</li>
<li><code>pip install SomePackage==1.0.4</code>:指定版本</li>
<li><code>pip-review --auto/pip-review --local --interactive</code>:自动更新所有包</li>
</ul>
<h1 id="三-conda">三、conda</h1>
<ul>
<li><code>conda --version</code>:查看conda版本，验证是否安装</li>
<li><code>conda update conda</code>:更新至最新版本，也会更新其它相关包</li>
<li><code>conda update --all</code>:更新所有包</li>
<li><code>conda update package_name</code>:更新指定的包</li>
<li><code>conda create -n env_name package_name</code>:创建名为 env_name 的新环境，并在该环境下安装名为 package_name 的包，可以指定新环境的版本号，例如：<code>conda create -n python2 python=python2.7 numpy pandas</code>，创建了python2环境，python版本为2.7，同时还安装了numpy pandas包</li>
<li><code>conda activate env_name</code>:切换至env_name环境</li>
<li><code>conda deactivate</code>:退出环境</li>
<li><code>conda info -e</code>:显示所有已经创建的环</li>
<li><code>conda create -n new_env_name --clone old_env_name</code>:复制old_env_name为new_env_name</li>
<li><code>conda remove -n env_name –-all</code>:删除环境</li>
<li><code>conda list</code>:查看所有已经安装的包</li>
<li><code>conda install -n env_name package_name</code>:在指定环境中安装包</li>
<li><code>conda remove -n env_name package</code>:删除指定环境中的包</li>
<li><code>rm -rf 虚拟环境所在路径</code>:删除空环境</li>
</ul>
<h1 id="四-vim">四、Vim</h1>
<ul>
<li><code>shift+g</code>:移至文件末尾</li>
</ul>
<h1 id="五-其他">五、其他</h1>
<ul>
<li><code>sudo nautilus /home</code>:打开图形化文件夹</li>
<li><code>top</code>或<code>htop</code>：查看当前进程</li>
<li><code>ifconfig</code>：查看IP地址</li>
<li><code>kill 进程号</code>:终止进程</li>
<li><code>kill -9 进程号</code>:强制终止进程</li>
<li><code>tar -zxvf xxx.tar.gz</code>:解压缩</li>
<li><code>chmod u+x file</code>:对文件 file 增加文件主可执行权限（u表示文件主）</li>
<li><code>sudo apt-get install package</code>:安装包</li>
<li><code>sudo apt-get install package --reinstall</code>:重新安装包</li>
<li><code>sudo apt-get -f install</code>:修复安装</li>
<li><code>sudo apt-get remove package</code>:删除包</li>
<li><code>sudo apt-get remove package --purge</code>:删除包，包括删除配置文件等</li>
<li><code>sudo apt-get update</code>:更新源</li>
<li><code>sudo apt-get upgrade</code>:更新已安装的包</li>
<li><code>sudo apt-get dist-upgrade</code>:`升级系统</li>
<li><code>sudo apt-get autoclean</code>:清理旧版本软件缓存</li>
<li><code>sudo dpkg -i package.deb</code>:所有deb文件的安装</li>
<li><code>sudo dpkg -r package</code>：所有deb文件的卸载</li>
<li><code>sudo dpkg -P package</code>:彻底的卸载，包括软件的配置文件</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello World!]]></title>
        <id>https://bailingnan.github.io/post/hello-world/</id>
        <link href="https://bailingnan.github.io/post/hello-world/">
        </link>
        <updated>2019-12-22T17:10:09.000Z</updated>
        <content type="html"><![CDATA[<p>New begin!</p>
]]></content>
    </entry>
</feed>